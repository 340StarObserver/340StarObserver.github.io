<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Principality Of 340号恒星观测员</title>
    <description>some technical blogs</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 15 Feb 2017 19:28:05 +0800</pubDate>
    <lastBuildDate>Wed, 15 Feb 2017 19:28:05 +0800</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Postgres -- 全备 &amp; 增备</title>
        <description>&lt;p&gt;本篇的主要内容 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 方案一 : 基于 转储 的备份和恢复
    2. 方案二 : 基于 WAL 的备份和恢复
    3. 备份和恢复的脚本
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;方案一.　基于转储的备份和恢复&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    A. script for backup ( sql_backup.sh )
    
    // 该脚本备份某个库
    // 　　结果放入以当天日期为名的目录中
    // 　　并把结果文件按256M拆分，接着每个文件单独压缩(因打包压缩会超出最大文件限制)
    // 用法 : ./sql_backup.sh dbname
    
        #!/bin/sh
        
        # accept parameters
        dbname=$1
        if [ ${#dbname} -eq 0 ]; then
        	echo &quot;You must choose a database to backup&quot;
        	echo &quot;Eg : ./sql_backup.sh dbname&quot;
        	exit
        fi
        
        BackupDir=/mydata/pgbackup
        
        # environment variables
        export PGUSER=postgres
        export PGPASSWORD='xxxxxx'
        export PGHOST=127.0.0.1
        export PGPORT=5432
        
        # dump
        CurDate=$(date +%Y%m%d)
        mkdir $BackupDir/$CurDate
        pg_dump -Fc $dbname | split -b 256M - $BackupDir/$CurDate/
        
        # compress each file separately
        cd $BackupDir/$CurDate
        ls -lh | while read line
        do
        	file=$(echo $line | awk '{word=$9}END{print word}')
        	if [ ${#file} -gt 0 ]; then
        		zip $file.zip $file
        		rm $file
        	fi
        done
        
        echo &quot;successfully backup to $BackupDir/$CurDate&quot;
    
    
    B. script for restore ( sql_restore.sh )
    
    // 该脚本恢复某个库
    // 用法 : ./sql_restore.sh 某次备份的结果目录 新库名
    // 例如 : ./sql_restore.sh /mydata/pgbackup/20170215
    
        #!/bin/sh
        
        # accept parameters
        restore_dir=$1
        new_dbname=$2
        if [ ${#restore_dir} -eq 0 ] || [ ${#new_dbname} -eq 0 ]; then
        	echo &quot;!-- lack of parameters&quot;
        	echo &quot;Eg : ./sql_restore.sh /mydata/pgbackup/20170215 newdb&quot;
        	exit
        fi
        
        # environment variables
        export PGUSER=postgres
        export PGPASSWORD='xxxxxx'
        export PGHOST=127.0.0.1
        export PGPORT=5432
        
        # uncompress each file separately
        cd $restore_dir
        ls -lh | while read line
        do
        	file=$(echo $line | awk '{word=$9}END{print word}')
        	if [ ${#file} -gt 0 ]; then
        		unzip $file
        		rm $file
        	fi
        done
        
        # restore
        createdb $new_dbname
        cat * | pg_restore -d $new_dbname
        psql -d $new_dbname -c 'analyze'
        
        echo &quot;successfully restore from $restore_dir to $new_dbname&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 14 Feb 2017 01:51:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/14/pg-backup/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/14/pg-backup/</guid>
        
        
        <category>Postgresql</category>
        
      </item>
    
      <item>
        <title>全文搜索 -- 从 Elk 转到 Postgres</title>
        <description>&lt;p&gt;自己做个APP玩，里面有个中文文章搜索的功能 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    a. 文章有标题，标签，引用，正文等字段
    b. 根据用户输入的一些关键词，对不同字段给予不同的匹配权重，搜索出综合匹配度最高的若干篇文章
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;原先是用Elasticsearch，通过 ik中文分词插件 来做的，地址是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    https://340starobserver.github.io/2016/10/03/Elasticsearch-IK/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然Elasticsearch的效率和稳定性不强，一直在寻找替代品.&lt;/p&gt;

&lt;p&gt;偶然上个月参加”DbGeek南京站”的活动时，听见德哥给旁边一个DBA安利pg，发现它恰巧是我一直在寻找的宝具啊&lt;/p&gt;

&lt;h3 id=&quot;scws--zhparser&quot;&gt;一.　插件 SCWS &amp;amp; zhparser&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    scws 按照官网的来装就行，zhparser按照github上的来装就行
    
    装完以后 :
    
    psql -h 127.0.0.1 -p 5432 -d deepnote -U postgres
    // 我这里的数据库名字叫 deepnote
    // 注意，使用超级用户登入，否则下面创建extension会失败
    
    create extension zhparser;
    create text search configuration chinese (parser = zhparser);
    alter text search configuration chinese add mapping for n,v,a,i,e,l with simple;
    // 创建了名为 chinese 的文本搜索配置
    
    select to_tsvector('chinese','年轻人还是要提高自己的姿势水平');
    // 测试一下分词的效果
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;二.　创建文章表&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    create table note (
        note_id uuid not null,
        title   varchar(128) not null,
        tags    varchar(64),
        refs    text,
        feel    text,
        primary key(note_id)
    );
    // 创建一个文章表，为了说明问题，只设了编号+标题+标签+引用+正文这些字段
    // 然后准备一些像样的数据弄进去
    
    
    alter table note add column textunite tsvector;
    update note set textunite = setweight(to_tsvector('chinese',title), 'A') ||
        setweight(to_tsvector('chinese',tags) , 'B') ||
        setweight(to_tsvector('chinese',refs) , 'D') ||
        setweight(to_tsvector('chinese',feel) , 'C');
    // 添加新的一列，并使用这个单独的一列来做文本搜索( 相比多列，单列查得更快一些 )
    // 注意，这个新列 = 标题标签正文等字段的加权综合
    // 注意，权重只有ABCD四种值，且 A &amp;gt; B &amp;gt; C &amp;gt; D
    
    
    create index note_textunite_idx on note using gin(textunite);
    // 创建 gin索引，来加速全文搜索
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;三.　查询测试&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    select ts_rank_cd(textunite, query, 32) as score, title 
        from note, to_tsquery('chinese','华夏文明|(商鞅 &amp;amp; 战国)') query 
        where query @@ textunite 
        order by score desc limit 3;
    // 根据输入的一些关键词的组合，查出综合匹配度最高的前三篇文章
    // 参数中的32表示最终得分 score = 原得分/(原得分+1)，即进行归一化        
    // 其结果形如 :
      score   |           title            
    ----------+----------------------------
     0.545455 | 失才亡魏
     0.285714 | 卫鞅三说秦孝公
     0.166667 | 振聋发聩的《谏逐客书》
     0.119128 | 认知中国原生文明的基本理念

    // 权值的分配有待研究
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 10 Feb 2017 21:30:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/10/pg-zhtextsearch/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/10/pg-zhtextsearch/</guid>
        
        
        <category>Postgresql</category>
        
      </item>
    
      <item>
        <title>Mysql - 全备份 &amp; 增量备份 &amp; 恢复</title>
        <description>&lt;p&gt;本篇讲述mysql的日常备份，包括 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 逻辑备份 : 全备份 + 增量备份  
    2. 物理备份 : 直接把数据目录和日志目录全拷贝放到安全的地方  
    3. 恢复  
    4. 自动化脚本  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mysqldump--mysqlbinlog&quot;&gt;方案一.　mysqldump全备 + mysqlbinlog增备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 该方案适合小数据量，且会锁表，只建议在业务低峰时使用  

    首先，确保配置文件中有这一项 :  
    [mysqld]  
    log_bin = /var/log/mysql/mysql-bin.log  
        // 最好让这个日志与数据库数据目录处于不同的硬盘上  
        // 在上述日志目录下，发现此时最新的日志文件的名字是 mysql-bin.000002  
    
    
    先进行一次全备 :  
    mysqldump \  
        --single-transaction \  
        --flush-logs \  
        --master-data=2 \  
        --triggers \  
        --routines \  
        university -u root -p &amp;gt; university-20170125.sql  
            // 把 university 这个库进行备份  
            // 由于有了 --triggers   这个参数，该库相关的触发器也被备份  
            // 由于有了 --routines   这个参数，该库相关的存储过程也被备份  
            // 由于有了 --flush-logs 这个参数  
            // 　　会在上述日志目录下生成一个新的日志文件mysql-bin.000003  
            // 　　且这个新的mysql-bin.000003便是之后拿来做增量恢复的  
    
    
    在这次全备完成后，我们对该库的数据做一些更改，来模拟生产环境下来自客户端的读写请求  
    
    
    再进行增备 :  
        把 mysql-bin.000003 这个增量日志，拷贝到安全的地方  
        // 通常，在生产环境下，建议每隔一小时，便对这个增量日志进行备份  
        // 这件事做得越勤，增量日志备份　与　实际最新数据　的差距便越小，一旦发生事故，损失也就越小  
    
    
    然后，我们模拟一次事故( 进行了一些误操作，导致数据被破坏 )  
    
    
    接下来我们恢复数据 ：  
        事故之前的最近数据 = 最近全备 + 该全备之后的最新增量日志  
        首先，要把该库清空  
        然后 :  
        mysql -u root -p university &amp;lt; university-20170125.sql  
            // 导入最近的全备  
        mysqlbinlog mysql-bin.000003 | mysql -u root -p  
            // 导入该全备之后的最新增量日志  
            // 注意，此处的 mysql-bin.000003 一定不能是日志目录下的运行时日志  
            // 　　　而是在事故发生前就拷贝到安全地方的最新的那份  
            // 　　　( 因为运行时日志已经由于误操作的影响而被污染了 )  
            // 　　　( 而且因为每隔一小时就备份一次增量日志，故取最新的那份 )  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;innobackupex--innobackupex&quot;&gt;方案二.　 innobackupex全备 + innobackupex增备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 该方案适合大数据量，不会锁表  
    
    需要安装 xtrabackup :  
        源码编译，按官网来就行  
        然后将 /usr/local/xtrabackup/bin 添加到PATH中  
    
    
    先进行一次全备 :  
    innobackupex \  
        --defaults-file=YourPath/mysqld.cnf \  
        --host=127.0.0.1 --port=3306 \  
        --user=root --password=xxxxxx /home/seven/try/test  
            // 进行全备份  
            // 备份到/home/seven/try/test这个目录下，会产生一个以时间戳为名字的目录  
            // 注意，强烈推荐像这样把所有库一起备份  
            // 　　否则单单备份某个库，即mysql系统本身的一些库没有被备份的话  
            // 　　之后恢复的时候，把数据目录一删，会导致恢复后无法读出数据的  


    在这次全备完成后，我们对数据做一些更改，来模拟生产环境下来自客户端的读写请求  
    
    
    再进行第一次增备 :  
    innobackupex \  
        --incremental-basedir=/home/seven/try/test/2017-01-25_23-20-48 \  
        --incremental /home/seven/try/test \  
        --host=127.0.0.1 --port=3306 \  
        --user=root --password=xxxxxx  
            // 其中，--incremental-basedir 是刚才全备时产生的目录  
            // 其中，--incremental         是增量存放的目录，同样会产生一个以时间戳为名字的目录  
            // 注意，--incremental 参数后面没有等号  
    
    
    在这次增备完成后，我们再对数据做一些更改  
    
    
    然后我们进行第二次增备 :  
        // 由于这次增备是在上一次增备基础上的，故 --incremental-basedir要填上一次增量产生的时间戳目录  
        // 勤于增备，每小时一次为佳  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/static/img/3.png&quot; alt=&quot;全备份的checkpoints&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    可以看到 :  
        增量1.from_lsn = 全备 .to_lsn  
        增量2.from_lsn = 增量1.to_lsn  
        // 说明上述操作正常  
    
    
    然后，我们模拟一次事故( 进行了一些误操作，导致数据被破坏 )  
    
    
    &amp;lt; 接下来，我们进行恢复 &amp;gt;  
    
    // 注意，执行恢复之前，强烈建议先关闭mysql  
    
    首先，要清空mysql的数据目录( 保险起见，在清空前，把该目录压缩拷贝到安全的地方 )  
        // 注意，清空数据目录，意味着mysql自己的系统库(保存着用户信息和表信息之类)也会被删掉  
        // 注意，所以，我前面推荐不要单单备份某个库，而是全部一起备份  
    
    然后 :  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_1  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_2  
    ...  
    ...  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_N-1  
    innobackupex --apply-log --use-memory=64M base_dir --incremental-dir=incre_dir_N  
        // base_dir 是之前全备份时产出的那个目录  
        // 假设你在那次全备后，做了N次增备，它们各自的产出目录分别是 incre_dir_1 ~ incre_dir_N  
        // 注意，最后对 incre_dir_N 操作的时候，是没有 --redo-only 这个参数的  
    
    然后 :  
    innobackupex --apply-log --use-memory=64M base_dir  
    innobackupex --copy-back base_dir  
    
    最后 :  
    chown -R mysql:mysql /var/lib/mysql/*  
        // 把mysql数据目录下的所有文件，全部改成mysql:mysql所属  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;三.　将备份与恢复脚本化&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 选用方案二进行脚本化( 每天一个以当天日期为名的新目录，里面存放当天的一次全备和若干次增备 )  


    3-1. 全备脚本 backup_full.sh  
    // 该脚本会以当天日期建一个新目录，并把产生的全备目录放入该日期目录中
    // 用法 : ./backup_full.sh
    
        #!/bin/sh
        
        # do Full-Backup for mysql
        # ( suggest that only root can rwx this file )
        
        # here, define your conf
        mysql_conf_file=/etc/mysql/mysql.conf.d/mysqld.cnf
        backup_dir=/mydata/mysqlbackup
        host=127.0.0.1
        port=3306
        user=root
        passwd=xxxxxx
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # every day has a directory
        today_dir=${backup_dir}/$(date +%Y%m%d)
        if [ -d $today_dir ]; then
        	echo &quot;$today_dir exists, it will be cleaned before full-backup&quot;
        	rm -rf ${today_dir}/*
        	echo &quot;$today_dir clean success&quot;
        fi
        
        # exec full-backup
        innobackupex \
        	--defaults-file=$mysql_conf_file \
        	--host=$host --port=$port \
        	--user=$user --password=$passwd $today_dir
        echo &quot;&amp;gt;_&amp;lt; successfully full-backup to $today_dir&quot;
    
    
    3-2. 增备脚本 backup_increment.sh  
    // 该脚本会自动在备份目录下，寻找文件名最大(即日期距今最近)的那个目录
    // 然后在那个目录下找到最近的一次备份，在那基础上做一次增备
    // 用法 : ./backup_increment.sh
    
        #!/bin/sh
        
        # do Increment-Backup for mysql
        # ( suggest that only root can rwx this file )
        
        # here, define your conf
        backup_dir=/mydata/mysqlbackup
        host=127.0.0.1
        port=3306
        user=root
        passwd=xxxxxx
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # recent_dir is like 'backup_dir/20170126'
        sub_dir=$(ls -lh $backup_dir | awk '{word=$9}END{print word}')
        recent_dir=${backup_dir}/$sub_dir
        
        # base_dir   is like 'backup_dir/20170126/2017-01-26_16-24-21'
        # 	if only exists 1 full-backup, use it
        # 	if exists 1 full-backup + n increment-backup, use the newest increment-backup
        sub_dir=$(ls -lh $recent_dir | awk '{word=$9}END{print word}')
        base_dir=${recent_dir}/$sub_dir
        
        # check whether already exists full-backup
        if [ ${#sub_dir} -eq 0 ]; then
        	echo &quot;!-- please do full-backup before incre-backup&quot;
        	exit
        fi
        
        # exec increment-backup
        innobackupex \
        	--incremental-basedir=$base_dir \
        	--incremental $recent_dir \
        	--host=$host --port=$port \
        	--user=$user --password=$passwd
        echo &quot;&amp;gt;_&amp;lt; successfully incre-backup to $recent_dir&quot;
    
    
    3-3. 恢复脚本 restore.sh  
    // 该脚本根据用户给定的日期目录，把那个目录中的首次全备和之后的若干次增备，整合起来，然后恢复
    // 用法 : ./restore.sh /mydata/mysqlbackup/20170215
    
        #!/bin/sh
        
        # do restore for mysql
        # ( 1. suggest that only root can rwx this file )
        # ( 2. stop mysql before restore )
        
        # here, define your conf
        mysql_data_dir=/var/lib/mysql
        mysql_before_restore_path=/mydata/mysqlbefore
        restore_buffer_size=64M
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # check parameters
        restore_dir=$1
        if [ ${#restore_dir} -eq 0 ]; then
        	echo &quot;!-- You must give the restore_dir, such as ./restore.sh /backup/20170126&quot;
        	exit
        fi
        
        # print your parameters
        echo &quot;Your settings are :&quot;
        echo &quot;\tmysql_data_dir       : $mysql_data_dir&quot;
        echo &quot;\tmysql_before_restore : $mysql_before_restore_path&quot;
        echo &quot;\trestore_buffer_size  : $restore_buffer_size&quot;
        echo &quot;\trestore_dir          : $restore_dir&quot;
        
        num=$(ls -lh $restore_dir | awk 'BEGIN{i=-1}{i+=1}END{print i}')
        base_dir=${restore_dir}/$(ls -lh $restore_dir | awk 'BEGIN{i=0}{if(i==1){a=$9} i+=1}END{print a}')
        i=0
        ls -lh $restore_dir | while read line
        do
        	sub_dir=$(echo $line | awk '{word=$9}END{print word}')
        	cur_dir=${restore_dir}/$sub_dir
        	if [ $i -eq 0 ]; then
        		:
        	elif [ $i -eq 1 ]; then
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			--redo-only $base_dir
        	elif [ $i -lt $num ]; then
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			--redo-only $base_dir \
        			--incremental-dir=$cur_dir
        	else
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			$base_dir \
        			--incremental-dir=$cur_dir
        	fi
        	i=$(($i+1))
        done
        
        cd ${mysql_data_dir}/../
        dirname=$(echo $mysql_data_dir | awk -F '/' '{print $4}')
        zip -r ${mysql_before_restore_path}/$(date +%Y%m%d).zip $dirname
        rm -rf $mysql_data_dir/*
        
        innobackupex --apply-log --use-memory=$restore_buffer_size $base_dir
        innobackupex --copy-back $base_dir
        
        chown -R mysql:mysql ${mysql_data_dir}/*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 25 Jan 2017 22:09:00 +0800</pubDate>
        <link>http://localhost:4000/2017/01/25/Mysql-Backup&Restore/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/01/25/Mysql-Backup&Restore/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>mongo监控命令与工具 </title>
        <description>&lt;h2 id=&quot;mongodb&quot;&gt;学习笔记 – mongodb监控&lt;/h2&gt;

&lt;h3 id=&quot;explain-&quot;&gt;法一.　使用　explain 来分析语句执行情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    例如 db.your_collection.find({ x : 123, y : 456 }).explain(&quot;allPlansExecution&quot;)，查看你的语句的工作情况 :  
    
    比如实际用了哪个索引来查  
    比如扫描了多少文档  
    ...  
    
    explain 也常用来测试比较多个索引方案的优劣  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;法二.　慢日志&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    不推荐在配置文件中设置，而是推荐在mongo-shell中动态地设置（一般需要测试的时候动态地开启，测试完后及时关闭）  
    
    db.setProfilingLevel( profile, slowms )  
        // 第一个参数表示慢日志的级别，取值是 0 1 2  
            profile=0  表示不记录慢日志  
            profile=1  表示只记录慢日志  
            profile=2  表示所有日志都记录  
        // 第二个参数表示慢日志的时间阀值，单位是毫秒  
    
    db.getProfilingStatus()  
        // 查看当前慢日志的配置信息，比如我的结果是 :  
        // { &quot;was&quot; : 0, &quot;slowms&quot; : 100 }  
        // 它说明目前 profile=0 &amp;amp; slowms=100  
    
    开启慢日志后，在当前库下就会出现system.profile这个collection  
        // 注意，你在哪个库下面开启慢日志，就只有那个库会有慢日志，每个开启慢日志的库下面都会有system.profile这个collection  
        // 注意，如果你在配置文件里设置慢日志的话，会导致每个库都开启慢日志  
    
    你可以查询当前库下的system.profile集合，获取你想要的慢日志  
        // 因为不同版本的mongo，这个集合里的document的字段数目和名称略有不同  
        // 推荐你用 db.system.profile.find().limit(2).sort({ ts : -1 }).pretty() 查出最近的2条慢日志  
        // 看看具体有哪些字段，就知道怎么写你想要的查询了  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;法三.　查看最近15分钟内的服务状态&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    db.serverStatus()  
        // 必须在admin库下，才能使用这条命令  
        // 举个例子，我只打印出部分信息，db.serverStatus()['extra_info']，结果是 :  
                
        {  
            &quot;note&quot;             : &quot;field vary by platform&quot;,  
            &quot;heap_usage_bytes&quot; : 62236488,  
            &quot;page_faults&quot;      : 24  
        }  
                
        // 其中 heap_usage_bytes 表示最近15分钟内，内存中的热数据占用的字节数  
        // 其中 page_faults      表示最近15分钟内，缺页中断的次数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongodb-mongostat&quot;&gt;法四.　使用mongodb自带的 mongostat&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    该脚本位于mongodb的安装目录的bin目录下  
    举个例子 :  
        
    &amp;gt; mongostat \  
    &amp;gt; --host host:port \  
    &amp;gt; --username admin库的用户 \  
    &amp;gt; --password admin库的密码 \  
    &amp;gt; --authenticationDatabase admin  
        
    注意，authenticationDatabase这个参数必须是admin  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;io&quot;&gt;法五.　查看当前系统的IO情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    iostat -x 1  
        // 每秒输出一次  
        // 注意，它是linux-shell下执行的，并不是mongo-shell里的  
        
    示例输出 :  
    Linux 4.2.0-30-generic (localhost) 	2016年11月20日 	_x86_64_	(4 CPU)  
    avg-cpu:  %user   %nice %system %iowait  %steal   %idle  
                6.37    0.01    1.74    0.92    0.00   90.96  
    Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util  
    sda               0.10     1.17    1.98    1.31    42.79   119.86    98.73     0.08   24.54   16.75   36.27   4.66   1.54  
        // 关注几个数据 :  
        // %iowait  是指CPU等待IO的比例  
        // %idle    是指CPU空闲的比例  
        // %util    是指设备（上述结果中可以看到是sda这块硬盘）在这一秒内的IO带宽的使用百分比  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongo-shell-benchrun&quot;&gt;法六.　使用mongo-shell自带的 benchRun&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    res = benchRun({  
        host        : '地址:端口',  
        username    : 'admin库的用户名',  
        password    : 'admin库的密码',  
        db          : '你要测试的库名',  
        ops         : [  
            {  
                ns  : '你要测试的库名.集合名',  
                op  : 'insert',  
                doc : { 'x' : { '#RAND_INT' : [ 0, 100 ] } }  
            }  
        ],  
        parallel    : 20,  
        seconds     : 5  
    })  
    注意，benchRun需要在admin库下才能执行  
    参数 parallel 是指我要用多少个线程（连接）去并发地插入，注意它并不是说每秒20个并发，因为每个线程每秒可以完成许多次插入  
    参数 seconds  是指这个benchRun要执行多长时间  
        
    返回结果 :  
    {  
        &quot;note&quot;                       : &quot;values per second&quot;,  
        &quot;errCount&quot;                   : NumberLong(0),  
        &quot;trapped&quot;                    : &quot;error: not implemented&quot;,  
        &quot;insertLatencyAverageMicros&quot; : 11.217961300363536,  
        &quot;totalOps&quot;                   : NumberLong(344396),  
        &quot;totalOps/s&quot;                 : 68697.5910483047,  
        &quot;findOne&quot;                    : 0,  
        &quot;insert&quot;                     : 68697.5910483047,  
        &quot;delete&quot;                     : 0,  
        &quot;update&quot;                     : 0,  
        &quot;query&quot;                      : 0,  
        &quot;command&quot;                    : 0  
    }  
    注意，上述结果中的数值都是每秒平均值  
    例如insert=68697 是指每秒执行了这么多次插入  
    例如errCount     是指每秒的平均错误数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mtools-&quot;&gt;法七.　使用 mtools 工具&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mtools最主要的功能是用来分析mongodb的日志  
    它的github的地址是 : https://github.com/rueckstiess/mtools  
    使用说明文档 地址是 : https://github.com/rueckstiess/mtools/wiki  
    
    最常用的是三个模块 :  
    mlogfilter   :  根据时间对日志切片，慢日志过滤，日志转json  
    mloginfo     :  日志统计  
    mplotqueries :  根据日志绘图  
    
    列举一些命令 :  
    
    
    &amp;lt; 7-1. mlogfilter   模块 &amp;gt;  
    
        mlogfilter xx.log --namespace A库.B集合 --slow 100 --json | mongoimport \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --username 你想要入库的库的拥有写权限的一个用户 \  
            --password 对应用户的密码 \  
            --db 你想要入库的库名 \  
            --collection 集合名  
            // 过滤慢日志（属于A库B集合的，超过100ms的），并以json的形式输出  
            // 把输出结果，通过管道，传给mongoimport，再导入到你想要的库里  
    
    
    &amp;lt; 7-2. mloginfo     模块 &amp;gt;  
    
        mloginfo xx.log --distinct  
            // 把日志分类（比如接受连接啊，关闭啊），统计各种分类下的数量  
        
        mloginfo xx.log --connections  
            // 统计日志中连接的来源情况   
        
        mloginfo xx.log --queries  
            // 统计日志中慢查询的分类  
    
    
    &amp;lt; 7-3. mplotqueries 模块 &amp;gt;  
    
        mplotqueries xx.log --group operation --output-file 1.png  
            // 绘制慢查询的散点分布图（按operation的类型分组）  
        
        mlogfilter xx.log --namespace 库名.集合名 | mplotqueries --output-file 2.png  
            // 绘制慢查询的散点分布图（只看指定的集合）  
        
        mlogfilter xx.log --operation query | mplotqueries --type histogram --bucketsize 3600 --output-file 3.png  
            // 过滤出查询的日志，绘制每3600秒里面查询操作的情况  
        
        mplotqueries log1 log2 ... --type rsstate --output-file 5.png  
            // 根据多个日志文件（复制集里的每个结点的日志），绘制出该复制集状态的变动  
    
    
    &amp;lt; 7-4. mgenerate    模块 &amp;gt;  
    
        比如我定义了一个模板文件 template.json，内容如下 :  
            {  
                &quot;user&quot;       : {  
                    &quot;first&quot;  : { &quot;$choose&quot; : [ &quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot; ] },  
                    &quot;last&quot;   : { &quot;$choose&quot; : [ &quot;AAA&quot;, &quot;BBB&quot;, &quot;CCC&quot; ] }  
                },  
                &quot;gender&quot;     : { &quot;$choose&quot; : [ &quot;male&quot;, &quot;female&quot; ] },  
                &quot;age&quot;        : &quot;$number&quot;,  
                &quot;address&quot;    : {  
                    &quot;street&quot; : { &quot;$string&quot; : { &quot;length&quot; : 10 } },  
                    &quot;code&quot;   : { &quot;$number&quot; : [ 10000, 99999 ] }  
                }  
            }  
        
        mgenerate template.json --stdout --pretty --number 1  
            // 指定模板文件，定义结果输出是屏幕，并以友好方式显示结果，指定生产的document的数量是一个  
            // 结果如下（因为定义了随机数，故每次结果可能不同）:  
                {  
                    &quot;gender&quot;     : &quot;male&quot;,  
                    &quot;age&quot;        : 14,  
                    &quot;user&quot;       : {  
                        &quot;last&quot;   :&quot;BBB&quot;,   
                        &quot;first&quot;  : &quot;aaa&quot;  
                    },  
                    &quot;address&quot;    : {  
                        &quot;code&quot;   : 10668,  
                        &quot;street&quot; : &quot;o9ZKibDmck&quot;  
                    }  
                }  
        
        mgenerate template.json \  
            --number 100 \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --database 库名 \  
            --collection 集合名 \  
            --processes 4  
            // 指定模板文件，指定产生100个document，并把结果写入mongodb（指定地址，端口，库名，集合名）  
            // processes参数是用来指定执行此操作的进程数（默认是CPU的数量）  
            // 注意，mgenerate，目前还不支持用户认证，所以 :  
            // 请在你的业务库之外，另建一个无需认证的库来做（因为mgenerate本身就是用来产生测试数据的）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 25 Nov 2016 04:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/25/Mongo-Monitor/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/25/Mongo-Monitor/</guid>
        
        
        <category>Mongodb</category>
        
      </item>
    
      <item>
        <title>基于日志点的Mysql主从复制</title>
        <description>&lt;p&gt;本篇讲述我学习mysql基于二进制日志的复制，主要内容是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 方案一 : 基于 mysqldump    的主从  
    2. 方案二 : 基于 innobackupex 的主从( 推荐 )  
    3. 主从切换  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我的环境是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    主结点 : ipA:3306  
    从结点 : ipB:3306  
    // iptables已配置，允许访问3306端口  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mysqldump-&quot;&gt;一.　基于 mysqldump 的主从&lt;/h3&gt;

&lt;h4 id=&quot;section&quot;&gt;1-1. 在主结点上建立用来复制的用户&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 首先，主结点的配置文件中以下几项要设置 :  
    
    log_bin = /var/run/mysqld/bin.log
    server-id = 10
    
    // 进入主结点，进行如下操作 :  

    create user 'seven'@'%' identified by 'xxxxxx';  
        // 创建用户seven，并且是任何网段的（即slave可以是任何网段下的），用来作为复制的用户  
    
    grant replication slave on *.* to 'seven'@'%' identified by 'xxxxxx';  
        // 为这个用户授权，可以复制任何库的任何表  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-1&quot;&gt;1-2. 备份主结点的数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mysqldump \  
        --single-transaction \  
        --master-data=2 \  
        --triggers \  
        --routines \  
        university -h localhost -u root -p &amp;gt; university.sql  
        // 导出university这个库  
        // 参数 --single-transaction 是用来保证事务完整性  
        // 参数 --master-data = 1    是表示在备份文件中不注销change-master命令  
        // 参数 --master-data = 2    是表示在备份文件中会注销change-master命令  
        // 参数 --triggers           是表示把触发器也导出  
        // 参数 --routines           是表示把存储过程也导出  

    more university.sql  
        // 查看导出的备份文件，里面有一行 -- CHANGE MASTER TO MASTER_LOG_FILE='bin.000002', MASTER_LOG_POS=120;  
        // 其中的 --              表示是注释，对应了刚才的 --master-data = 2 这个参数  
        // 其中的 MASTER_LOG_FILE 表示日志文件，会在之后用到  
        // 其中的 MASTER_LOG_POS  表示日志点，会在之后用到  
        // 注意，这两个值也可以通过　show master status\G; 来查看  
    
    把导出的这个备份文件拷到从结点上（可以使用sftp,scp等）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-2&quot;&gt;1-3.　在从结点上恢复数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 首先，从结点的配置文件中以下几项要配置 :  
    
    skip_slave_start = 1    # manually use start slave to start the slave process
    read_only        = 1    # this slave is read-only
    server-id        = 20
        // 注意，从结点上建议关闭 log_bin  
        // 注意，每个结点的server-id是不同的  

    mysql -h localhost -u root -p university &amp;lt; university.sql  
        // 注意，事先要创建好university这个库，然后才能导入  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;change-master&quot;&gt;1-4. 在从结点上 change master&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    进入从结点的mysql  
    
    change master to master_host = 'ipA',  
        master_port = 3306,  
        master_user = 'seven',  
        master_password = 'xxxxxx',  
        master_log_file = 'bin.000002',  
        master_log_pos = 120;  
        // 参数 master_host     是主结点的地址  
        // 参数 master_user     是主结点上之前创建的用来复制的用户  
        // 参数 master_password 是主结点上之前创建的用来复制的用户的密码  
        // 参数 master_log_file 是上面提到的备份文件中的那一行里的日志文件  
        // 参数 master_log_pos  是上面提到的备份文件中的那一行里的日志点  
    
    start slave;  
        // 启动slave复制进程  
    
    show slave status \G  
        // 查看slave进程的状态，若发现 :  
        // Slave_IO_Running : Yes  
        // Slave_SQL_Running: Yes  
        // 则主从配置基本上可以放心成功了  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-3&quot;&gt;1-5.　验证主从配置&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    在主结点上插入几条数据  
    
    在从结点上查询是否有了那几条新数据  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;innobackupex-&quot;&gt;二.　基于 innobackupex 的主从&lt;/h3&gt;

&lt;h4 id=&quot;section-4&quot;&gt;2-1.　预准备 : 配置文件 + 创建用来复制的用户&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    主结点 :  
    log_bin = /var/run/mysqld/bin.log
    binlog_format = mixed
    server-id = 10
    skip_slave_start = 1
    
    从结点 :  
    log_bin = /var/run/mysqld/bin.log
    binlog_format = mixed
    server-id = 20
    skip_slave_start = 1
        // 注意，主结点和从结点上，建议都开启log_bin，因为这样便于进行主从切换  
        // 注意，主结点和所有的从结点，server-id一定不能相同  
    
    
    在所有结点上(主结点和从结点都要，便于进行主从切换)，创建用来复制的用户 :  
    
    create user 'seven'@'%' identified by 'xxxxxx';  
        // 创建用户seven，并且是任何网段的（即slave可以是任何网段下的），用来作为复制的用户  
    
    grant replication slave on *.* to 'seven'@'%' identified by 'xxxxxx';  
        // 为这个用户授权，可以复制任何库的任何表  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-5&quot;&gt;2-2.　备份主结点的数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    innobackupex \  
        --defaults-file=/etc/my.cnf \  
        --host=ipA --port=3306 \  
        --user=root --password=xxxxxx /mydata/mysqlbackup  
        
        // 进行全备份  
        // 备份到 /mydata/mysqlbackup 这个目录下，会产生一个以时间戳为名字的目录  
        // 注意，强烈推荐像这样把所有库一起备份  
        // 　　否则单单备份某个库，即mysql系统本身的一些库没有被备份的话  
        // 　　之后恢复的时候，把数据目录一删，会导致恢复后无法读出数据的  


    innobackupex \  
        --defaults-file=/etc/my.cnf \  
        --host=ipA --port=3306 \  
        --user=root --password=xxxxxx \  
        --apply-log /mydata/mysqlbackup/2017-01-29_21-03-48  
        
        // 用来保持事务的一致性  
        // 此处的 /mydata/mysqlbackup/2017-01-29_21-03-48 便是刚才全备份的时候产出的目录  
        // 　　需要把该目录拷贝到新的从结点上  
    
    
    下面是线上添加从结点的操作  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-6&quot;&gt;2-3.　在从结点上恢复数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 在mysql关闭的情况下，执行恢复数据的操作  
    
    // 首先，需要清空datadir  
    // ( 建议清空它之前，先压缩拷贝到安全的地方，万一之后的恢复操作失败，也不至于让mysql崩溃无法启动 )  
    
    // 然后 :  
    innobackupex \  
        --defaults-file=/etc/my.cnf \  
        --host=ipB --port=3306 \  
        --user=root --password=xxxxxx \  
        --copy-back /mydata/mysqlbackup/2017-01-29_21-03-48  
        
    // 最后要把datadir中所有文件改成 mysql:mysql所属 :  
    chown -R mysql:mysql /var/lib/mysql/*  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;change-master-1&quot;&gt;2-4.　在从结点上 change master&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    more /mydata/mysqlbackup/2017-01-29_21-03-48/xtrabackup_binlog_info  
        // 看一下这个目录中的 xtrabackup_binlog_info  
        // 我这边的结果是 bin.000001	1984  
        // 这两个数据会派用处  

    启动从结点上的mysql，并进入它的shell  
    
    change master to master_host = 'ipA',  
        master_port = 3306,  
        master_user = 'seven',  
        master_password = 'xxxxxx',  
        master_log_file = 'bin.000001',  
        master_log_pos = 1984;  

    start slave;  
        // 启动slave复制进程  
    
    show slave status \G  
        // Slave_IO_Running : Yes  
        // Slave_SQL_Running: Yes  
        // 则成功  
    
    set global read_only=1;  
        // 最后，要在所有从结点上，设置只读  
        // 注意，也可在配置文件中设置只读，但不推荐那么做；而通过在线命令的方式进行设置，便于进行主从切换  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-7&quot;&gt;三.　主从切换&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    我是基于方案二的，也就是说 :
        1. 主结点和从结点的配置文件中，都开启了log_bin
        2. 从结点的配置文件中，并没有设置只读，而是通过在线命令的方式设置只读的
        3. 主结点和从结点上，都创建了用来复制的用户
    
    
    首先，在原来的主结点上 :
        set global read_only=1;
        show variables like 'read_only';
            // 把原来的主结点设成只读，这样，在进行主从切换的这段时间里，就不会有新的写操作过来
            // 改完后，通过show variables确认一下
        flush logs;
            // 刷新log_bin
        show master status \G
            // 查看主结点状态
    
    
    然后，在原来的某个从结点上(你要选它做新的主结点) :
        show slave status \G
            // 查看原slave状态
            // 若看到&quot;Slave_SQL_Running_State: Slave has read all relay log&quot;
            // 　　则说明主从数据完全一致，可以继续下面的操作
            // 　　否则，你需要等待一会
        stop slave;
            // 停止原来这个从结点上的slave进程
        show master status \G
            // 查看这个新的主结点的master进程的状态，记下结果中的 File 和 Position 字段的值
        set global read_only=0;
            // 原来这个结点作为从结点时，是只读的，现在它当主结点了，要把只读关掉
    
    
    然后，在原来的其他从结点上(它们仍然做从结点，但是它们的主变了) :
        show slave status \G
        stop slave;
            // 仍然是看到&quot;Slave has read all relay log&quot;，才可以关掉slave进程
            // 注意，当所有从结点做完这些操作后，才可以进行下面的操作
    
    
    然后，在新主结点之外的其他所有结点上(即 原主 + 原其他从) :
        change master to master_host = '新主的ip',
            master_port = 3306,
            master_user = 'seven',
            master_password = 'xxxxxx',
            master_log_file = '刚才要你记下的File的值',
            master_log_pos = 刚才要你记下的Position的值;
        start slave;
            // 设置它的主是谁，并启动slave进程
        show slave status \G
            // Slave_IO_Running : Yes　且　Slave_SQL_Running: Yes，则可以
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 22 Nov 2016 03:13:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/22/Mysql-Repliset/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/22/Mysql-Repliset/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>linux磁盘管理</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一.　查看磁盘分区使用状况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    df  
        -l  只显示本地磁盘的（默认）  
        -a  显示所有文件系统的磁盘使用情况（包括0字节分区，往往0字节分区的数目还是比较多的）  
        
        -T  显示每个分区采用了什么文件系统  
        //  比如 /usr挂载点对应的分区 是ext4还是ext3  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  当不指定这两种参数的时候，默认显示的单位是KB  
        
        -t  指定只显示哪种文件系统（比如ext4）的分区  
        -x  指定不显示哪种文件系统（比如ext3）的分区  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;二. 统计文件大小&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    du  
        -b  以字节为单位  
        -k  以KB为单位  
        -m  以MB为单位  
        //  不指定单位的时候，默认是以KB为单位的  
        //  指定单位的时候，会可能有四舍五入的误差  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  注意，用 -b或-k或-m的时候，所有的文件都是一个单位  
        //  注意，用 -h或-H的时候，每个文件显示的单位可能是不一样的，它会对每个文件都按照最合适的单位来显示　
        
        -s  指定统计目标  
        //  不指定该参数的话，默认是统计当前目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;三. 主分区 &amp;amp; 扩展分区 &amp;amp; 逻辑分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 主分区 + 扩展分区　的总数不能超过4个  
    2. 扩展分区要么没有，要么只有一个  
    3. 扩展分区不能直接存储数据，必须在扩展分区的内部创建逻辑分区，才能存储数据  
    
    sudo fdisk -l  
    
        查看磁盘情况，例如我的结果的一部分是 :  
        
        Device     Boot      Start        End    Sectors   Size Id Type  
        /dev/sda1             2048  127999999  127997952    61G 83 Linux  
        /dev/sda2  *     128000000  130000895    2000896   977M 83 Linux  
        /dev/sda3        130000896  138000383    7999488   3.8G 82 Linux swap / Solaris  
        /dev/sda4        138002430 1305999359 1167996930   557G  5 Extended  
        /dev/sda5        138002432  650000383  511997952 244.1G 83 Linux  
        /dev/sda6        650002432 1162000383  511997952 244.1G 83 Linux  
        /dev/sda7       1162002432 1290000383  127997952    61G 83 Linux  
        /dev/sda8       1290002432 1297999871    7997440   3.8G 83 Linux  
        /dev/sda9       1298001920 1305999359    7997440   3.8G 83 Linux  
        
        // 可见，这是第一块磁盘（sda）的9个分区的情况  
        // 其中，sda1~sda4 是主分区&amp;amp;扩展分区  
        // 其中，sda5~sda9 是逻辑分区  
        // sda1,sda2,sda3是主分区， sda4是扩展分区，　且sda2是boot启动区  
        
        // fdisk -l 与 df -Th 命令结合着看 :  
        //     就可以知道我有哪些分区  
        //     每个分区是主分区，还是扩展分区，还是逻辑分区  
        //     每个分区对应哪个目录（即挂载点），各自的大小是多少  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;四.　服务器添加新磁盘&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    目标　：　加入 /dev/sdb 这块新硬盘  
    
    步骤 :  
    
    df -T -h   
        // 查看当前系统中有哪些分区，以及各分区的文件系统的类型  
        // 从返回结果可知当前的 /目录 的文件系统类型是ext4  
    
    sudo mkfs.ext4 /dev/sdb  
        // 把/dev/sdb这块硬盘格式化为ext4格式  
        // （我要在 /mydata　挂载硬盘，所以格式要和 /目录 保持一致）  
    
    sudo fdisk /dev/sdb  
        // 输入 m 查看帮助     
        // 我们先来创建一个主分区 :  
            输入 n 新建分区  
            输入 p 表明要创建的是主分区  
            输入 这个分区的编号是（我这里输入1）  
                （注意，主分区和扩展分区加起来最多4个，且编号为1~4）  
            输入 这个新分区的起始扇区位置（直接回车，使用默认值就行了）  
            输入 这个新分区的结束扇区位置
                （键入数值，该数值减去刚才的起始位置就是你这个新分区的容量）  
                （我们这里输入 +20G，表示从该分区的起始位置往后20G才是终结位置，即给该分区分配20G的空间）  
                （在这之后，还可以继续用 n p 来创建新的主分区）  
        // 我们再来创建一个扩展分区  
            输入 n 继续创建下一个分区  
            输入 e 创建一个扩展分区  
            输入 这个扩展分区的编号（我这里输入2）  
            输入 这个扩展分区的起始扇区位置（我这里输入系统提示的默认值）  
            输入 这个扩展分区的结束扇区位置（我这里输入系统提示的默认值）  
        // 我们再来创建逻辑分区（因为扩展分区并不能直接存储数据，需要在它内部创建逻辑分区）  
            输入 n 创建分区（可以看到现在只能创建主分区和逻辑分区了，因为扩展分区最多只有一个，且已经在上一步中被创建过了）  
            输入 l 创建一个逻辑分区  \
            输入 这个逻辑分区的编号（从5开始，因为1~4是给主分区和扩展分区用的）  
            输入 这个逻辑分区的起始扇区位置  
            输入 这个逻辑分区的终止扇区位置     
        // 输入 p 查看当前这块/dev/sdb磁盘的分区计划  
        // 最后输入 w 把上述制定的分区计划写入分区表  
            （注意，fdisk工具，只能给硬盘做MBR模式的分区）   
        // 例如，最后，我为/dev/sdb这块新硬盘的分区方案为 :  
            /dev/sdb1    主分区　　　　　　　　　　　　　编号=1    大小20G  
            /dev/sdb2    扩展分区　　　　　　　　　　　　编号=2    大小40G  
            /dev/sdb5    逻辑分区（从属于扩展分区）　　　编号=5    大小10G  
            /dev/sdb6    逻辑分区（从属于扩展分区）　　　编号=6    大小30G  
    
    mkdir /mydata  
    mkdir /mydata/pA  
    mkdir /mydata/pB  
    mkdir /mydata/pC  
        // 新建空目录用来挂载硬盘  
        // 其中， /mydata/pA 作为 /dev/sdb1　的挂载点  
        // 其中， /mydata/pB 作为 /dev/sdb5　的挂载点  
        // 其中， /mydata/pC 作为 /dev/sdb6　的挂载点  
        // 注意， 扩展分区不需要挂载点，因为扩展分区并不存储数据，而是它下面的若干逻辑分区需要各自的挂载点  
    
    sudo mount -t ext4 /dev/sdb1 /mydata/pA  
    sudo mount -t ext4 /dev/sdb5 /mydata/pB  
    sudo mount -t ext4 /dev/sdb6 /mydata/pC  
        // 进行挂载
        // 注意，mount命令是临时生效，如果想要永久生效，需要编辑 /etc/fstab  
    
    sudo vi /etc/fstab  
        // 添加 :  
        // /dev/sdb1    /mydata/pA    ext4    defaults    0    1  
        // /dev/sdb5    /mydata/pB    ext4    defaults    0    1  
        // /dev/sdb6    /mydata/pC    ext4    defaults    0    1  
    
    sudo shutdown -r now  
        // 重启  
    
    sudo fdisk -l  
        // 再次查看磁盘情况（有/dev/sdb1之类的就说明成功了）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;swap&quot;&gt;五.　如何给硬盘添加swap分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    第一步，建一个普通的分区（主分区or逻辑分区都行）  
    第二步，修改分区类型的16进制编码  
    第三步，格式化swap分区  
    第四步，启用swap分区  
    
    比方说，我要把 /dev/sdb7 这个分区做成swap分区  
    // 保证该分区已经被创建了，而且还没有被挂载  
    
    fdisk /dev/sdb  
        // 输入 t 来修改分区类型  
        // 输入 7 表示我要对 /dev/sdb7 做修改  
        // 输入 L 来查看各种分区类型对应的编号  
        // 输入 82 （82是swap类型的编号）  
        // 输入 w 来保存  
    
    mkswap /dev/sdb7  
        // 格式化交换分区  
        // 注意，它和格式化普通分区是有区别的，普通分区的格式化用的是mkfs命令  
    
    swapon /dev/sdb7  
        // 启用这个交换分区  
        // swapoff可以用来停用  
    
    vi /etc/fstab  
        // 添加 :  
        // /dev/sdb7    swap    swap    sw    0    0  
    
    重启生效  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 14 Nov 2016 23:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/14/Linux-Disk/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/14/Linux-Disk/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>mysql存储过程 &amp; 触发器</title>
        <description>&lt;p&gt;我把做App时候的一个存储过程（邀请注册）记录下来，以便之后不用再花时间研究它的格式了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    /*  
        procedure for regedit a new account  
        parameters  
        {  
        	usr        : the username you want to use  
        	pwd        : the password you want to use,and it is encoded to char(32) by md5  
        	registtime : the time when regedit  
        	invitor    : the username of person that he invited you to regedit a new account  
        	authcode   : the necessary code for regedit that you get from your invitor  
        	res        : 0 authcode is wrong;1 username has been used by others;2 transaction error;3 succeed  
        }  
        to make our deepnote environment good,we hope that our users are good readers,so we use invite regedit method  
        that is to say,if you want to regedit successfully,  
        A. you should get a right authcode or called invitecode  
        B. your username has not been used by others  
    */  
    
    drop procedure if exists regedit;  
    delimiter //  
    create procedure regedit (in usr varchar(16),in pwd char(32),in registtime int(11),in invitor varchar(16),in authcode char(32),out res tinyint(1))  
    begin  
        declare lastid int;  
        declare t_error int default 0;  
        declare continue handler for sqlexception set t_error=1;  
        
        start transaction;  
    	set res=0;  
    	if exists(select 1 from usertable where username=invitor and inviteauth=1 and invitecode=authcode limit 1)  
    	then  
    		if exists(select 1 from usertable where username=usr limit 1)  
    		then  
    			set res=1;  
    		else  
    			insert into usertable (username,password,birthtime) values(usr,pwd,registtime);  
    			set lastid=LAST_INSERT_ID();  
    			insert into classifytable (userid) values(lastid);  
    			set res=3;  
    		end if;  
    	end if;  
    	
    	if t_error=0 then  
            commit;  
            set res=3;  
        else  
            rollback;  
            set res=2;  
        end if;  
        
    end //  
    delimiter ;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;尝试用触发器的时候，踩过一些坑，这里记录一下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    drop trigger if exists check_sailors;
    delimiter //
    create trigger check_sailors after insert on Sailors for each row
    begin
    	if exists(select * from Sailors 
    		where master is not NULL and master=NEW.master 
    		group by master having count(*)&amp;gt;2)
    	then
    		delete from Sailors where sid = NEW.sid limit 1;
    	end if;
    end //
    delimiter ;
    
    -- mysql5.6 don't support {commit, start transaction, rollback} in trigger  
    -- mysql5.6 don't support 'referencing NEW as N'  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;对比一下 Postgresql 的存储过程，我写了一个转账的事务例子&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    create or replace function transfer(
    	sender bigint, receiver bigint, amount numeric(20,2)
    	) returns boolean AS $$
    begin
    	update customer set balance = balance - amount where id = sender;
    	update customer set balance = balance + amount where id = receiver;
    
    	if exists(select 1 from customer where id = sender and balance &amp;lt; 0.00 limit 1) then
    		rollback;
    	end if;
    
    	return True;
    	commit;
    end;
    $$ language plpgsql;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 10 Nov 2016 16:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/10/Mysql-Procedure/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/10/Mysql-Procedure/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>iptables</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一. 总的命令格式&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                    table        command          chain          parameters        action  

    iptables        -t filter    -A(追加在表尾)     PREROUTING     -p tcp(协议)       -j ACCEPT  
                       nat       -I(追加在表头)     POSTROUTING    -s ip(源ip)           DROP(丢弃且不响应)  
                                 -D(删除一条)       INPUT          -d ip(宿ip)           REJECT(拒绝且会给客户端响应)  
                                 -L(列举)          OUTPUT         --sport sp            DNAT(修改宿地址)  
                                 -n               FORWARD        --dport dp            SNAT(修改源地址)  
                                 -F(清空)                         -m  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;iptables&quot;&gt;二.　初次启用 iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    systemctl stop firewalld  
    systemctl mask firewalld  
    
        centos 默认使用的是firewall，因此需要先关闭它  
    
    yum install iptables-services  
    
        安装iptables service  
    
    systemctl enable iptables  
    
        开机启动iptables-service  
    
    systemctl start iptables  
    
        启动iptables  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;etcsysconfigiptables&quot;&gt;三. 我的 /etc/sysconfig/iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    -A INPUT -i lo -j ACCEPT  
        允许本地访问  

    -A INPUT -p icmp -j ACCEPT  
        允许所有的ICMP协议的报文（即允许被ping）  

    -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT  
        允许已经建立的连接进行回包  


    
    -A INPUT -p tcp --dport 35628 -j ACCEPT  
        允许ssh（改了端口的ssh）被所有机器访问  
        
        

    -A INPUT -p tcp -s 10.47.86.0/24 --dport 9200 -m limit --limit 10/m --limit-burst 100 -j ACCEPT   
        允许 10.47.86.198/24 这个网段的机器访问这台机器的9200端口  
        （并发控制）9200端口的最大连接数是100，超过的话就限制每分钟只能10个连接  
        // 注意， -A 和 -I 都是追加一条规则，区别为 :  
        // -A 是追加在原有规则表的最后  
        // -I 是追加在原有规则表的开头  
    
    -A INPUT -p tcp --dport 9200 -j DROP  
        没有满足上述的并发控制的话，访问9200端口的请求就直接丢弃  
    
    -A OUTPUT -p tcp --sport 9200 -j ACCEPT  
        允许这台机器的9200端口，向任何机器返回数据  
        
        

    -A INPUT -p tcp --dport 8081:8089 -j ACCEPT  
        允许任何机器访问这台机器的8081~8089端口  
        


    -A INPUT -j REJECT  
        拒绝所有额外的数据包（无论什么协议的）  
        // 注意，必须是 -A，即在规则表的表尾；如果是 -I，则会导致所有应该接受的数据包也被拒绝掉  
        // 注意，一般的配置思路是accept的在表头，拒绝的次之  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;snat&quot;&gt;四. SNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写源地址（作用在PostRouting链上，即向外发出数据包的时候）  
     
    应用场景 ：  
     
        有一台HttpServer是A网段的，B网段的一台客户机想要访问A网段里的HttpSserver  
        需要在A网段和B网段之间架设一台nat服务器，通过iptables配置nat转发  
     
    具体做法 :  
     
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A POSTROUTING -p tcp -s B网段地址 -j SNAT --to A网段地址  
            然后执行 service iptables restart  
            
        3. 一定要确保客户机的网关地址，是这台nat服务器的地址  
            可以通过修改客户机的 /etc/sysconfig/network 来达到目的  
            否则的话，如果客户机的请求不巧发给了别的一台网关，那台网关上没有配置nat转发，就访问不了HttpServer了  
    
    // 这样一来，客户机就可以直接访问HttpServer（直接的意思是输入的url不变，就是HttpServer的地址）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;dnat&quot;&gt;五. DNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写宿地址（作用在PreRouting链上，即接收数据包的时候）  
    
    应用场景  :  
    
        同上，还是B网段的客户机想要访问A网段上的http服务  
        但是稍微做些改动，客户机不是直接去访问server的地址，而是去访问nat服务器的地址，nat服务器再做转发  
        // 即，客户机访问nat服务器，但是实际上数据包被偷偷转发给了A网段的server  
    
    具体做法  :  
    
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A PREROUTING -p tcp -d 与客户机相连的网卡地址 --dport 80 -j DNAT --to HttpServer地址:端口  
            然后执行 service iptables restart  
    
    // 这样一来，客户机就可以间接访问HttpServer（间接的意思是客户机并不访问HttpServer的地址，而是使用nat的地址做url）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 09 Nov 2016 18:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/09/Iptables/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/09/Iptables/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>用 rsync 来做主机间的数据同步</title>
        <description>&lt;h3 id=&quot;rsync-&quot;&gt;rsync 数据同步&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync可以用来在服务器之间 同步数据 or 备份数据  

一般linux上自动装了它，用了一下感觉很方便，记录一下以便日后再次用到  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsync&quot;&gt;一. 与rsync相关的目录结构&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync这种级别的服务，推荐让root管理员来管理，当然它的相关配置也推荐放在/root目录下面  


/root/rsyncd  

    # rsync的根目录  


/root/rsyncd/conf  

    # rsync服务的配置目录  

/root/rsyncd/conf/rsyncd.conf  

    # rsync的主配置文件  

/root/rsyncd/conf/rsyncd.secrets  

    # rsync的认证配置  

/root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  


/root/rsyncd/restful  

    # rsync服务的相关脚本目录  

/root/rsyncd/restful/start.sh  

    # rsync服务的启动脚本  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdconf&quot;&gt;二. 主配置文件 rsyncd.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pid file = /mydata/rsyncd/rsyncd.pid  

    # rsync的进程文件目录  

motd file = /root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  

log file = /mydata/rsyncd/rsyncd.log  

    # rsync的日志文件路径  

address = ******  

    # 这台服务器的ip  
    # 若仅在内部使用，请使用内网ip，否则使用公网ip  

port = 873  

    # 监听的端口  

hosts allow = *  

    # 允许的客户端的ip，*表示允许所有  

max connections = 5  

    # 最大连接数量  

uid = root  

gid = root  

use chroot = yes  

read only = yes  

    # 只读  
    # 若允许客户端上传同步数据，则可以设置 write only 或者 read write  

transfer logging = yes  

log format = %t %a %m %f %b  

syslog facility = local3  

timeout = 300  


[linkA]  

path = /mydata/rsyncd/test  

auth users = root  

list = yes  

ignore errors  

secrets file = /root/rsyncd/conf/rsyncd.secrets  

    # 上面这段配置是 linkA，同一台rsync服务器上可以配置多个这种东西，每个的同步目录不同  
    # path          表示linkA所指向的需要同步的目录  
    # auth users    表示同步这个目录下的文件，需要用哪个用户来认证  
    # list=yes      表示在用户登入后，可以看到这个目录下的文件列表；反之设置为no  
    # secrets file  表示该目录所需要的认证配置信息的路径  
    # 还可以配置 exclude = dir1/ dir2/，表示在这个目录下排除（不同步）这个两个子目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdsecrets&quot;&gt;三. 认证配置文件 rsyncd.secrets&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root:abc  

    # 格式为 用户:密码  
    # 注意，此处的用户需要是这台服务器上真实存在的用户  
    # 注意，此处的密码可以不是这个用户的密码（即可以任意）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdmotd&quot;&gt;四. 提示信息配置文件 rsyncd.motd&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;welcome to sync server &amp;gt;_&amp;lt;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;startsh&quot;&gt;五. 启动脚本 start.sh&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --daemon --config=/root/rsyncd/conf/rsyncd.conf  

    # 以后台方式启动  
    # 指定配置文件路径  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;六. 客户端操作&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --port 873 --list-only  root@xx.xx.xx.xx::linkA  

    # 列出服务器上linkA下面的资源  
    # 注意，需要指定端口  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP root@xx.xx.xx.xx::linkA mypath/  

    # 把服务器上linkA下面的资源同步到本机的 mypath目录  
    # 注意，此处不需要指定端口  
    # 注意，此处的参数 -a 是 archive mode  
    # 注意，此处的参数 -v 是 传输时的进度等信息  
    # 注意，此处的参数 -z 是 压缩传输  
    # 注意，此处的参数 -r 是 递归（递归同步linkA下面的子目录）  
    # 注意，此处的参数 -P 是 传输进度  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP --delete root@xx.xx.xx.xx::linkA mypath/  

    # 注意，比较上面一条命令，多了参数 --delete  
    # 它表示客户端的数据要与服务器上的完全一致  
    # 即如果同步之前，你的客户端的mypath目录下存在服务器上没有的文件，则同步的时候会自动删除它们  
    # 所以，使用这条命令的时候，请小心不要让你的客户端的同步目录下有其他重要数据  

Tip : 建议把客户端的同步命令放入crontab里，定期自动同步or备份  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 16:40:00 +0800</pubDate>
        <link>http://localhost:4000/2016/10/23/Rsync/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/23/Rsync/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>Elasticsearch 中文分词 &amp; 安全配置</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一. 资源准备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    centos7.0  

        注意是7.0的系统  

    elasticsearch-2.2.0.tar.gz  

        资源地址 : https://www.elastic.co/downloads/past-releases/elasticsearch-2-2-0  
        注意是 2.2.0 的版本  

    elasticsearch-analysis-ik-1.8.0.zip  

        资源地址 : https://github.com/medcl/elasticsearch-analysis-ik/releases  
        注意是 1.8.0 的版本  
    
    
    
    tar -zxvf elasticsearch-2.2.0.tar.gz  
    
        解压 elasticsearch  
    
    mv elasticsearch-2.2.0 elasticsearch  
    
        改名 elasticsearch 的安装目录(强迫症...)  
    
    mv elasticsearch-2.2.0.tar.gz elasticsearch/  
    
        把压缩包移至elasticsearch的安装目录(强迫症...)  
    
    
    
    tar -zxvf elasticsearch-analysis-ik-1.8.0.zip  
    
        解压 elasticsearch-ik  
    
    mv elasticsearch-analysis-ik-1.8.0 elastic-ik  
    
        改名 elasticsearch-ik 的安装目录(强迫症...)  
    
    mv elasticsearch-analysis-ik-1.8.0.zip elastic-ik/  
    
        把压缩包移至elastic-ik的安装目录(强迫症...)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ik&quot;&gt;二. 安装 ik分词器&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    yum install maven  
    
        安装 maven  
    
    cd path/elastic-ik  
    
        进入你的elastic-ik的安装目录  
    
    mvn clean  
    
    mvn compile  
    
    mvn package  
    
    mkdir /home/seven/elasticsearch/plugins/ik  
    
        创建ik分词插件的目录  
    
    cp target/releases/elasticsearch-analysis-ik-1.8.0.zip /home/seven/elasticsearch/plugins/ik/  
    
        把target/releases下的压缩文件拷贝到elasticsearch的ik插件目录下  
    
    cd /home/seven/elasticsearch/plugins/ik  
    
        进入elasticsearch的ik插件目录  
    
    unzip elasticsearch-analysis-ik-1.8.0.zip  
    
        解压这个ik压缩文件  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;elasticsearchyml&quot;&gt;三. 配置文件 elasticsearch.yml&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    # 此配置文件位于elasticsearch安装目录下的config目录中  
    # 我只把我显示指定的配置项列了出来 :  
    
    cluster.name: waringstates  
    
        集群的名称  
        若是同一个网段下几个机子要构成集群，该配置项必须相同  
    
    node.name: node-1  
    
        该结点的名称  
        若是同一个网段下几个机子要构成集群，该配置项必须不同  
    
    path.data: /mydata/elasticsearch/data  
    
        数据存储路径  
    
    path.logs: /mydata/elasticsearch/logs  
    
        日志存储路径  
    
    network.host: ******  
    
        绑定的ip地址  
        该值可以填 : 127.0.0.1 or 内网地址 or 公网地址  
    
    http.port: 9200  
    
        绑定的端口  
    
    path.repo: [&quot;/mydata/elasticsearch/backup&quot;]  
    
        数据备份的路径  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;elasticsearch&quot;&gt;四. 检验 elasticsearch&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 我把自己一个APP里面搜索文章的示例作为示范
    // 它根据用户输入的一句话，来搜索最匹配的若干篇文章( 根据文章的标题，标签，正文等，给予不同的匹配权重 )

    a. 创建一个测试用的索引  
    
        curl -XPUT 127.0.0.1:9200/deepnote
    
    b. 创建一个mapping  
    
        curl -XPOST 127.0.0.1:9200/deepnote/notes/_mapping -d'{
            &quot;mappings&quot; : {
                &quot;notes&quot; : {
                    &quot;properties&quot; : {
                        &quot;title&quot; : { &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot; : &quot;ik_smart&quot; },
                        &quot;tags&quot;  : { &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot; : &quot;ik_smart&quot; },
                        &quot;refer&quot; : { &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot; },
                        &quot;feel&quot;  : { &quot;type&quot; : &quot;string&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot; }
                    }
                }
            }
        }'
    
    c. 查询测试  
    
        curl -XPOST 127.0.0.1:9200/deepnote/notes/_search -d '{
            &quot;size&quot; : 10,
            &quot;sort&quot; : [ { &quot;_score&quot; : { &quot;order&quot; : &quot;desc&quot; } } ],
            &quot;query&quot; : {
                &quot;filtered&quot; : {
                    &quot;query&quot; : {
                        &quot;bool&quot; : {
                            &quot;should&quot; : [
                                { &quot;match&quot; : { &quot;title&quot; : { &quot;query&quot; : 此处填一句话, &quot;boost&quot; : 此处填整数权重 } } },
                                { &quot;match&quot; : { &quot;tags&quot;  : { &quot;query&quot; : 此处填一句话, &quot;boost&quot; : 此处填整数权重 } } },
                                { &quot;match&quot; : { &quot;refer&quot; : { &quot;query&quot; : 此处填一句话, &quot;boost&quot; : 此处填整数权重 } } },
                                { &quot;match&quot; : { &quot;feel&quot;  : { &quot;query&quot; : 此处填一句话, &quot;boost&quot; : 此处填整数权重 } } }
                            ]
                        }
                    }
                }
            }
        }'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ip&quot;&gt;五. 限制 IP&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    # 因为elasticsearch目前还没有用户权限的概念，因此必须做好安全防护  
    # 当你需要在公网上访问elasticsearch的时候，建议要限制可以访问的IP  
    # 通常，我们使用 iptables 来限制ip  
    
    systemctl stop firewalld  
    systemctl mask firewalld  
    
        centos7 默认使用的是firewall，因此需要先关闭它  
    
    yum install iptables-services  
    
        安装iptables service  
    
    systemctl enable iptables  
    
        开机启动iptables-service  
    
    systemctl start iptables  
    
        启动iptables  
    
    
    iptables -I INPUT -p tcp --dport 22 -j ACCEPT  
    
        开启ssh的22端口  
        !! 注意，别忘了把你之前的一些对外的端口信息配置一下，否则会导致无法连接  
        !! 注意，尤其注意先把ssh配好，否则呵呵哒...  
    
    iptables -I INPUT -s want_ip -p tcp --dport 9200 -j ACCEPT  
    
        开启9200端口(elasticsearch)，且只对want_ip这个ip开放  
    
    service iptables save  
    
        保存iptables的配置  
    
    service iptables restart  
    
        重启iptables  
    
    
    curl -XGET 公网ip:9200/?pretty  
    
        测试访问elasticsearch  
        当你在 want_ip 这个机子上执行这条命令，是有返回值的  
        当你在 其他机子上执行这条命令，是连不上的  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 03 Oct 2016 23:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/10/03/Elasticsearch-IK/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/03/Elasticsearch-IK/</guid>
        
        
        <category>Elasticsearch</category>
        
      </item>
    
  </channel>
</rss>
