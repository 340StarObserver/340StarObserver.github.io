<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Principality Of 340号恒星观测员</title>
    <description>some technical blogs</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 16 Mar 2017 16:56:47 +0800</pubDate>
    <lastBuildDate>Thu, 16 Mar 2017 16:56:47 +0800</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Mysql -- GTID主从方案的学习</title>
        <description>&lt;p&gt;本篇讲述我学习mysql-GTID主从复制，主要内容是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 基于事务的主从配置
    2. 主从切换
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我的环境是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    主结点 ipA : 3306
    从结点 ipB : 3306
    // iptables已配置，允许访问3306端口
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section&quot;&gt;1. 我的配置文件&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    [mysqld]
    log_bin                      = /mysql/logs/bin.log
    binlog-format                = row
    binlog-checksum              = CRC32
    binlog-rows-query-log-events = 1
    
    log-slave-updates      = true
    skip_slave_start       = 1
    slave-parallel-workers = 2
    
    gtid-mode                 = on
    enforce-gtid-consistency  = true
    master-info-repository    = TABLE
    relay-log-info-repository = TABLE
    
    datadir = /var/lib/mysql
    socket  = /mysql/sock/mysql.sock
    
    server-id = 10
    user      = mysql
    port      = 3306
    
    character-set-server = utf8
    symbolic-links       = 0
    sql_mode             = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
    
    [client]
    default-character-set = utf8
    socket = /mysql/sock/mysql.sock
    
    [mysqld_safe]
    log-error = /var/log/mysqld.log
    pid-file  = /mysql/pids/mysqld.pid
    socket    = /mysql/sock/mysql.sock
    
    // 注意
    // 1. 上面出现的路径，确保所属人和所属组都是mysql
    // 2. log_bin       不能位于临时目录下
    // 3. binlog-format 必须是 row
    // 4. binlog-rows-query-log-events=1 表示把sql语句也记下来
    // 5. log-slave-updates=true         表示从结点上也要更新日志
    // 6. skip_slave_start=1             表示从结点启动后，不会自动开启slave进程
    // 7. slave-parallel-workers=2       表示多线程复制，建议业务拆分，分成多个库，有效利用多线程复制
    // 8. 三个socket路径要一致
    // 9. 主结点和从结点的配置文件中，唯一不同的是 server-id
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-1&quot;&gt;2. 检查连接是否正常&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    在所有结点上，都试试看 :
        mysql -h localhost  -P 3306 -u root -p
        mysql -h 该结点的地址 -P 3306 -u root -p
    
    经常会出现改完配置文件后，发现无法登入的情况，此时需要重设root密码 + 增加远程连接的权限
    
    mysqld_safe --skip-grant-tables
        // 绕过权限验证来启动mysql
        // 注意，执行它之前，请先关闭mysql
    
    另外开一个Terminal窗口，执行以下操作 :
        mysql
        &amp;gt; use mysql
        &amp;gt; update user set password=password(&quot;NewPwd&quot;) where user=&quot;root&quot;;
        &amp;gt; flush privileges;
        &amp;gt; exit
        
        pkill -KILL -t pts/0
            // 杀掉原先用mysqld_safe方式启动的mysql
        
        再次启动mysql
        
        mysql -h localhost -P 3306 -u root -p
        &amp;gt; grant all privileges on *.* to 'root'@'localhost' identified by 'NewPwd' with grant option;
            // 若出现报错 ERROR 1820 (HY000): You must SET PASSWORD before executing this statement
            // 则需要先执行 set password = password('NewPwd');
            // 再次执行grant命令
        &amp;gt; grant all privileges on *.* to 'root'@'%'         identified by 'NewPwd' with grant option;
        &amp;gt; flush privileges;
        &amp;gt; exit
    
    然后再次用localhost，内网地址，外网地址都连接看看
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-2&quot;&gt;3. 创建复制用户&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mysql -h localhost -P 3306 -u root -p
    &amp;gt; create user 'ReplicaUser'@'%' identified by 'xxxxxx';
    &amp;gt; grant replication slave on *.* to 'ReplicaUser'@'%' identified by 'xxxxxx';
    &amp;gt; flush privileges;
    &amp;gt; exit
    
    // 注意
    // 1. 只需主结点上创建用户
    // 2. 此处我创建的这个用户，允许从结点来自任何网段，如想限制从结点网段则可以把'%'换掉
    // 3. 此处我创建的这个用户，允许从结点复制任何库的任何表
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-3&quot;&gt;4. 在主结点上备份数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    innobackupex \
    &amp;gt; --defaults-file=/etc/my.cnf \
    &amp;gt; --host=ipA \
    &amp;gt; --port=3306 \
    &amp;gt; --user=root \
    &amp;gt; --password=xxxxxx \
    &amp;gt; /mydata/mysqlbackup
        // 进行一次全备
        // 1. 备份到 /mydata/mysqlbackup 这个目录下，会产生一个以时间为名的目录
        // 2. 建议像这样把所有库一起备份，包括 库mysql 和 库performance schema
    
    innobackupex \
    &amp;gt; --defaults-file=/etc/my.cnf \
    &amp;gt; --host=ipA \
    &amp;gt; --port=3306 \
    &amp;gt; --user=root \
    &amp;gt; --password=xxxxxx \
    &amp;gt; --apply-log \
    &amp;gt; /mydata/mysqlbackup/2017-03-16_14-42-01
        // 对刚才那份全备做事务一致性
        // 1. 2017-03-16_14-42-01 便是刚才全备生成的目录，需要拷贝到每个从结点
        // 2. 查看一下全备目录下的 xtrabackup_binlog_info
        //    记下事务号，比如我的是 02a9ad8e-0984-11e7-963e-00163e00e4e0:1-19
        //    这个事务号之后会用到
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-4&quot;&gt;5. 在从结点上恢复数据&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    先关闭从结点上的mysql
    
    把数据目录/var/lib/mysql压缩留一个备份，然后把原数据目录清空
    
    innobackupex \
    &amp;gt; --defaults-file=/etc/my.cnf \
    &amp;gt; --host=ipB \
    &amp;gt; --port=3306 \
    &amp;gt; --user=root \
    &amp;gt; --password=xxxxxx \
    &amp;gt; --copy-back /mydata/mysqlbackup/2017-03-16_14-42-01
    
    chown -R mysql:mysql /var/lib/mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-5&quot;&gt;6. 在从结点上启动复制&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    启动从结点上的mysql，并登入
    
    reset master;
    set global gtid_purged='02a9ad8e-0984-11e7-963e-00163e00e4e0:1-19';
        // 这是之前记好的事务号
        // 如果不执行这两条命令，会导致之后　&quot;Slave_SQL_Running: No&quot;
    
    change master to master_host='ipA',
        master_port=3306,
        master_user='ReplicaUser',
        master_password='YourPwd',
        master_auto_position=1;
    
    start slave;
    
    show slave status \G
    
    set global read_only=1;
        // 别忘了把从结点设为只读
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-6&quot;&gt;7. 主从切换&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    在原主结点上 :
        set global read_only=1;
            // 原主作为新从，便要只读
        flush logs;
            // 刷新binlog
    
    在某原从结点上( 选它做新主 ) :
        stop slave;
        set global read_only=0;
            // 新主是可写的
    
    在其他的原从结点上( 仍作为从结点 ) :
        stop slave;
    
    在所有的新从结点上 :
        change master to master_host='新主地址',
            master_port=3306,
            master_user='ReplicaUser',
            master_password='YourPwd',
            master_auto_position=1;
            // 相比基于日志点的复制，事务复制在主从切换的时候，不用设置File和Position
        start slave;
        show slave status \G
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 15 Mar 2017 23:13:00 +0800</pubDate>
        <link>http://localhost:4000/2017/03/15/Mysql-Repliset/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/15/Mysql-Repliset/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>记一次配置 pgbouncer 的几个踩坑点</title>
        <description>&lt;p&gt;用 pgbouncer 来作为 pg的连接池，我配置时的主要疑惑点和踩坑点 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. pg_hba.conf   的配合
    2. pgbouncer.ini 中的几个注意点
    3. userlist.txt  的配合
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;一.　简单描述我的环境&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    数据库们 : mydb, deepnote
    
    数据库的超级用户 : postgres
    数据库的普通用户 : seven (它可以读写这两个库中的某些表)
    
    启动pg和pgbouncer的linux用户 : postgres
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pghbaconf---&quot;&gt;二.　pg_hba.conf   的配合&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    # TYPE  DATABASE        USER            ADDRESS                 METHOD
    host    all             all             127.0.0.1/32            md5
    
    // 注意，认证方法必须是 md5，因为要与 pgbouncer.ini中呼应
    // 否则的话，在登陆pgbouncer的时候会一直报错密码错误
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pgbouncerini-&quot;&gt;三.　pgbouncer.ini 中的几个注意点&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    [databases]
    db1 = host=127.0.0.1 port=5432 dbname=deepnote
    db2 = host=127.0.0.1 port=5432 dbname=mydb
    // 注意 :
    // 1. 你一共有多少个需要在应用层使用的库，就要配置多少行
    // 2. host, port, dbname 必须和实际情况一致
    // 3. 第一行开头的db1，是你为 deepnote 这个库起的别名，意味着 pgbouncer.db1 映射到 pg.deepnote
    //    第二行开头的db2，是你为 mydb     这个库起的别名，意味着 pgbouncer.db2 映射到 pg.mydb
    // 4. 在这个部分，建议不要配置 user :
    //    因为如果你写成 db2 = host=127.0.0.1 port=5432 dbname=mydb user=xxx password=yyy
    //    则，在使用pgbouncer连接到该库的时候，只能使用xxx这一个用户，也即该库只享有一个连接池
    //    然而我们实际往往是某个库有很多个用户，分别拥有不同的读写权限，处理着不同的业务
    
    
    [pgbouncer]
    listen_addr = 127.0.0.1
    listen_port = 6432
    
    logfile = /usr/local/pgsql/pgbouncer/pgbouncer.log
    pidfile = /usr/local/pgsql/pgbouncer/pgbouncer.pid
    
    unix_socket_dir = /var/run/pgbouncer
    unix_socket_mode = 0777
    unix_socket_group =
    // 注意 :
    // 在 /var/run 这个目录下，所有的东西，在每次重启机器的时候都会清空
    // 所以，每次启动pgbouncer之前，都去建立 unix_socket_dir，且设为只有 postgres 能访问(即权限700)
    
    auth_type = md5
    auth_file = /home/postgres/pgbouncer-install/conf/userlist.txt
    // 注意 :
    // 当 auth_type=md5 的时候，你的 pg_hba.conf 中也必须设置为md5认证方式
    // 否则的话，在登陆pgbouncer的时候会一直报错密码错误
    
    admin_users = postgres
    // 注意 :
    // 它指的是哪些用户可以管理pgbouncer，你可能会疑惑，它到底是某些linux用户呢，还是某些数据库用户呢
    // 保险起见，不管它应该填linux用户，还是数据库用户
    // 你只需创建一个 数据库超级用户 (且与启动pg和pgbouncer的 linux用户 同名)，就可以无忧了
    
    pool_mode = transaction
    
    max_client_conn = 100
    default_pool_size = 20
    min_pool_size = 0
    reserve_pool_size = 5
    reserve_pool_timeout = 3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;userlisttxt--&quot;&gt;四.　userlist.txt  的配合&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 先以超级用户的身份登陆pg的任意一个库，执行下述命令 :
    
        \o userlist.txt
        select rolname,rolpassword from pg_authid where rolname = 'seven' or rolname = 'postgres';
        \o
        \q
        
        // 查询条件必须是 所有 需要在应用层中使用的数据库用户
        
        
    2. 生成的 userlist.txt
    
         rolname  |             rolpassword             
        ----------+-------------------------------------
         seven    | md5528a5677b92d65f47a4b1713d5b7ead3
         postgres | md567879684dac8ab24662f675b312e1635
        (2 rows)
    
    
    3. 改成下列样子
    
        &quot;seven&quot; &quot;填该用户的原密码&quot;
        &quot;seven&quot; &quot;md5528a5677b92d65f47a4b1713d5b7ead3&quot;
        &quot;postgres&quot; &quot;填该用户的原密码&quot;
        &quot;postgres&quot; &quot;md567879684dac8ab24662f675b312e1635&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pgbouncer&quot;&gt;五.　如何连接 pgbouncer&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 如何登入pgbouncer进行管理
    
        psql -h 127.0.0.1 -p 6432 -U postgres pgbouncer
        // 注意 :
        // 1. 端口是pgbouncer的端口
        // 2. 用户 postgres 是 pgbouncer.ini 中的 admin_users
        //    虽然我上面建议 admin_users 是启动pg和pgbouncer的linux用户
        //    但是注意密码是要输入对应的数据库用户的密码
        // 3. 没有 -d，直接填数据库的名字，这一定要与直接连接pg时的&quot;-d 库名&quot; 区别开来
        //    此处库名是 pgbouncer，对了你一定发现了，它既不是 pgbouncer.ini 中的 db1，也不是 db2
        //    为何凭空冒出这个东西呢 ?
        //    因为我不是要通过pgbouncer来连接pg，这里，我只是要登入管理pgbouncer，所以库名填它
        
        show config;
        
        show clients;


    2. 如何通过pgbouncer间接连接pg
    
        psql -h 127.0.0.1 -p 6432 -U seven db1
        // 注意 :
        // 1. 端口仍是pgbouncer的端口
        // 2. 用户是 userlist.txt 中的一个
        // 3. 没有 -d，直接填数据库的别名(注意是别名)，即 pgbouncer.ini 中的 [databases]中对应那行的开头那个单词
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 22 Feb 2017 22:30:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/22/pg-pgbouncer/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/22/pg-pgbouncer/</guid>
        
        
        <category>Postgresql</category>
        
      </item>
    
      <item>
        <title>Postgres -- 备份恢复的三种方式</title>
        <description>&lt;p&gt;本篇的主要内容 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 方案一 : 基于 转储 的备份与恢复
    2. 方案二 : 基于 归档 的备份和恢复
    3. 方案三 : 基于 pg_rman 的全备与增备 ( 推荐 )
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;方案一.　基于转储的备份和恢复&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    A. script for backup ( sql_backup.sh )
    
    // 该脚本备份某个库
    // 　　结果放入以当天日期为名的目录中
    // 　　并把结果文件按256M拆分，接着每个文件单独压缩(因打包压缩会超出最大文件限制)
    // 用法 : ./sql_backup.sh dbname
    
        #!/bin/sh
        
        # accept parameters
        dbname=$1
        if [ ${#dbname} -eq 0 ]; then
        	echo &quot;You must choose a database to backup&quot;
        	echo &quot;Eg : ./sql_backup.sh dbname&quot;
        	exit
        fi
        
        BackupDir=/mydata/pgbackup
        
        # environment variables
        export PGUSER=postgres
        export PGPASSWORD='xxxxxx'
        export PGHOST=127.0.0.1
        export PGPORT=5432
        
        # dump
        CurDate=$(date +%Y%m%d)
        mkdir $BackupDir/$CurDate
        pg_dump -Fc $dbname | split -b 256M - $BackupDir/$CurDate/
        
        # compress each file separately
        cd $BackupDir/$CurDate
        ls -lh | while read line
        do
        	file=$(echo $line | awk '{word=$9}END{print word}')
        	if [ ${#file} -gt 0 ]; then
        		zip $file.zip $file
        		rm $file
        	fi
        done
        
        echo &quot;successfully backup to $BackupDir/$CurDate&quot;
    
    
    B. script for restore ( sql_restore.sh )
    
    // 该脚本恢复某个库
    // 用法 : ./sql_restore.sh 某次备份的结果目录 新库名
    // 例如 : ./sql_restore.sh /mydata/pgbackup/20170215
    
        #!/bin/sh
        
        # accept parameters
        restore_dir=$1
        new_dbname=$2
        if [ ${#restore_dir} -eq 0 ] || [ ${#new_dbname} -eq 0 ]; then
        	echo &quot;!-- lack of parameters&quot;
        	echo &quot;Eg : ./sql_restore.sh /mydata/pgbackup/20170215 newdb&quot;
        	exit
        fi
        
        # environment variables
        export PGUSER=postgres
        export PGPASSWORD='xxxxxx'
        export PGHOST=127.0.0.1
        export PGPORT=5432
        
        # uncompress each file separately
        cd $restore_dir
        ls -lh | while read line
        do
        	file=$(echo $line | awk '{word=$9}END{print word}')
        	if [ ${#file} -gt 0 ]; then
        		unzip $file
        		rm $file
        	fi
        done
        
        # restore
        createdb $new_dbname
        cat * | pg_restore -d $new_dbname
        psql -d $new_dbname -c 'analyze'
        
        echo &quot;successfully restore from $restore_dir to $new_dbname&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;方案二.　基于 归档 的备份和恢复&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 修改 postgresql.conf
    
        wal_level       = archive
        archive_mode    = on
        archive_command = 'test ! -f /usr/local/pgsql/archivedir/%f &amp;amp;&amp;amp; cp %p /usr/local/pgsql/archivedir/%f'
        archive_timeout = 300
        max_wal_senders = 4
        // 如果你的事务不是很频繁，可以设置 archive_timeout，限制超过多少秒就把wal段归档
    
    
    2. 修改 pg_hba.conf，添加一行 :
    
        host    replication     postgres        127.0.0.1/32            password
        // 比如你要使用超级用户postgres来进行复制
        // 改完这两个配置文件后重启服务
    
    
    3. 先进行一次全备份( 基础备份 )
    
        pg_basebackup -h 127.0.0.1 -p 5432 -U postgres -D /mydata/pgbackup -Ft -z -P
        // -D     指定备份目录
        // -Ft -z 指定按照tar.gz来压缩
        // -P     指定输出一些进度信息
    
    
    4. 更改一些数据，模拟读写请求，然后等一会，直至/usr/local/pgsql/archivedir目录下出现了新的wal归档
        // 如果等不及，可以用 select pg_switch_xlog(); 来强制更新wal段
    
    
    5. 发生故障，如何恢复 ?
    
        第一步 : 关闭服务
        
        第二步 : 清空数据目录 ( 清空前建议打包压缩先放到其他地方，以免恢复失败时不至于服务都启动不了 )
        
        第三步 : 把之前做的基础备份放到数据目录下并还原 :
        
                mv /mydata/pgbackup/base.tar.gz /usr/local/pgsql/data/
                cd /usr/local/pgsql/data
                tar -xvf base.tar.gz
                rm base.tar.gz
                
                rm -rf pg_xlog/*
                mkdir pg_xlog/archive_status
                chmod 700 pg_xlog/archive_status

        第四步 : 创建 /usr/local/pgsql/data/recovery.conf，内容是 :
                restore_command = 'cp /usr/local/pgsql/archivedir/%f %p'
        
        第五步 : 启动服务
        // 过一会数据恢复好以后，可以看到数据目录下的 recovery.conf 后缀名变成了 done
        // 最后不要忘了恢复后执行一下 vacuum 或 analyze
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pgrman---&quot;&gt;方案三.　基于 pg_rman 的全备和增备( 推荐 )&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. postgresql.conf 的要求
    
        wal_level         = archive
        
        archive_mode      = on
        archive_command   = 'test ! -f /usr/local/pgsql/archivedir/%f &amp;amp;&amp;amp; cp %p /usr/local/pgsql/archivedir/%f'
        
        log_destination   = 'csvlog'
        logging_collector = on
        log_directory     = '/usr/local/pgsql/logs'
    
    
    2. 初始化备份目录
    
        pg_rman init -B /mydata/pgbackup -D /usr/local/pgsql/data
        // -B 指定一个空的备份目录
        // -D 指定原数据目录
    
    
    3. 先来做一次全量备份
    
        pg_rman backup \
            -B /mydata/pgbackup \
            -D /usr/local/pgsql/data \
            -b full \
            -s -Z -C \
            --keep-data-days=10 \
            --keep-arclog-files=20 \
            --keep-arclog-days=10 \
            --keep-srvlog-files=20 \
            --keep-srvlog-days=10 \
            -h 127.0.0.1 -p 5432 -U postgres -d deepnote
        // -b full              表示是全备份
        // -s                   表示服务日志也要备份
        // -Z                   表示备份要压缩
        // -C                   表示要检查检查点
        // --keep-data-days=10  表示这份全备要保持10天
        
        pg_rman show -B /mydata/pgbackup
        // 结果 :
            ============================================================================
            Start                Time   Total    Data     WAL     Log  Backup   Status  
            ============================================================================
            2017-02-20 21:02:54    0m    34MB    ----    33MB   1023B  4046kB   DONE
        // 根据这个时间(正是这次全备)，状态是DONE，说明全备成功
        
        pg_rman validate -B /mydata/pgbackup
        // 每次做完一次备份( 不管是全备还是增备 )，都必须做校验
        
        pg_rman show -B /mydata/pgbackup
        // 结果 :
            ============================================================================
            Start                Time   Total    Data     WAL     Log  Backup   Status  
            ============================================================================
            2017-02-20 21:02:54    0m    34MB    ----    33MB   1023B  4046kB   OK
        // 根据这个时间(正是刚才的全备)，状态从原来的DONE变成了OK，说明校验成功
    
    
    4. 再来做一次增量备份
        
        pg_rman backup \
            -B /mydata/pgbackup \
            -D /usr/local/pgsql/data \
            -b incremental \
            -s -Z -C \
            --keep-data-days=10 \
            --keep-arclog-files=20 \
            --keep-arclog-days=10 \
            --keep-srvlog-files=20 \
            --keep-srvlog-days=10 \
            -h 127.0.0.1 -p 5432 -U postgres -d deepnote
        
        pg_rman show -B /mydata/pgbackup
        // 结果 :
            ============================================================================
            Start                Time   Total    Data     WAL     Log  Backup   Status  
            ============================================================================
            2017-02-20 21:05:49    0m    ----   492kB    33MB      0B   102kB   DONE
            2017-02-20 21:02:54    0m    34MB    ----    33MB   1023B  4046kB   OK
        // 从 Total 字段，可以看出哪份是全备，哪份是增备
        
        pg_rman validate -B /mydata/pgbackup
        // 每次做完一次备份( 不管是全备还是增备 )，都必须做校验
        
        pg_rman show -B /mydata/pgbackup
        // 结果 :
            ============================================================================
            Start                Time   Total    Data     WAL     Log  Backup   Status  
            ============================================================================
            2017-02-20 21:05:49    0m    ----   492kB    33MB      0B   102kB   OK
            2017-02-20 21:02:54    0m    34MB    ----    33MB   1023B  4046kB   OK
        // 看到刚才的增备，状态从DONE变成了OK，说明这份增备也校验成功
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pgrman&quot;&gt;四.　基于 pg_rman，如何删除不想要的备份&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    在进行全备和增备的时候，参数 --keep-data-days 表示该全备(or增备)的有效期
    然而可能等不及过期就想删掉某些备份，我们知道强迫症患者有时候是很可怕的 &amp;gt; &amp;lt;
    
    
    // 假设此时 pg_rman show -B /mydata/pgbackup 的结果是这样的 :
        ============================================================================
        Start                Time   Total    Data     WAL     Log  Backup   Status  
        ============================================================================
        2017-02-20 21:13:51    0m    ----   336kB    33MB      0B    87kB   OK
        2017-02-20 21:12:05    0m    ----   287kB    33MB      0B    84kB   OK
        2017-02-20 21:09:25    0m    34MB    ----    33MB      0B  4047kB   OK
        2017-02-20 21:05:49    0m    ----   492kB    33MB      0B   102kB   OK
        2017-02-20 21:02:54    0m    34MB    ----    33MB   1023B  4046kB   OK
    // 此时有两条备份线 :
    // 备份线1 : 2017-02-20 21:02:54(全)  --&amp;gt;  2017-02-20 21:05:49(增)
    // 备份线2 : 2017-02-20 21:09:25(全)  --&amp;gt;  2017-02-20 21:12:05(增)  --&amp;gt;  2017-02-20 21:13:51(增)
    
    
    pg_rman delete 2017-02-20 21:13:51 -B /mydata/pgbackup
    // 执行完再用show命令看看会发生什么 :
        ============================================================================
        Start                Time   Total    Data     WAL     Log  Backup   Status  
        ============================================================================
        2017-02-20 21:13:51    0m    ----   336kB    33MB      0B    87kB   OK
        2017-02-20 21:12:05    0m    ----   287kB    33MB      0B    84kB   OK
        2017-02-20 21:09:25    0m    34MB    ----    33MB      0B  4047kB   OK
    // 特别注意一下 delete 参数的含义 : 要恢复到这个时刻，哪些备份是不必要的
    // 所以，我要恢复到 2017-02-20 21:13:51，只要前三份备份就够了
    // 即， 21:02:54那个全备 和 21:05:49那个增备，没有也不妨碍
    
    
    pg_rman show timeline -B /mydata/pgbackup
    // 结果 :
        ============================================================
        Start                Mode  Current TLI  Parent TLI  Status  
        ============================================================
        2017-02-20 21:13:51  INCR            3           0  OK
        2017-02-20 21:12:05  INCR            3           0  OK
        2017-02-20 21:09:25  FULL            3           0  OK
    // show timeline 能更方便观察时间线和全备增备
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pgrman-1&quot;&gt;五.　基于 pg_rman，如何恢复到指定时间&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 假设此时的 pg_rman show -B /mydata/pgbackup 的结果是这样的 :
        ============================================================================
        Start                Time   Total    Data     WAL     Log  Backup   Status  
        ============================================================================
        2017-02-21 08:56:51    0m    ----   509kB    67MB   3118B   156kB   OK
        2017-02-20 21:13:51    0m    ----   336kB    33MB      0B    87kB   OK
        2017-02-20 21:12:05    0m    ----   287kB    33MB      0B    84kB   OK
        2017-02-20 21:09:25    0m    34MB    ----    33MB      0B  4047kB   OK
    
    
    // 比如我要恢复到 2017-02-20 21:13:00 这个时刻，怎么办 ?
    // 2017-02-20 21:13:00　属于　2017-02-20 21:12:05　和　2017-02-20 21:13:51　之间
    // 即需要使用如下三份备份 :
    // 　　2017-02-20 21:09:25　这个全量备份
    // 　　2017-02-20 21:12:05　这个增量备份
    // 　　2017-02-20 21:13:51　这个增量备份
    
    
    // 注意 :
    // 我的表空间，x_log都在数据目录下，即 /usr/local/pgsql/data
    // 我的wal段文件存储目录             /usr/local/pgsql/archivedir
    
    
    pg_ctl stop -m fast -D /usr/local/pgsql/data
    // 注意，在恢复数据前，最好先关闭服务，且使用 -m fast模式为佳
    // 而且最好把原来的数据目录先备份一下
    
    
    pg_rman restore \
        --recovery-target-time &quot;2017-02-20 21:13:00&quot; \
        -B /mydata/pgbackup \
        -D /usr/local/pgsql/data
    // 恢复到目标时间
    
    
    vi /usr/local/pgsql/data/recovery.conf
    // 结果 :
        # recovery.conf generated by pg_rman 1.2.11
        restore_command = 'cp /usr/local/pgsql/archivedir/%f %p'
        recovery_target_time = '2017-02-20 21:13:00'
        recovery_target_timeline = '4'
    // 没错
    
    
    最后再次启动服务，会发现数据不是最新的(确实是&quot;2017-02-20 21:13:51&quot;这份备份截止时的)
    // 最后不要忘了恢复后执行一下 vacuum 或 analyze
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 14 Feb 2017 01:51:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/14/pg-backup/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/14/pg-backup/</guid>
        
        
        <category>Postgresql</category>
        
      </item>
    
      <item>
        <title>全文搜索 -- 从 Elk 转到 Postgres</title>
        <description>&lt;p&gt;自己做个APP玩，里面有个中文文章搜索的功能 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    a. 文章有标题，标签，引用，正文等字段
    b. 根据用户输入的一些关键词，对不同字段给予不同的匹配权重，搜索出综合匹配度最高的若干篇文章
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;原先是用Elasticsearch，通过 ik中文分词插件 来做的，地址是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    https://340starobserver.github.io/2016/10/03/Elasticsearch-IK/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然Elasticsearch的效率和稳定性不强，一直在寻找替代品.&lt;/p&gt;

&lt;p&gt;偶然上个月参加”DbGeek南京站”的活动时，听见德哥给旁边一个DBA安利pg，发现它恰巧是我一直在寻找的宝具啊&lt;/p&gt;

&lt;h3 id=&quot;scws--zhparser&quot;&gt;一.　插件 SCWS &amp;amp; zhparser&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    scws 按照官网的来装就行，zhparser按照github上的来装就行
    
    装完以后 :
    
    psql -h 127.0.0.1 -p 5432 -d deepnote -U postgres
    // 我这里的数据库名字叫 deepnote
    // 注意，使用超级用户登入，否则下面创建extension会失败
    
    create extension zhparser;
    create text search configuration chinese (parser = zhparser);
    alter text search configuration chinese add mapping for n,v,a,i,e,l with simple;
    // 创建了名为 chinese 的文本搜索配置
    
    select to_tsvector('chinese','年轻人还是要提高自己的姿势水平');
    // 测试一下分词的效果
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;二.　创建文章表&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    create table note (
        note_id uuid not null,
        title   varchar(128) not null,
        tags    varchar(64),
        refs    text,
        feel    text,
        primary key(note_id)
    );
    // 创建一个文章表，为了说明问题，只设了编号+标题+标签+引用+正文这些字段
    // 然后准备一些像样的数据弄进去
    
    
    alter table note add column textunite tsvector;
    update note set textunite = setweight(to_tsvector('chinese',title), 'A') ||
        setweight(to_tsvector('chinese',tags) , 'B') ||
        setweight(to_tsvector('chinese',refs) , 'D') ||
        setweight(to_tsvector('chinese',feel) , 'C');
    // 添加新的一列，并使用这个单独的一列来做文本搜索( 相比多列，单列查得更快一些 )
    // 注意，这个新列 = 标题标签正文等字段的加权综合
    // 注意，权重只有ABCD四种值，且 A &amp;gt; B &amp;gt; C &amp;gt; D
    
    
    create index note_textunite_idx on note using gin(textunite);
    // 创建 gin索引，来加速全文搜索
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;三.　查询测试&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    select ts_rank_cd(textunite, query, 32) as score, title 
        from note, to_tsquery('chinese','华夏文明|(商鞅 &amp;amp; 战国)') query 
        where query @@ textunite 
        order by score desc limit 3;
    // 根据输入的一些关键词的组合，查出综合匹配度最高的前三篇文章
    // 参数中的32表示最终得分 score = 原得分/(原得分+1)，即进行归一化        
    // 其结果形如 :
      score   |           title            
    ----------+----------------------------
     0.545455 | 失才亡魏
     0.285714 | 卫鞅三说秦孝公
     0.166667 | 振聋发聩的《谏逐客书》
     0.119128 | 认知中国原生文明的基本理念

    // 权值的分配有待研究
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 10 Feb 2017 21:30:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/10/pg-zhtextsearch/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/10/pg-zhtextsearch/</guid>
        
        
        <category>Postgresql</category>
        
      </item>
    
      <item>
        <title>Mysql - 全备份 &amp; 增量备份 &amp; 恢复</title>
        <description>&lt;p&gt;本篇讲述mysql的日常备份，包括 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 逻辑备份 : 全备份 + 增量备份  
    2. 物理备份 : 直接把数据目录和日志目录全拷贝放到安全的地方  
    3. 恢复  
    4. 自动化脚本  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mysqldump--mysqlbinlog&quot;&gt;方案一.　mysqldump全备 + mysqlbinlog增备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 该方案适合小数据量，且会锁表，只建议在业务低峰时使用  

    首先，确保配置文件中有这一项 :  
    [mysqld]  
    log_bin = /var/log/mysql/mysql-bin.log  
        // 最好让这个日志与数据库数据目录处于不同的硬盘上  
        // 在上述日志目录下，发现此时最新的日志文件的名字是 mysql-bin.000002  
    
    
    先进行一次全备 :  
    mysqldump \  
        --single-transaction \  
        --flush-logs \  
        --master-data=2 \  
        --triggers \  
        --routines \  
        university -u root -p &amp;gt; university-20170125.sql  
            // 把 university 这个库进行备份  
            // 由于有了 --triggers   这个参数，该库相关的触发器也被备份  
            // 由于有了 --routines   这个参数，该库相关的存储过程也被备份  
            // 由于有了 --flush-logs 这个参数  
            // 　　会在上述日志目录下生成一个新的日志文件mysql-bin.000003  
            // 　　且这个新的mysql-bin.000003便是之后拿来做增量恢复的  
    
    
    在这次全备完成后，我们对该库的数据做一些更改，来模拟生产环境下来自客户端的读写请求  
    
    
    再进行增备 :  
        把 mysql-bin.000003 这个增量日志，拷贝到安全的地方  
        // 通常，在生产环境下，建议每隔一小时，便对这个增量日志进行备份  
        // 这件事做得越勤，增量日志备份　与　实际最新数据　的差距便越小，一旦发生事故，损失也就越小  
    
    
    然后，我们模拟一次事故( 进行了一些误操作，导致数据被破坏 )  
    
    
    接下来我们恢复数据 ：  
        事故之前的最近数据 = 最近全备 + 该全备之后的最新增量日志  
        首先，要把该库清空  
        然后 :  
        mysql -u root -p university &amp;lt; university-20170125.sql  
            // 导入最近的全备  
        mysqlbinlog mysql-bin.000003 | mysql -u root -p  
            // 导入该全备之后的最新增量日志  
            // 注意，此处的 mysql-bin.000003 一定不能是日志目录下的运行时日志  
            // 　　　而是在事故发生前就拷贝到安全地方的最新的那份  
            // 　　　( 因为运行时日志已经由于误操作的影响而被污染了 )  
            // 　　　( 而且因为每隔一小时就备份一次增量日志，故取最新的那份 )  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;innobackupex--innobackupex&quot;&gt;方案二.　 innobackupex全备 + innobackupex增备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 该方案适合大数据量，不会锁表  
    
    需要安装 xtrabackup :  
        源码编译，按官网来就行  
        然后将 /usr/local/xtrabackup/bin 添加到PATH中  
    
    
    先进行一次全备 :  
    innobackupex \  
        --defaults-file=YourPath/mysqld.cnf \  
        --host=127.0.0.1 --port=3306 \  
        --user=root --password=xxxxxx /home/seven/try/test  
            // 进行全备份  
            // 备份到/home/seven/try/test这个目录下，会产生一个以时间戳为名字的目录  
            // 注意，强烈推荐像这样把所有库一起备份  
            // 　　否则单单备份某个库，即mysql系统本身的一些库没有被备份的话  
            // 　　之后恢复的时候，把数据目录一删，会导致恢复后无法读出数据的  


    在这次全备完成后，我们对数据做一些更改，来模拟生产环境下来自客户端的读写请求  
    
    
    再进行第一次增备 :  
    innobackupex \  
        --incremental-basedir=/home/seven/try/test/2017-01-25_23-20-48 \  
        --incremental /home/seven/try/test \  
        --host=127.0.0.1 --port=3306 \  
        --user=root --password=xxxxxx  
            // 其中，--incremental-basedir 是刚才全备时产生的目录  
            // 其中，--incremental         是增量存放的目录，同样会产生一个以时间戳为名字的目录  
            // 注意，--incremental 参数后面没有等号  
    
    
    在这次增备完成后，我们再对数据做一些更改  
    
    
    然后我们进行第二次增备 :  
        // 由于这次增备是在上一次增备基础上的，故 --incremental-basedir要填上一次增量产生的时间戳目录  
        // 勤于增备，每小时一次为佳  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/static/img/3.png&quot; alt=&quot;全备份的checkpoints&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    可以看到 :  
        增量1.from_lsn = 全备 .to_lsn  
        增量2.from_lsn = 增量1.to_lsn  
        // 说明上述操作正常  
    
    
    然后，我们模拟一次事故( 进行了一些误操作，导致数据被破坏 )  
    
    
    &amp;lt; 接下来，我们进行恢复 &amp;gt;  
    
    // 注意，执行恢复之前，强烈建议先关闭mysql  
    
    首先，要清空mysql的数据目录( 保险起见，在清空前，把该目录压缩拷贝到安全的地方 )  
        // 注意，清空数据目录，意味着mysql自己的系统库(保存着用户信息和表信息之类)也会被删掉  
        // 注意，所以，我前面推荐不要单单备份某个库，而是全部一起备份  
    
    然后 :  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_1  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_2  
    ...  
    ...  
    innobackupex --apply-log --use-memory=64M --redo-only base_dir --incremental-dir=incre_dir_N-1  
    innobackupex --apply-log --use-memory=64M base_dir --incremental-dir=incre_dir_N  
        // base_dir 是之前全备份时产出的那个目录  
        // 假设你在那次全备后，做了N次增备，它们各自的产出目录分别是 incre_dir_1 ~ incre_dir_N  
        // 注意，最后对 incre_dir_N 操作的时候，是没有 --redo-only 这个参数的  
    
    然后 :  
    innobackupex --apply-log --use-memory=64M base_dir  
    innobackupex --copy-back base_dir  
    
    最后 :  
    chown -R mysql:mysql /var/lib/mysql/*  
        // 把mysql数据目录下的所有文件，全部改成mysql:mysql所属  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;三.　将备份与恢复脚本化&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // 选用方案二进行脚本化( 每天一个以当天日期为名的新目录，里面存放当天的一次全备和若干次增备 )  


    3-1. 全备脚本 backup_full.sh  
    // 该脚本会以当天日期建一个新目录，并把产生的全备目录放入该日期目录中
    // 用法 : ./backup_full.sh
    
        #!/bin/sh
        
        # do Full-Backup for mysql
        # ( suggest that only root can rwx this file )
        
        # here, define your conf
        mysql_conf_file=/etc/mysql/mysql.conf.d/mysqld.cnf
        backup_dir=/mydata/mysqlbackup
        host=127.0.0.1
        port=3306
        user=root
        passwd=xxxxxx
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # every day has a directory
        today_dir=${backup_dir}/$(date +%Y%m%d)
        if [ -d $today_dir ]; then
        	echo &quot;$today_dir exists, it will be cleaned before full-backup&quot;
        	rm -rf ${today_dir}/*
        	echo &quot;$today_dir clean success&quot;
        fi
        
        # exec full-backup
        innobackupex \
        	--defaults-file=$mysql_conf_file \
        	--host=$host --port=$port \
        	--user=$user --password=$passwd $today_dir
        echo &quot;&amp;gt;_&amp;lt; successfully full-backup to $today_dir&quot;
    
    
    3-2. 增备脚本 backup_increment.sh  
    // 该脚本会自动在备份目录下，寻找文件名最大(即日期距今最近)的那个目录
    // 然后在那个目录下找到最近的一次备份，在那基础上做一次增备
    // 用法 : ./backup_increment.sh
    
        #!/bin/sh
        
        # do Increment-Backup for mysql
        # ( suggest that only root can rwx this file )
        
        # here, define your conf
        backup_dir=/mydata/mysqlbackup
        host=127.0.0.1
        port=3306
        user=root
        passwd=xxxxxx
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # recent_dir is like 'backup_dir/20170126'
        sub_dir=$(ls -lh $backup_dir | awk '{word=$9}END{print word}')
        recent_dir=${backup_dir}/$sub_dir
        
        # base_dir   is like 'backup_dir/20170126/2017-01-26_16-24-21'
        # 	if only exists 1 full-backup, use it
        # 	if exists 1 full-backup + n increment-backup, use the newest increment-backup
        sub_dir=$(ls -lh $recent_dir | awk '{word=$9}END{print word}')
        base_dir=${recent_dir}/$sub_dir
        
        # check whether already exists full-backup
        if [ ${#sub_dir} -eq 0 ]; then
        	echo &quot;!-- please do full-backup before incre-backup&quot;
        	exit
        fi
        
        # exec increment-backup
        innobackupex \
        	--incremental-basedir=$base_dir \
        	--incremental $recent_dir \
        	--host=$host --port=$port \
        	--user=$user --password=$passwd
        echo &quot;&amp;gt;_&amp;lt; successfully incre-backup to $recent_dir&quot;
    
    
    3-3. 恢复脚本 restore.sh  
    // 该脚本根据用户给定的日期目录，把那个目录中的首次全备和之后的若干次增备，整合起来，然后恢复
    // 用法 : ./restore.sh /mydata/mysqlbackup/20170215
    
        #!/bin/sh
        
        # do restore for mysql
        # ( 1. suggest that only root can rwx this file )
        # ( 2. stop mysql before restore )
        
        # here, define your conf
        mysql_data_dir=/var/lib/mysql
        mysql_before_restore_path=/mydata/mysqlbefore
        restore_buffer_size=64M
        export PATH=/usr/local/xtrabackup/bin:$PATH
        
        # check parameters
        restore_dir=$1
        if [ ${#restore_dir} -eq 0 ]; then
        	echo &quot;!-- You must give the restore_dir, such as ./restore.sh /backup/20170126&quot;
        	exit
        fi
        
        # print your parameters
        echo &quot;Your settings are :&quot;
        echo &quot;\tmysql_data_dir       : $mysql_data_dir&quot;
        echo &quot;\tmysql_before_restore : $mysql_before_restore_path&quot;
        echo &quot;\trestore_buffer_size  : $restore_buffer_size&quot;
        echo &quot;\trestore_dir          : $restore_dir&quot;
        
        num=$(ls -lh $restore_dir | awk 'BEGIN{i=-1}{i+=1}END{print i}')
        base_dir=${restore_dir}/$(ls -lh $restore_dir | awk 'BEGIN{i=0}{if(i==1){a=$9} i+=1}END{print a}')
        i=0
        ls -lh $restore_dir | while read line
        do
        	sub_dir=$(echo $line | awk '{word=$9}END{print word}')
        	cur_dir=${restore_dir}/$sub_dir
        	if [ $i -eq 0 ]; then
        		:
        	elif [ $i -eq 1 ]; then
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			--redo-only $base_dir
        	elif [ $i -lt $num ]; then
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			--redo-only $base_dir \
        			--incremental-dir=$cur_dir
        	else
        		innobackupex \
        			--apply-log --use-memory=$restore_buffer_size \
        			$base_dir \
        			--incremental-dir=$cur_dir
        	fi
        	i=$(($i+1))
        done
        
        cd ${mysql_data_dir}/../
        dirname=$(echo $mysql_data_dir | awk -F '/' '{print $4}')
        zip -r ${mysql_before_restore_path}/$(date +%Y%m%d).zip $dirname
        rm -rf $mysql_data_dir/*
        
        innobackupex --apply-log --use-memory=$restore_buffer_size $base_dir
        innobackupex --copy-back $base_dir
        
        chown -R mysql:mysql ${mysql_data_dir}/*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 25 Jan 2017 22:09:00 +0800</pubDate>
        <link>http://localhost:4000/2017/01/25/Mysql-Backup&Restore/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/01/25/Mysql-Backup&Restore/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>mongo监控命令与工具 </title>
        <description>&lt;h2 id=&quot;mongodb&quot;&gt;学习笔记 – mongodb监控&lt;/h2&gt;

&lt;h3 id=&quot;explain-&quot;&gt;法一.　使用　explain 来分析语句执行情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    例如 db.your_collection.find({ x : 123, y : 456 }).explain(&quot;allPlansExecution&quot;)，查看你的语句的工作情况 :  
    
    比如实际用了哪个索引来查  
    比如扫描了多少文档  
    ...  
    
    explain 也常用来测试比较多个索引方案的优劣  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;法二.　慢日志&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    不推荐在配置文件中设置，而是推荐在mongo-shell中动态地设置（一般需要测试的时候动态地开启，测试完后及时关闭）  
    
    db.setProfilingLevel( profile, slowms )  
        // 第一个参数表示慢日志的级别，取值是 0 1 2  
            profile=0  表示不记录慢日志  
            profile=1  表示只记录慢日志  
            profile=2  表示所有日志都记录  
        // 第二个参数表示慢日志的时间阀值，单位是毫秒  
    
    db.getProfilingStatus()  
        // 查看当前慢日志的配置信息，比如我的结果是 :  
        // { &quot;was&quot; : 0, &quot;slowms&quot; : 100 }  
        // 它说明目前 profile=0 &amp;amp; slowms=100  
    
    开启慢日志后，在当前库下就会出现system.profile这个collection  
        // 注意，你在哪个库下面开启慢日志，就只有那个库会有慢日志，每个开启慢日志的库下面都会有system.profile这个collection  
        // 注意，如果你在配置文件里设置慢日志的话，会导致每个库都开启慢日志  
    
    你可以查询当前库下的system.profile集合，获取你想要的慢日志  
        // 因为不同版本的mongo，这个集合里的document的字段数目和名称略有不同  
        // 推荐你用 db.system.profile.find().limit(2).sort({ ts : -1 }).pretty() 查出最近的2条慢日志  
        // 看看具体有哪些字段，就知道怎么写你想要的查询了  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;法三.　查看最近15分钟内的服务状态&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    db.serverStatus()  
        // 必须在admin库下，才能使用这条命令  
        // 举个例子，我只打印出部分信息，db.serverStatus()['extra_info']，结果是 :  
                
        {  
            &quot;note&quot;             : &quot;field vary by platform&quot;,  
            &quot;heap_usage_bytes&quot; : 62236488,  
            &quot;page_faults&quot;      : 24  
        }  
                
        // 其中 heap_usage_bytes 表示最近15分钟内，内存中的热数据占用的字节数  
        // 其中 page_faults      表示最近15分钟内，缺页中断的次数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongodb-mongostat&quot;&gt;法四.　使用mongodb自带的 mongostat&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    该脚本位于mongodb的安装目录的bin目录下  
    举个例子 :  
        
    &amp;gt; mongostat \  
    &amp;gt; --host host:port \  
    &amp;gt; --username admin库的用户 \  
    &amp;gt; --password admin库的密码 \  
    &amp;gt; --authenticationDatabase admin  
        
    注意，authenticationDatabase这个参数必须是admin  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;io&quot;&gt;法五.　查看当前系统的IO情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    iostat -x 1  
        // 每秒输出一次  
        // 注意，它是linux-shell下执行的，并不是mongo-shell里的  
        
    示例输出 :  
    Linux 4.2.0-30-generic (localhost) 	2016年11月20日 	_x86_64_	(4 CPU)  
    avg-cpu:  %user   %nice %system %iowait  %steal   %idle  
                6.37    0.01    1.74    0.92    0.00   90.96  
    Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util  
    sda               0.10     1.17    1.98    1.31    42.79   119.86    98.73     0.08   24.54   16.75   36.27   4.66   1.54  
        // 关注几个数据 :  
        // %iowait  是指CPU等待IO的比例  
        // %idle    是指CPU空闲的比例  
        // %util    是指设备（上述结果中可以看到是sda这块硬盘）在这一秒内的IO带宽的使用百分比  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongo-shell-benchrun&quot;&gt;法六.　使用mongo-shell自带的 benchRun&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    res = benchRun({  
        host        : '地址:端口',  
        username    : 'admin库的用户名',  
        password    : 'admin库的密码',  
        db          : '你要测试的库名',  
        ops         : [  
            {  
                ns  : '你要测试的库名.集合名',  
                op  : 'insert',  
                doc : { 'x' : { '#RAND_INT' : [ 0, 100 ] } }  
            }  
        ],  
        parallel    : 20,  
        seconds     : 5  
    })  
    注意，benchRun需要在admin库下才能执行  
    参数 parallel 是指我要用多少个线程（连接）去并发地插入，注意它并不是说每秒20个并发，因为每个线程每秒可以完成许多次插入  
    参数 seconds  是指这个benchRun要执行多长时间  
        
    返回结果 :  
    {  
        &quot;note&quot;                       : &quot;values per second&quot;,  
        &quot;errCount&quot;                   : NumberLong(0),  
        &quot;trapped&quot;                    : &quot;error: not implemented&quot;,  
        &quot;insertLatencyAverageMicros&quot; : 11.217961300363536,  
        &quot;totalOps&quot;                   : NumberLong(344396),  
        &quot;totalOps/s&quot;                 : 68697.5910483047,  
        &quot;findOne&quot;                    : 0,  
        &quot;insert&quot;                     : 68697.5910483047,  
        &quot;delete&quot;                     : 0,  
        &quot;update&quot;                     : 0,  
        &quot;query&quot;                      : 0,  
        &quot;command&quot;                    : 0  
    }  
    注意，上述结果中的数值都是每秒平均值  
    例如insert=68697 是指每秒执行了这么多次插入  
    例如errCount     是指每秒的平均错误数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mtools-&quot;&gt;法七.　使用 mtools 工具&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mtools最主要的功能是用来分析mongodb的日志  
    它的github的地址是 : https://github.com/rueckstiess/mtools  
    使用说明文档 地址是 : https://github.com/rueckstiess/mtools/wiki  
    
    最常用的是三个模块 :  
    mlogfilter   :  根据时间对日志切片，慢日志过滤，日志转json  
    mloginfo     :  日志统计  
    mplotqueries :  根据日志绘图  
    
    列举一些命令 :  
    
    
    &amp;lt; 7-1. mlogfilter   模块 &amp;gt;  
    
        mlogfilter xx.log --namespace A库.B集合 --slow 100 --json | mongoimport \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --username 你想要入库的库的拥有写权限的一个用户 \  
            --password 对应用户的密码 \  
            --db 你想要入库的库名 \  
            --collection 集合名  
            // 过滤慢日志（属于A库B集合的，超过100ms的），并以json的形式输出  
            // 把输出结果，通过管道，传给mongoimport，再导入到你想要的库里  
    
    
    &amp;lt; 7-2. mloginfo     模块 &amp;gt;  
    
        mloginfo xx.log --distinct  
            // 把日志分类（比如接受连接啊，关闭啊），统计各种分类下的数量  
        
        mloginfo xx.log --connections  
            // 统计日志中连接的来源情况   
        
        mloginfo xx.log --queries  
            // 统计日志中慢查询的分类  
    
    
    &amp;lt; 7-3. mplotqueries 模块 &amp;gt;  
    
        mplotqueries xx.log --group operation --output-file 1.png  
            // 绘制慢查询的散点分布图（按operation的类型分组）  
        
        mlogfilter xx.log --namespace 库名.集合名 | mplotqueries --output-file 2.png  
            // 绘制慢查询的散点分布图（只看指定的集合）  
        
        mlogfilter xx.log --operation query | mplotqueries --type histogram --bucketsize 3600 --output-file 3.png  
            // 过滤出查询的日志，绘制每3600秒里面查询操作的情况  
        
        mplotqueries log1 log2 ... --type rsstate --output-file 5.png  
            // 根据多个日志文件（复制集里的每个结点的日志），绘制出该复制集状态的变动  
    
    
    &amp;lt; 7-4. mgenerate    模块 &amp;gt;  
    
        比如我定义了一个模板文件 template.json，内容如下 :  
            {  
                &quot;user&quot;       : {  
                    &quot;first&quot;  : { &quot;$choose&quot; : [ &quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot; ] },  
                    &quot;last&quot;   : { &quot;$choose&quot; : [ &quot;AAA&quot;, &quot;BBB&quot;, &quot;CCC&quot; ] }  
                },  
                &quot;gender&quot;     : { &quot;$choose&quot; : [ &quot;male&quot;, &quot;female&quot; ] },  
                &quot;age&quot;        : &quot;$number&quot;,  
                &quot;address&quot;    : {  
                    &quot;street&quot; : { &quot;$string&quot; : { &quot;length&quot; : 10 } },  
                    &quot;code&quot;   : { &quot;$number&quot; : [ 10000, 99999 ] }  
                }  
            }  
        
        mgenerate template.json --stdout --pretty --number 1  
            // 指定模板文件，定义结果输出是屏幕，并以友好方式显示结果，指定生产的document的数量是一个  
            // 结果如下（因为定义了随机数，故每次结果可能不同）:  
                {  
                    &quot;gender&quot;     : &quot;male&quot;,  
                    &quot;age&quot;        : 14,  
                    &quot;user&quot;       : {  
                        &quot;last&quot;   :&quot;BBB&quot;,   
                        &quot;first&quot;  : &quot;aaa&quot;  
                    },  
                    &quot;address&quot;    : {  
                        &quot;code&quot;   : 10668,  
                        &quot;street&quot; : &quot;o9ZKibDmck&quot;  
                    }  
                }  
        
        mgenerate template.json \  
            --number 100 \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --database 库名 \  
            --collection 集合名 \  
            --processes 4  
            // 指定模板文件，指定产生100个document，并把结果写入mongodb（指定地址，端口，库名，集合名）  
            // processes参数是用来指定执行此操作的进程数（默认是CPU的数量）  
            // 注意，mgenerate，目前还不支持用户认证，所以 :  
            // 请在你的业务库之外，另建一个无需认证的库来做（因为mgenerate本身就是用来产生测试数据的）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 25 Nov 2016 04:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/25/Mongo-Monitor/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/25/Mongo-Monitor/</guid>
        
        
        <category>Mongodb</category>
        
      </item>
    
      <item>
        <title>linux磁盘管理</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一.　查看磁盘分区使用状况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    df  
        -l  只显示本地磁盘的（默认）  
        -a  显示所有文件系统的磁盘使用情况（包括0字节分区，往往0字节分区的数目还是比较多的）  
        
        -T  显示每个分区采用了什么文件系统  
        //  比如 /usr挂载点对应的分区 是ext4还是ext3  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  当不指定这两种参数的时候，默认显示的单位是KB  
        
        -t  指定只显示哪种文件系统（比如ext4）的分区  
        -x  指定不显示哪种文件系统（比如ext3）的分区  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;二. 统计文件大小&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    du  
        -b  以字节为单位  
        -k  以KB为单位  
        -m  以MB为单位  
        //  不指定单位的时候，默认是以KB为单位的  
        //  指定单位的时候，会可能有四舍五入的误差  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  注意，用 -b或-k或-m的时候，所有的文件都是一个单位  
        //  注意，用 -h或-H的时候，每个文件显示的单位可能是不一样的，它会对每个文件都按照最合适的单位来显示　
        
        -s  指定统计目标  
        //  不指定该参数的话，默认是统计当前目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;三. 主分区 &amp;amp; 扩展分区 &amp;amp; 逻辑分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 主分区 + 扩展分区　的总数不能超过4个  
    2. 扩展分区要么没有，要么只有一个  
    3. 扩展分区不能直接存储数据，必须在扩展分区的内部创建逻辑分区，才能存储数据  
    
    sudo fdisk -l  
    
        查看磁盘情况，例如我的结果的一部分是 :  
        
        Device     Boot      Start        End    Sectors   Size Id Type  
        /dev/sda1             2048  127999999  127997952    61G 83 Linux  
        /dev/sda2  *     128000000  130000895    2000896   977M 83 Linux  
        /dev/sda3        130000896  138000383    7999488   3.8G 82 Linux swap / Solaris  
        /dev/sda4        138002430 1305999359 1167996930   557G  5 Extended  
        /dev/sda5        138002432  650000383  511997952 244.1G 83 Linux  
        /dev/sda6        650002432 1162000383  511997952 244.1G 83 Linux  
        /dev/sda7       1162002432 1290000383  127997952    61G 83 Linux  
        /dev/sda8       1290002432 1297999871    7997440   3.8G 83 Linux  
        /dev/sda9       1298001920 1305999359    7997440   3.8G 83 Linux  
        
        // 可见，这是第一块磁盘（sda）的9个分区的情况  
        // 其中，sda1~sda4 是主分区&amp;amp;扩展分区  
        // 其中，sda5~sda9 是逻辑分区  
        // sda1,sda2,sda3是主分区， sda4是扩展分区，　且sda2是boot启动区  
        
        // fdisk -l 与 df -Th 命令结合着看 :  
        //     就可以知道我有哪些分区  
        //     每个分区是主分区，还是扩展分区，还是逻辑分区  
        //     每个分区对应哪个目录（即挂载点），各自的大小是多少  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;四.　服务器添加新磁盘&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    目标　：　加入 /dev/sdb 这块新硬盘  
    
    步骤 :  
    
    df -T -h   
        // 查看当前系统中有哪些分区，以及各分区的文件系统的类型  
        // 从返回结果可知当前的 /目录 的文件系统类型是ext4  
    
    sudo mkfs.ext4 /dev/sdb  
        // 把/dev/sdb这块硬盘格式化为ext4格式  
        // （我要在 /mydata　挂载硬盘，所以格式要和 /目录 保持一致）  
    
    sudo fdisk /dev/sdb  
        // 输入 m 查看帮助     
        // 我们先来创建一个主分区 :  
            输入 n 新建分区  
            输入 p 表明要创建的是主分区  
            输入 这个分区的编号是（我这里输入1）  
                （注意，主分区和扩展分区加起来最多4个，且编号为1~4）  
            输入 这个新分区的起始扇区位置（直接回车，使用默认值就行了）  
            输入 这个新分区的结束扇区位置
                （键入数值，该数值减去刚才的起始位置就是你这个新分区的容量）  
                （我们这里输入 +20G，表示从该分区的起始位置往后20G才是终结位置，即给该分区分配20G的空间）  
                （在这之后，还可以继续用 n p 来创建新的主分区）  
        // 我们再来创建一个扩展分区  
            输入 n 继续创建下一个分区  
            输入 e 创建一个扩展分区  
            输入 这个扩展分区的编号（我这里输入2）  
            输入 这个扩展分区的起始扇区位置（我这里输入系统提示的默认值）  
            输入 这个扩展分区的结束扇区位置（我这里输入系统提示的默认值）  
        // 我们再来创建逻辑分区（因为扩展分区并不能直接存储数据，需要在它内部创建逻辑分区）  
            输入 n 创建分区（可以看到现在只能创建主分区和逻辑分区了，因为扩展分区最多只有一个，且已经在上一步中被创建过了）  
            输入 l 创建一个逻辑分区  \
            输入 这个逻辑分区的编号（从5开始，因为1~4是给主分区和扩展分区用的）  
            输入 这个逻辑分区的起始扇区位置  
            输入 这个逻辑分区的终止扇区位置     
        // 输入 p 查看当前这块/dev/sdb磁盘的分区计划  
        // 最后输入 w 把上述制定的分区计划写入分区表  
            （注意，fdisk工具，只能给硬盘做MBR模式的分区）   
        // 例如，最后，我为/dev/sdb这块新硬盘的分区方案为 :  
            /dev/sdb1    主分区　　　　　　　　　　　　　编号=1    大小20G  
            /dev/sdb2    扩展分区　　　　　　　　　　　　编号=2    大小40G  
            /dev/sdb5    逻辑分区（从属于扩展分区）　　　编号=5    大小10G  
            /dev/sdb6    逻辑分区（从属于扩展分区）　　　编号=6    大小30G  
    
    mkdir /mydata  
    mkdir /mydata/pA  
    mkdir /mydata/pB  
    mkdir /mydata/pC  
        // 新建空目录用来挂载硬盘  
        // 其中， /mydata/pA 作为 /dev/sdb1　的挂载点  
        // 其中， /mydata/pB 作为 /dev/sdb5　的挂载点  
        // 其中， /mydata/pC 作为 /dev/sdb6　的挂载点  
        // 注意， 扩展分区不需要挂载点，因为扩展分区并不存储数据，而是它下面的若干逻辑分区需要各自的挂载点  
    
    sudo mount -t ext4 /dev/sdb1 /mydata/pA  
    sudo mount -t ext4 /dev/sdb5 /mydata/pB  
    sudo mount -t ext4 /dev/sdb6 /mydata/pC  
        // 进行挂载
        // 注意，mount命令是临时生效，如果想要永久生效，需要编辑 /etc/fstab  
    
    sudo vi /etc/fstab  
        // 添加 :  
        // /dev/sdb1    /mydata/pA    ext4    defaults    0    1  
        // /dev/sdb5    /mydata/pB    ext4    defaults    0    1  
        // /dev/sdb6    /mydata/pC    ext4    defaults    0    1  
    
    sudo shutdown -r now  
        // 重启  
    
    sudo fdisk -l  
        // 再次查看磁盘情况（有/dev/sdb1之类的就说明成功了）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;swap&quot;&gt;五.　如何给硬盘添加swap分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    第一步，建一个普通的分区（主分区or逻辑分区都行）  
    第二步，修改分区类型的16进制编码  
    第三步，格式化swap分区  
    第四步，启用swap分区  
    
    比方说，我要把 /dev/sdb7 这个分区做成swap分区  
    // 保证该分区已经被创建了，而且还没有被挂载  
    
    fdisk /dev/sdb  
        // 输入 t 来修改分区类型  
        // 输入 7 表示我要对 /dev/sdb7 做修改  
        // 输入 L 来查看各种分区类型对应的编号  
        // 输入 82 （82是swap类型的编号）  
        // 输入 w 来保存  
    
    mkswap /dev/sdb7  
        // 格式化交换分区  
        // 注意，它和格式化普通分区是有区别的，普通分区的格式化用的是mkfs命令  
    
    swapon /dev/sdb7  
        // 启用这个交换分区  
        // swapoff可以用来停用  
    
    vi /etc/fstab  
        // 添加 :  
        // /dev/sdb7    swap    swap    sw    0    0  
    
    重启生效  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 14 Nov 2016 23:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/14/Linux-Disk/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/14/Linux-Disk/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>mysql存储过程 &amp; 触发器</title>
        <description>&lt;p&gt;我把做App时候的一个存储过程（邀请注册）记录下来，以便之后不用再花时间研究它的格式了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    /*  
        procedure for regedit a new account  
        parameters  
        {  
        	usr        : the username you want to use  
        	pwd        : the password you want to use,and it is encoded to char(32) by md5  
        	registtime : the time when regedit  
        	invitor    : the username of person that he invited you to regedit a new account  
        	authcode   : the necessary code for regedit that you get from your invitor  
        	res        : 0 authcode is wrong;1 username has been used by others;2 transaction error;3 succeed  
        }  
        to make our deepnote environment good,we hope that our users are good readers,so we use invite regedit method  
        that is to say,if you want to regedit successfully,  
        A. you should get a right authcode or called invitecode  
        B. your username has not been used by others  
    */  
    
    drop procedure if exists regedit;  
    delimiter //  
    create procedure regedit (in usr varchar(16),in pwd char(32),in registtime int(11),in invitor varchar(16),in authcode char(32),out res tinyint(1))  
    begin  
        declare lastid int;  
        declare t_error int default 0;  
        declare continue handler for sqlexception set t_error=1;  
        
        start transaction;  
    	set res=0;  
    	if exists(select 1 from usertable where username=invitor and inviteauth=1 and invitecode=authcode limit 1)  
    	then  
    		if exists(select 1 from usertable where username=usr limit 1)  
    		then  
    			set res=1;  
    		else  
    			insert into usertable (username,password,birthtime) values(usr,pwd,registtime);  
    			set lastid=LAST_INSERT_ID();  
    			insert into classifytable (userid) values(lastid);  
    			set res=3;  
    		end if;  
    	end if;  
    	
    	if t_error=0 then  
            commit;  
            set res=3;  
        else  
            rollback;  
            set res=2;  
        end if;  
        
    end //  
    delimiter ;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;尝试用触发器的时候，踩过一些坑，这里记录一下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    drop trigger if exists check_sailors;
    delimiter //
    create trigger check_sailors after insert on Sailors for each row
    begin
    	if exists(select * from Sailors 
    		where master is not NULL and master=NEW.master 
    		group by master having count(*)&amp;gt;2)
    	then
    		delete from Sailors where sid = NEW.sid limit 1;
    	end if;
    end //
    delimiter ;
    
    -- mysql5.6 don't support {commit, start transaction, rollback} in trigger  
    -- mysql5.6 don't support 'referencing NEW as N'  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;对比一下 Postgresql 的存储过程，我写了一个转账的事务例子&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    create or replace function transfer(
    	sender bigint, receiver bigint, amount numeric(20,2)
    	) returns boolean AS $$
    begin
    	update customer set balance = balance - amount where id = sender;
    	update customer set balance = balance + amount where id = receiver;
    
    	if exists(select 1 from customer where id = sender and balance &amp;lt; 0.00 limit 1) then
    		rollback;
    	end if;
    
    	return True;
    	commit;
    end;
    $$ language plpgsql;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 10 Nov 2016 16:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/10/Mysql-Procedure/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/10/Mysql-Procedure/</guid>
        
        
        <category>Mysql</category>
        
      </item>
    
      <item>
        <title>iptables</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一. 总的命令格式&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                    table        command          chain          parameters        action  

    iptables        -t filter    -A(追加在表尾)     PREROUTING     -p tcp(协议)       -j ACCEPT  
                       nat       -I(追加在表头)     POSTROUTING    -s ip(源ip)           DROP(丢弃且不响应)  
                                 -D(删除一条)       INPUT          -d ip(宿ip)           REJECT(拒绝且会给客户端响应)  
                                 -L(列举)          OUTPUT         --sport sp            DNAT(修改宿地址)  
                                 -n               FORWARD        --dport dp            SNAT(修改源地址)  
                                 -F(清空)                         -m  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;iptables&quot;&gt;二.　初次启用 iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    systemctl stop firewalld  
    systemctl mask firewalld  
    
        centos 默认使用的是firewall，因此需要先关闭它  
    
    yum install iptables-services  
    
        安装iptables service  
    
    systemctl enable iptables  
    
        开机启动iptables-service  
    
    systemctl start iptables  
    
        启动iptables  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;etcsysconfigiptables&quot;&gt;三. 我的 /etc/sysconfig/iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    -A INPUT -i lo -j ACCEPT  
        允许本地访问  

    -A INPUT -p icmp -j ACCEPT  
        允许所有的ICMP协议的报文（即允许被ping）  

    -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT  
        允许已经建立的连接进行回包  


    
    -A INPUT -p tcp --dport 35628 -j ACCEPT  
        允许ssh（改了端口的ssh）被所有机器访问  
        
        

    -A INPUT -p tcp -s 10.47.86.0/24 --dport 9200 -m limit --limit 10/m --limit-burst 100 -j ACCEPT   
        允许 10.47.86.198/24 这个网段的机器访问这台机器的9200端口  
        （并发控制）9200端口的最大连接数是100，超过的话就限制每分钟只能10个连接  
        // 注意， -A 和 -I 都是追加一条规则，区别为 :  
        // -A 是追加在原有规则表的最后  
        // -I 是追加在原有规则表的开头  
    
    -A INPUT -p tcp --dport 9200 -j DROP  
        没有满足上述的并发控制的话，访问9200端口的请求就直接丢弃  
    
    -A OUTPUT -p tcp --sport 9200 -j ACCEPT  
        允许这台机器的9200端口，向任何机器返回数据  
        
        

    -A INPUT -p tcp --dport 8081:8089 -j ACCEPT  
        允许任何机器访问这台机器的8081~8089端口  
        


    -A INPUT -j REJECT  
        拒绝所有额外的数据包（无论什么协议的）  
        // 注意，必须是 -A，即在规则表的表尾；如果是 -I，则会导致所有应该接受的数据包也被拒绝掉  
        // 注意，一般的配置思路是accept的在表头，拒绝的次之  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;snat&quot;&gt;四. SNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写源地址（作用在PostRouting链上，即向外发出数据包的时候）  
     
    应用场景 ：  
     
        有一台HttpServer是A网段的，B网段的一台客户机想要访问A网段里的HttpSserver  
        需要在A网段和B网段之间架设一台nat服务器，通过iptables配置nat转发  
     
    具体做法 :  
     
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A POSTROUTING -p tcp -s B网段地址 -j SNAT --to A网段地址  
            然后执行 service iptables restart  
            
        3. 一定要确保客户机的网关地址，是这台nat服务器的地址  
            可以通过修改客户机的 /etc/sysconfig/network 来达到目的  
            否则的话，如果客户机的请求不巧发给了别的一台网关，那台网关上没有配置nat转发，就访问不了HttpServer了  
    
    // 这样一来，客户机就可以直接访问HttpServer（直接的意思是输入的url不变，就是HttpServer的地址）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;dnat&quot;&gt;五. DNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写宿地址（作用在PreRouting链上，即接收数据包的时候）  
    
    应用场景  :  
    
        同上，还是B网段的客户机想要访问A网段上的http服务  
        但是稍微做些改动，客户机不是直接去访问server的地址，而是去访问nat服务器的地址，nat服务器再做转发  
        // 即，客户机访问nat服务器，但是实际上数据包被偷偷转发给了A网段的server  
    
    具体做法  :  
    
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A PREROUTING -p tcp -d 与客户机相连的网卡地址 --dport 80 -j DNAT --to HttpServer地址:端口  
            然后执行 service iptables restart  
    
    // 这样一来，客户机就可以间接访问HttpServer（间接的意思是客户机并不访问HttpServer的地址，而是使用nat的地址做url）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 09 Nov 2016 18:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/09/Iptables/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/09/Iptables/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>用 rsync 来做主机间的数据同步</title>
        <description>&lt;h3 id=&quot;rsync-&quot;&gt;rsync 数据同步&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync可以用来在服务器之间 同步数据 or 备份数据  

一般linux上自动装了它，用了一下感觉很方便，记录一下以便日后再次用到  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsync&quot;&gt;一. 与rsync相关的目录结构&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync这种级别的服务，推荐让root管理员来管理，当然它的相关配置也推荐放在/root目录下面  


/root/rsyncd  

    # rsync的根目录  


/root/rsyncd/conf  

    # rsync服务的配置目录  

/root/rsyncd/conf/rsyncd.conf  

    # rsync的主配置文件  

/root/rsyncd/conf/rsyncd.secrets  

    # rsync的认证配置  

/root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  


/root/rsyncd/restful  

    # rsync服务的相关脚本目录  

/root/rsyncd/restful/start.sh  

    # rsync服务的启动脚本  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdconf&quot;&gt;二. 主配置文件 rsyncd.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pid file = /mydata/rsyncd/rsyncd.pid  

    # rsync的进程文件目录  

motd file = /root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  

log file = /mydata/rsyncd/rsyncd.log  

    # rsync的日志文件路径  

address = ******  

    # 这台服务器的ip  
    # 若仅在内部使用，请使用内网ip，否则使用公网ip  

port = 873  

    # 监听的端口  

hosts allow = *  

    # 允许的客户端的ip，*表示允许所有  

max connections = 5  

    # 最大连接数量  

uid = root  

gid = root  

use chroot = yes  

read only = yes  

    # 只读  
    # 若允许客户端上传同步数据，则可以设置 write only 或者 read write  

transfer logging = yes  

log format = %t %a %m %f %b  

syslog facility = local3  

timeout = 300  


[linkA]  

path = /mydata/rsyncd/test  

auth users = root  

list = yes  

ignore errors  

secrets file = /root/rsyncd/conf/rsyncd.secrets  

    # 上面这段配置是 linkA，同一台rsync服务器上可以配置多个这种东西，每个的同步目录不同  
    # path          表示linkA所指向的需要同步的目录  
    # auth users    表示同步这个目录下的文件，需要用哪个用户来认证  
    # list=yes      表示在用户登入后，可以看到这个目录下的文件列表；反之设置为no  
    # secrets file  表示该目录所需要的认证配置信息的路径  
    # 还可以配置 exclude = dir1/ dir2/，表示在这个目录下排除（不同步）这个两个子目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdsecrets&quot;&gt;三. 认证配置文件 rsyncd.secrets&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root:abc  

    # 格式为 用户:密码  
    # 注意，此处的用户需要是这台服务器上真实存在的用户  
    # 注意，此处的密码可以不是这个用户的密码（即可以任意）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdmotd&quot;&gt;四. 提示信息配置文件 rsyncd.motd&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;welcome to sync server &amp;gt;_&amp;lt;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;startsh&quot;&gt;五. 启动脚本 start.sh&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --daemon --config=/root/rsyncd/conf/rsyncd.conf  

    # 以后台方式启动  
    # 指定配置文件路径  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;六. 客户端操作&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --port 873 --list-only  root@xx.xx.xx.xx::linkA  

    # 列出服务器上linkA下面的资源  
    # 注意，需要指定端口  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP root@xx.xx.xx.xx::linkA mypath/  

    # 把服务器上linkA下面的资源同步到本机的 mypath目录  
    # 注意，此处不需要指定端口  
    # 注意，此处的参数 -a 是 archive mode  
    # 注意，此处的参数 -v 是 传输时的进度等信息  
    # 注意，此处的参数 -z 是 压缩传输  
    # 注意，此处的参数 -r 是 递归（递归同步linkA下面的子目录）  
    # 注意，此处的参数 -P 是 传输进度  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP --delete root@xx.xx.xx.xx::linkA mypath/  

    # 注意，比较上面一条命令，多了参数 --delete  
    # 它表示客户端的数据要与服务器上的完全一致  
    # 即如果同步之前，你的客户端的mypath目录下存在服务器上没有的文件，则同步的时候会自动删除它们  
    # 所以，使用这条命令的时候，请小心不要让你的客户端的同步目录下有其他重要数据  

Tip : 建议把客户端的同步命令放入crontab里，定期自动同步or备份  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 16:40:00 +0800</pubDate>
        <link>http://localhost:4000/2016/10/23/Rsync/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/23/Rsync/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
  </channel>
</rss>
