<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Principality Of 340号恒星观测员</title>
    <description>some technical blogs</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 29 Dec 2016 21:30:09 +0800</pubDate>
    <lastBuildDate>Thu, 29 Dec 2016 21:30:09 +0800</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>mongo监控命令与工具 </title>
        <description>&lt;h2 id=&quot;mongodb&quot;&gt;学习笔记 – mongodb监控&lt;/h2&gt;

&lt;h3 id=&quot;explain-&quot;&gt;法一.　使用　explain 来分析语句执行情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    例如 db.your_collection.find({ x : 123, y : 456 }).explain(&quot;allPlansExecution&quot;)，查看你的语句的工作情况 :  
    
    比如实际用了哪个索引来查  
    比如扫描了多少文档  
    ...  
    
    explain 也常用来测试比较多个索引方案的优劣  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;法二.　慢日志&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    不推荐在配置文件中设置，而是推荐在mongo-shell中动态地设置（一般需要测试的时候动态地开启，测试完后及时关闭）  
    
    db.setProfilingLevel( profile, slowms )  
        // 第一个参数表示慢日志的级别，取值是 0 1 2  
            profile=0  表示不记录慢日志  
            profile=1  表示只记录慢日志  
            profile=2  表示所有日志都记录  
        // 第二个参数表示慢日志的时间阀值，单位是毫秒  
    
    db.getProfilingStatus()  
        // 查看当前慢日志的配置信息，比如我的结果是 :  
        // { &quot;was&quot; : 0, &quot;slowms&quot; : 100 }  
        // 它说明目前 profile=0 &amp;amp; slowms=100  
    
    开启慢日志后，在当前库下就会出现system.profile这个collection  
        // 注意，你在哪个库下面开启慢日志，就只有那个库会有慢日志，每个开启慢日志的库下面都会有system.profile这个collection  
        // 注意，如果你在配置文件里设置慢日志的话，会导致每个库都开启慢日志  
    
    你可以查询当前库下的system.profile集合，获取你想要的慢日志  
        // 因为不同版本的mongo，这个集合里的document的字段数目和名称略有不同  
        // 推荐你用 db.system.profile.find().limit(2).sort({ ts : -1 }).pretty() 查出最近的2条慢日志  
        // 看看具体有哪些字段，就知道怎么写你想要的查询了  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;法三.　查看最近15分钟内的服务状态&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    db.serverStatus()  
        // 必须在admin库下，才能使用这条命令  
        // 举个例子，我只打印出部分信息，db.serverStatus()['extra_info']，结果是 :  
                
        {  
            &quot;note&quot;             : &quot;field vary by platform&quot;,  
            &quot;heap_usage_bytes&quot; : 62236488,  
            &quot;page_faults&quot;      : 24  
        }  
                
        // 其中 heap_usage_bytes 表示最近15分钟内，内存中的热数据占用的字节数  
        // 其中 page_faults      表示最近15分钟内，缺页中断的次数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongodb-mongostat&quot;&gt;法四.　使用mongodb自带的 mongostat&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    该脚本位于mongodb的安装目录的bin目录下  
    举个例子 :  
        
    &amp;gt; mongostat \  
    &amp;gt; --host host:port \  
    &amp;gt; --username admin库的用户 \  
    &amp;gt; --password admin库的密码 \  
    &amp;gt; --authenticationDatabase admin  
        
    注意，authenticationDatabase这个参数必须是admin  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;io&quot;&gt;法五.　查看当前系统的IO情况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    iostat -x 1  
        // 每秒输出一次  
        // 注意，它是linux-shell下执行的，并不是mongo-shell里的  
        
    示例输出 :  
    Linux 4.2.0-30-generic (localhost) 	2016年11月20日 	_x86_64_	(4 CPU)  
    avg-cpu:  %user   %nice %system %iowait  %steal   %idle  
                6.37    0.01    1.74    0.92    0.00   90.96  
    Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util  
    sda               0.10     1.17    1.98    1.31    42.79   119.86    98.73     0.08   24.54   16.75   36.27   4.66   1.54  
        // 关注几个数据 :  
        // %iowait  是指CPU等待IO的比例  
        // %idle    是指CPU空闲的比例  
        // %util    是指设备（上述结果中可以看到是sda这块硬盘）在这一秒内的IO带宽的使用百分比  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongo-shell-benchrun&quot;&gt;法六.　使用mongo-shell自带的 benchRun&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    举个例子 :  
    res = benchRun({  
        host        : '地址:端口',  
        username    : 'admin库的用户名',  
        password    : 'admin库的密码',  
        db          : '你要测试的库名',  
        ops         : [  
            {  
                ns  : '你要测试的库名.集合名',  
                op  : 'insert',  
                doc : { 'x' : { '#RAND_INT' : [ 0, 100 ] } }  
            }  
        ],  
        parallel    : 20,  
        seconds     : 5  
    })  
    注意，benchRun需要在admin库下才能执行  
    参数 parallel 是指我要用多少个线程（连接）去并发地插入，注意它并不是说每秒20个并发，因为每个线程每秒可以完成许多次插入  
    参数 seconds  是指这个benchRun要执行多长时间  
        
    返回结果 :  
    {  
        &quot;note&quot;                       : &quot;values per second&quot;,  
        &quot;errCount&quot;                   : NumberLong(0),  
        &quot;trapped&quot;                    : &quot;error: not implemented&quot;,  
        &quot;insertLatencyAverageMicros&quot; : 11.217961300363536,  
        &quot;totalOps&quot;                   : NumberLong(344396),  
        &quot;totalOps/s&quot;                 : 68697.5910483047,  
        &quot;findOne&quot;                    : 0,  
        &quot;insert&quot;                     : 68697.5910483047,  
        &quot;delete&quot;                     : 0,  
        &quot;update&quot;                     : 0,  
        &quot;query&quot;                      : 0,  
        &quot;command&quot;                    : 0  
    }  
    注意，上述结果中的数值都是每秒平均值  
    例如insert=68697 是指每秒执行了这么多次插入  
    例如errCount     是指每秒的平均错误数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mtools-&quot;&gt;法七.　使用 mtools 工具&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mtools最主要的功能是用来分析mongodb的日志  
    它的github的地址是 : https://github.com/rueckstiess/mtools  
    使用说明文档 地址是 : https://github.com/rueckstiess/mtools/wiki  
    
    最常用的是三个模块 :  
    mlogfilter   :  根据时间对日志切片，慢日志过滤，日志转json  
    mloginfo     :  日志统计  
    mplotqueries :  根据日志绘图  
    
    列举一些命令 :  
    
    
    &amp;lt; 7-1. mlogfilter   模块 &amp;gt;  
    
        mlogfilter xx.log --namespace A库.B集合 --slow 100 --json | mongoimport \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --username 你想要入库的库的拥有写权限的一个用户 \  
            --password 对应用户的密码 \  
            --db 你想要入库的库名 \  
            --collection 集合名  
            // 过滤慢日志（属于A库B集合的，超过100ms的），并以json的形式输出  
            // 把输出结果，通过管道，传给mongoimport，再导入到你想要的库里  
    
    
    &amp;lt; 7-2. mloginfo     模块 &amp;gt;  
    
        mloginfo xx.log --distinct  
            // 把日志分类（比如接受连接啊，关闭啊），统计各种分类下的数量  
        
        mloginfo xx.log --connections  
            // 统计日志中连接的来源情况   
        
        mloginfo xx.log --queries  
            // 统计日志中慢查询的分类  
    
    
    &amp;lt; 7-3. mplotqueries 模块 &amp;gt;  
    
        mplotqueries xx.log --group operation --output-file 1.png  
            // 绘制慢查询的散点分布图（按operation的类型分组）  
        
        mlogfilter xx.log --namespace 库名.集合名 | mplotqueries --output-file 2.png  
            // 绘制慢查询的散点分布图（只看指定的集合）  
        
        mlogfilter xx.log --operation query | mplotqueries --type histogram --bucketsize 3600 --output-file 3.png  
            // 过滤出查询的日志，绘制每3600秒里面查询操作的情况  
        
        mplotqueries log1 log2 ... --type rsstate --output-file 5.png  
            // 根据多个日志文件（复制集里的每个结点的日志），绘制出该复制集状态的变动  
    
    
    &amp;lt; 7-4. mgenerate    模块 &amp;gt;  
    
        比如我定义了一个模板文件 template.json，内容如下 :  
            {  
                &quot;user&quot;       : {  
                    &quot;first&quot;  : { &quot;$choose&quot; : [ &quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot; ] },  
                    &quot;last&quot;   : { &quot;$choose&quot; : [ &quot;AAA&quot;, &quot;BBB&quot;, &quot;CCC&quot; ] }  
                },  
                &quot;gender&quot;     : { &quot;$choose&quot; : [ &quot;male&quot;, &quot;female&quot; ] },  
                &quot;age&quot;        : &quot;$number&quot;,  
                &quot;address&quot;    : {  
                    &quot;street&quot; : { &quot;$string&quot; : { &quot;length&quot; : 10 } },  
                    &quot;code&quot;   : { &quot;$number&quot; : [ 10000, 99999 ] }  
                }  
            }  
        
        mgenerate template.json --stdout --pretty --number 1  
            // 指定模板文件，定义结果输出是屏幕，并以友好方式显示结果，指定生产的document的数量是一个  
            // 结果如下（因为定义了随机数，故每次结果可能不同）:  
                {  
                    &quot;gender&quot;     : &quot;male&quot;,  
                    &quot;age&quot;        : 14,  
                    &quot;user&quot;       : {  
                        &quot;last&quot;   :&quot;BBB&quot;,   
                        &quot;first&quot;  : &quot;aaa&quot;  
                    },  
                    &quot;address&quot;    : {  
                        &quot;code&quot;   : 10668,  
                        &quot;street&quot; : &quot;o9ZKibDmck&quot;  
                    }  
                }  
        
        mgenerate template.json \  
            --number 100 \  
            --host 127.0.0.1 \  
            --port 28001 \  
            --database 库名 \  
            --collection 集合名 \  
            --processes 4  
            // 指定模板文件，指定产生100个document，并把结果写入mongodb（指定地址，端口，库名，集合名）  
            // processes参数是用来指定执行此操作的进程数（默认是CPU的数量）  
            // 注意，mgenerate，目前还不支持用户认证，所以 :  
            // 请在你的业务库之外，另建一个无需认证的库来做（因为mgenerate本身就是用来产生测试数据的）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 25 Nov 2016 04:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/25/Mongo-Monitor/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/25/Mongo-Monitor/</guid>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>基于日志点的Mysql主从复制</title>
        <description>&lt;p&gt;本篇讲述我学习mysql基于二进制日志的复制&lt;/p&gt;

&lt;p&gt;我的环境是 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    主结点 : ipA:3306  
    从结点 : ipB:3306  
    
    // iptables已配置，允许访问3306端口  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;一. 在主结点上建立用来复制的用户&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    create user 'seven'@'%' identified by 'xxxxxx';  
    
        // 创建用户seven，并且是任何网段的（即slave可以是任何网段下的），用来作为复制的用户  
    
    grant replication slave on *.* to 'seven'@'%' identified by 'xxxxxx';  
    
        // 为这个用户授权，可以复制任何库的任何表  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;二. 备份主结点的数据&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mysqldump \  
        --single-transaction \  
        --master-data=2 \  
        --triggers \  
        --routines \  
        university -h localhost -u root -p &amp;gt; university.sql  
        
        // 导出university这个库  
        // 参数 --single-transaction 是用来保证事务完整性  
        // 参数 --master-data = 1    是表示在备份文件中不注销change-master命令  
        // 参数 --master-data = 2    是表示在备份文件中会注销change-master命令  
        // 参数 --triggers           是表示把触发器也导出  
        // 参数 --routines           是表示把存储过程也导出  

    more university.sql  
    
        // 查看导出的备份文件，里面有一行 -- CHANGE MASTER TO MASTER_LOG_FILE='bin.000002', MASTER_LOG_POS=120;  
        // 其中的 --              表示是注释，对应了刚才的 --master-data = 2 这个参数  
        // 其中的 MASTER_LOG_FILE 表示日志文件，会在之后用到  
        // 其中的 MASTER_LOG_POS  表示日志点，会在之后用到  
        // 注意，这两个值也可以通过　show master status\G; 来查看  
    
    把导出的这个备份文件拷到从结点上（可以使用sftp,scp等）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;三.　在每个从结点上恢复数据&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mysql -h localhost -u root -p university &amp;lt; university.sql  
    
        // 注意，事先要创建好university这个库，然后才能导入  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;change-master&quot;&gt;四. change master（在每个从结点上操作）&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    进入从结点的mysql  
    
    change master to master_host = 'ipA',  
        master_port = 3306,  
        master_user = 'seven',  
        master_password = 'xxxxxx',  
        master_log_file = 'bin.000002',  
        master_log_pos = 120;  
    
        // 参数 master_host     是主结点的地址  
        // 参数 master_user     是主结点上之前创建的用来复制的用户  
        // 参数 master_password 是主结点上之前创建的用来复制的用户的密码  
        // 参数 master_log_file 是上面提到的备份文件中的那一行里的日志文件  
        // 参数 master_log_pos  是上面提到的备份文件中的那一行里的日志点  
    
    start slave;  
        
        // 启动slave复制进程  
        // 啊，提示报错　The server is not configured as slave; fix in config file or with CHANGE MASTER TO  
        // 我的mysql版本是5.6，查资料说是5.7以后才能不需要改配置文件，没办法只好在配置文件里设置了  
        
        修改主结点的配置文件 :  
            log_bin       = /var/run/mysqld/bin.log  
            binlog_format = mixed   # 采用混合模式（state模式 &amp;amp; row模式 的混合）  
            server-id     = 10  
        
        修改从结点的配置文件 :  
            skip_slave_start = 1    # 启动从结点mysql的时候，不会自动启动复制进程，而是需要用start slave来手动启动  
            read_only        = 1    # 这个从结点是只读的  
            server-id        = 20   # 该值必须和主结点，以及其他从结点不同  
            // 注意，从结点不需要再配置log_bin了，因为只需要主结点一份就够了  
        
        重启主结点和从结点的mysql  
        
        再次执行change master命令，以及start slave命令  
    
    show slave status \G;  
    
        // 查看slave进程的状态，若发现 :  
        // Slave_IO_Running : Yes  
        // Slave_SQL_Running: Yes  
        // 则主从配置基本上可以放心成功了  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;五.　验证主从配置&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    在主结点上插入几条数据  
    
    在从结点上查询是否有了那几条新数据  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-4&quot;&gt;六.　多线程复制（在每个从结点上操作）&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    注意 :  
        I . mysql5.7之前就已经支持多线程复制，但是，5.7之前的版本，一个线程只能作用于一个库，  
            当我只有一个库的时候，或者某个库的写操作占整体写操作的大比例的时候，多线程复制的效率反而不如单线程  
        II. mysql5.7开始，多线程复制是一个线程作用于一个表  
    
    show variables like 'slave_parallel%';  
    
        // 查看该从结点上，有关多线程复制的参数  
        // 可以看到有　         slave_parallel_workers　这个参数  
        // 若是mysql5.7，还会有 slave_parallel_type　   这个参数  
        // 其中，slave_parallel_type的默认值是'database'，可选值是'logical_clock'（即逻辑时钟的类型，该值相同的复制可以并发执行）  
    
    stop slave;  
    
        // 先停止该从结点上的slave服务  
    
    set global slave_parallel_type='logical_clock';  
    
        // 修改多线程复制的方式为逻辑时钟方式  
    
    set global slave_parallel_workers=4;  
    
        // 修改多线程复制的线程数为4（该值请根据CPU数量和能力来设置）  
    
    start slave;  
    
        // 再次启动该从结点上的slave服务    
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 21 Nov 2016 00:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/21/Mysql-Repliset/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/21/Mysql-Repliset/</guid>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>linux磁盘管理</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一.　查看磁盘分区使用状况&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    df  
        -l  只显示本地磁盘的（默认）  
        -a  显示所有文件系统的磁盘使用情况（包括0字节分区，往往0字节分区的数目还是比较多的）  
        
        -T  显示每个分区采用了什么文件系统  
        //  比如 /usr挂载点对应的分区 是ext4还是ext3  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  当不指定这两种参数的时候，默认显示的单位是KB  
        
        -t  指定只显示哪种文件系统（比如ext4）的分区  
        -x  指定不显示哪种文件系统（比如ext3）的分区  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;二. 统计文件大小&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    du  
        -b  以字节为单位  
        -k  以KB为单位  
        -m  以MB为单位  
        //  不指定单位的时候，默认是以KB为单位的  
        //  指定单位的时候，会可能有四舍五入的误差  
        
        -h  以1024进制，用最合适的单位来表示大小  
        -H  以1000进制，用最合适的单位来表示大小  
        //  注意，用 -b或-k或-m的时候，所有的文件都是一个单位  
        //  注意，用 -h或-H的时候，每个文件显示的单位可能是不一样的，它会对每个文件都按照最合适的单位来显示　
        
        -s  指定统计目标  
        //  不指定该参数的话，默认是统计当前目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;三. 主分区 &amp;amp; 扩展分区 &amp;amp; 逻辑分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    1. 主分区 + 扩展分区　的总数不能超过4个  
    2. 扩展分区要么没有，要么只有一个  
    3. 扩展分区不能直接存储数据，必须在扩展分区的内部创建逻辑分区，才能存储数据  
    
    sudo fdisk -l  
    
        查看磁盘情况，例如我的结果的一部分是 :  
        
        Device     Boot      Start        End    Sectors   Size Id Type  
        /dev/sda1             2048  127999999  127997952    61G 83 Linux  
        /dev/sda2  *     128000000  130000895    2000896   977M 83 Linux  
        /dev/sda3        130000896  138000383    7999488   3.8G 82 Linux swap / Solaris  
        /dev/sda4        138002430 1305999359 1167996930   557G  5 Extended  
        /dev/sda5        138002432  650000383  511997952 244.1G 83 Linux  
        /dev/sda6        650002432 1162000383  511997952 244.1G 83 Linux  
        /dev/sda7       1162002432 1290000383  127997952    61G 83 Linux  
        /dev/sda8       1290002432 1297999871    7997440   3.8G 83 Linux  
        /dev/sda9       1298001920 1305999359    7997440   3.8G 83 Linux  
        
        // 可见，这是第一块磁盘（sda）的9个分区的情况  
        // 其中，sda1~sda4 是主分区&amp;amp;扩展分区  
        // 其中，sda5~sda9 是逻辑分区  
        // sda1,sda2,sda3是主分区， sda4是扩展分区，　且sda2是boot启动区  
        
        // fdisk -l 与 df -Th 命令结合着看 :  
        //     就可以知道我有哪些分区  
        //     每个分区是主分区，还是扩展分区，还是逻辑分区  
        //     每个分区对应哪个目录（即挂载点），各自的大小是多少  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;四.　服务器添加新磁盘&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    目标　：　加入 /dev/sdb 这块新硬盘  
    
    步骤 :  
    
    df -T -h   
        // 查看当前系统中有哪些分区，以及各分区的文件系统的类型  
        // 从返回结果可知当前的 /目录 的文件系统类型是ext4  
    
    sudo mkfs.ext4 /dev/sdb  
        // 把/dev/sdb这块硬盘格式化为ext4格式  
        // （我要在 /mydata　挂载硬盘，所以格式要和 /目录 保持一致）  
    
    sudo fdisk /dev/sdb  
        // 输入 m 查看帮助     
        // 我们先来创建一个主分区 :  
            输入 n 新建分区  
            输入 p 表明要创建的是主分区  
            输入 这个分区的编号是（我这里输入1）  
                （注意，主分区和扩展分区加起来最多4个，且编号为1~4）  
            输入 这个新分区的起始扇区位置（直接回车，使用默认值就行了）  
            输入 这个新分区的结束扇区位置
                （键入数值，该数值减去刚才的起始位置就是你这个新分区的容量）  
                （我们这里输入 +20G，表示从该分区的起始位置往后20G才是终结位置，即给该分区分配20G的空间）  
                （在这之后，还可以继续用 n p 来创建新的主分区）  
        // 我们再来创建一个扩展分区  
            输入 n 继续创建下一个分区  
            输入 e 创建一个扩展分区  
            输入 这个扩展分区的编号（我这里输入2）  
            输入 这个扩展分区的起始扇区位置（我这里输入系统提示的默认值）  
            输入 这个扩展分区的结束扇区位置（我这里输入系统提示的默认值）  
        // 我们再来创建逻辑分区（因为扩展分区并不能直接存储数据，需要在它内部创建逻辑分区）  
            输入 n 创建分区（可以看到现在只能创建主分区和逻辑分区了，因为扩展分区最多只有一个，且已经在上一步中被创建过了）  
            输入 l 创建一个逻辑分区  \
            输入 这个逻辑分区的编号（从5开始，因为1~4是给主分区和扩展分区用的）  
            输入 这个逻辑分区的起始扇区位置  
            输入 这个逻辑分区的终止扇区位置     
        // 输入 p 查看当前这块/dev/sdb磁盘的分区计划  
        // 最后输入 w 把上述制定的分区计划写入分区表  
            （注意，fdisk工具，只能给硬盘做MBR模式的分区）   
        // 例如，最后，我为/dev/sdb这块新硬盘的分区方案为 :  
            /dev/sdb1    主分区　　　　　　　　　　　　　编号=1    大小20G  
            /dev/sdb2    扩展分区　　　　　　　　　　　　编号=2    大小40G  
            /dev/sdb5    逻辑分区（从属于扩展分区）　　　编号=5    大小10G  
            /dev/sdb6    逻辑分区（从属于扩展分区）　　　编号=6    大小30G  
    
    mkdir /mydata  
    mkdir /mydata/pA  
    mkdir /mydata/pB  
    mkdir /mydata/pC  
        // 新建空目录用来挂载硬盘  
        // 其中， /mydata/pA 作为 /dev/sdb1　的挂载点  
        // 其中， /mydata/pB 作为 /dev/sdb5　的挂载点  
        // 其中， /mydata/pC 作为 /dev/sdb6　的挂载点  
        // 注意， 扩展分区不需要挂载点，因为扩展分区并不存储数据，而是它下面的若干逻辑分区需要各自的挂载点  
    
    sudo mount -t ext4 /dev/sdb1 /mydata/pA  
    sudo mount -t ext4 /dev/sdb5 /mydata/pB  
    sudo mount -t ext4 /dev/sdb6 /mydata/pC  
        // 进行挂载
        // 注意，mount命令是临时生效，如果想要永久生效，需要编辑 /etc/fstab  
    
    sudo vi /etc/fstab  
        // 添加 :  
        // /dev/sdb1    /mydata/pA    ext4    defaults    0    1  
        // /dev/sdb5    /mydata/pB    ext4    defaults    0    1  
        // /dev/sdb6    /mydata/pC    ext4    defaults    0    1  
    
    sudo shutdown -r now  
        // 重启  
    
    sudo fdisk -l  
        // 再次查看磁盘情况（有/dev/sdb1之类的就说明成功了）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;swap&quot;&gt;五.　如何给硬盘添加swap分区&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    第一步，建一个普通的分区（主分区or逻辑分区都行）  
    第二步，修改分区类型的16进制编码  
    第三步，格式化swap分区  
    第四步，启用swap分区  
    
    比方说，我要把 /dev/sdb7 这个分区做成swap分区  
    // 保证该分区已经被创建了，而且还没有被挂载  
    
    fdisk /dev/sdb  
        // 输入 t 来修改分区类型  
        // 输入 7 表示我要对 /dev/sdb7 做修改  
        // 输入 L 来查看各种分区类型对应的编号  
        // 输入 82 （82是swap类型的编号）  
        // 输入 w 来保存  
    
    mkswap /dev/sdb7  
        // 格式化交换分区  
        // 注意，它和格式化普通分区是有区别的，普通分区的格式化用的是mkfs命令  
    
    swapon /dev/sdb7  
        // 启用这个交换分区  
        // swapoff可以用来停用  
    
    vi /etc/fstab  
        // 添加 :  
        // /dev/sdb7    swap    swap    sw    0    0  
    
    重启生效  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 14 Nov 2016 23:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/14/Linux-Disk/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/14/Linux-Disk/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>mysql存储过程</title>
        <description>&lt;p&gt;我把做App时候的一个存储过程（邀请注册）记录下来，以便之后不用再花时间研究它的格式了&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    /*  
        procedure for regedit a new account  
        parameters  
        {  
        	usr        : the username you want to use  
        	pwd        : the password you want to use,and it is encoded to char(32) by md5  
        	registtime : the time when regedit  
        	invitor    : the username of person that he invited you to regedit a new account  
        	authcode   : the necessary code for regedit that you get from your invitor  
        	res        : 0 authcode is wrong;1 username has been used by others;2 transaction error;3 succeed  
        }  
        to make our deepnote environment good,we hope that our users are good readers,so we use invite regedit method  
        that is to say,if you want to regedit successfully,  
        A. you should get a right authcode or called invitecode  
        B. your username has not been used by others  
    */  
    
    drop procedure if exists regedit;  
    delimiter //  
    create procedure regedit (in usr varchar(16),in pwd char(32),in registtime int(11),in invitor varchar(16),in authcode char(32),out res tinyint(1))  
    begin  
        declare lastid int;  
        declare t_error int default 0;  
        declare continue handler for sqlexception set t_error=1;  
        
        start transaction;  
    	set res=0;  
    	if exists(select 1 from usertable where username=invitor and inviteauth=1 and invitecode=authcode limit 1)  
    	then  
    		if exists(select 1 from usertable where username=usr limit 1)  
    		then  
    			set res=1;  
    		else  
    			insert into usertable (username,password,birthtime) values(usr,pwd,registtime);  
    			set lastid=LAST_INSERT_ID();  
    			insert into classifytable (userid) values(lastid);  
    			set res=3;  
    		end if;  
    	end if;  
    	
    	if t_error=0 then  
            commit;  
            set res=3;  
        else  
            rollback;  
            set res=2;  
        end if;  
        
    end //  
    delimiter ;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 10 Nov 2016 16:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/10/Mysql-Procedure/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/10/Mysql-Procedure/</guid>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>iptables</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一. 总的命令格式&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                    table        command          chain          parameters        action  

    iptables        -t filter    -A(追加在表尾)     PREROUTING     -p tcp(协议)       -j ACCEPT  
                       nat       -I(追加在表头)     POSTROUTING    -s ip(源ip)           DROP(丢弃且不响应)  
                                 -D(删除一条)       INPUT          -d ip(宿ip)           REJECT(拒绝且会给客户端响应)  
                                 -L(列举)          OUTPUT         --sport sp            DNAT(修改宿地址)  
                                 -n               FORWARD        --dport dp            SNAT(修改源地址)  
                                 -F(清空)                         -m  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;iptables&quot;&gt;二.　初次启用 iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    systemctl stop firewalld  
    systemctl mask firewalld  
    
        centos 默认使用的是firewall，因此需要先关闭它  
    
    yum install iptables-services  
    
        安装iptables service  
    
    systemctl enable iptables  
    
        开机启动iptables-service  
    
    systemctl start iptables  
    
        启动iptables  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;etcsysconfigiptables&quot;&gt;三. 我的 /etc/sysconfig/iptables&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    -A INPUT -i lo -j ACCEPT  
        允许本地访问  

    -A INPUT -p icmp -j ACCEPT  
        允许所有的ICMP协议的报文（即允许被ping）  

    -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT  
        允许已经建立的连接进行回包  


    
    -A INPUT -p tcp --dport 35628 -j ACCEPT  
        允许ssh（改了端口的ssh）被所有机器访问  
        
        

    -A INPUT -p tcp -s 10.47.86.0/24 --dport 9200 -m limit --limit 10/m --limit-burst 100 -j ACCEPT   
        允许 10.47.86.198/24 这个网段的机器访问这台机器的9200端口  
        （并发控制）9200端口的最大连接数是100，超过的话就限制每分钟只能10个连接  
        // 注意， -A 和 -I 都是追加一条规则，区别为 :  
        // -A 是追加在原有规则表的最后  
        // -I 是追加在原有规则表的开头  
    
    -A INPUT -p tcp --dport 9200 -j DROP  
        没有满足上述的并发控制的话，访问9200端口的请求就直接丢弃  
    
    -A OUTPUT -p tcp --sport 9200 -j ACCEPT  
        允许这台机器的9200端口，向任何机器返回数据  
        
        

    -A INPUT -p tcp --dport 8081:8089 -j ACCEPT  
        允许任何机器访问这台机器的8081~8089端口  
        


    -A INPUT -j REJECT  
        拒绝所有额外的数据包（无论什么协议的）  
        // 注意，必须是 -A，即在规则表的表尾；如果是 -I，则会导致所有应该接受的数据包也被拒绝掉  
        // 注意，一般的配置思路是accept的在表头，拒绝的次之  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;snat&quot;&gt;四. SNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写源地址（作用在PostRouting链上，即向外发出数据包的时候）  
     
    应用场景 ：  
     
        有一台HttpServer是A网段的，B网段的一台客户机想要访问A网段里的HttpSserver  
        需要在A网段和B网段之间架设一台nat服务器，通过iptables配置nat转发  
     
    具体做法 :  
     
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A POSTROUTING -p tcp -s B网段地址 -j SNAT --to A网段地址  
            然后执行 service iptables restart  
            
        3. 一定要确保客户机的网关地址，是这台nat服务器的地址  
            可以通过修改客户机的 /etc/sysconfig/network 来达到目的  
            否则的话，如果客户机的请求不巧发给了别的一台网关，那台网关上没有配置nat转发，就访问不了HttpServer了  
    
    // 这样一来，客户机就可以直接访问HttpServer（直接的意思是输入的url不变，就是HttpServer的地址）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;dnat&quot;&gt;五. DNAT转发&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    改写宿地址（作用在PreRouting链上，即接收数据包的时候）  
    
    应用场景  :  
    
        同上，还是B网段的客户机想要访问A网段上的http服务  
        但是稍微做些改动，客户机不是直接去访问server的地址，而是去访问nat服务器的地址，nat服务器再做转发  
        // 即，客户机访问nat服务器，但是实际上数据包被偷偷转发给了A网段的server  
    
    具体做法  :  
    
        1. nat服务器，修改 /etc/sysctl.conf  
            添加 net.ipv4.ip_forward = 1  
            然后执行 sysctl -p 命令来使之生效  
            
        2. nat服务器，修改 /etc/sysconfig/iptables  
            添加 iptables -t nat -A PREROUTING -p tcp -d 与客户机相连的网卡地址 --dport 80 -j DNAT --to HttpServer地址:端口  
            然后执行 service iptables restart  
    
    // 这样一来，客户机就可以间接访问HttpServer（间接的意思是客户机并不访问HttpServer的地址，而是使用nat的地址做url）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 09 Nov 2016 18:05:00 +0800</pubDate>
        <link>http://localhost:4000/2016/11/09/Iptables/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/11/09/Iptables/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>用 rsync 来做主机间的数据同步</title>
        <description>&lt;h3 id=&quot;rsync-&quot;&gt;rsync 数据同步&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync可以用来在服务器之间 同步数据 or 备份数据  

一般linux上自动装了它，用了一下感觉很方便，记录一下以便日后再次用到  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsync&quot;&gt;一. 与rsync相关的目录结构&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync这种级别的服务，推荐让root管理员来管理，当然它的相关配置也推荐放在/root目录下面  


/root/rsyncd  

    # rsync的根目录  


/root/rsyncd/conf  

    # rsync服务的配置目录  

/root/rsyncd/conf/rsyncd.conf  

    # rsync的主配置文件  

/root/rsyncd/conf/rsyncd.secrets  

    # rsync的认证配置  

/root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  


/root/rsyncd/restful  

    # rsync服务的相关脚本目录  

/root/rsyncd/restful/start.sh  

    # rsync服务的启动脚本  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdconf&quot;&gt;二. 主配置文件 rsyncd.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pid file = /mydata/rsyncd/rsyncd.pid  

    # rsync的进程文件目录  

motd file = /root/rsyncd/conf/rsyncd.motd  

    # rsync的用来提示用户的注释信息的配置  

log file = /mydata/rsyncd/rsyncd.log  

    # rsync的日志文件路径  

address = ******  

    # 这台服务器的ip  
    # 若仅在内部使用，请使用内网ip，否则使用公网ip  

port = 873  

    # 监听的端口  

hosts allow = *  

    # 允许的客户端的ip，*表示允许所有  

max connections = 5  

    # 最大连接数量  

uid = root  

gid = root  

use chroot = yes  

read only = yes  

    # 只读  
    # 若允许客户端上传同步数据，则可以设置 write only 或者 read write  

transfer logging = yes  

log format = %t %a %m %f %b  

syslog facility = local3  

timeout = 300  


[linkA]  

path = /mydata/rsyncd/test  

auth users = root  

list = yes  

ignore errors  

secrets file = /root/rsyncd/conf/rsyncd.secrets  

    # 上面这段配置是 linkA，同一台rsync服务器上可以配置多个这种东西，每个的同步目录不同  
    # path          表示linkA所指向的需要同步的目录  
    # auth users    表示同步这个目录下的文件，需要用哪个用户来认证  
    # list=yes      表示在用户登入后，可以看到这个目录下的文件列表；反之设置为no  
    # secrets file  表示该目录所需要的认证配置信息的路径  
    # 还可以配置 exclude = dir1/ dir2/，表示在这个目录下排除（不同步）这个两个子目录  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdsecrets&quot;&gt;三. 认证配置文件 rsyncd.secrets&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root:abc  

    # 格式为 用户:密码  
    # 注意，此处的用户需要是这台服务器上真实存在的用户  
    # 注意，此处的密码可以不是这个用户的密码（即可以任意）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rsyncdmotd&quot;&gt;四. 提示信息配置文件 rsyncd.motd&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;welcome to sync server &amp;gt;_&amp;lt;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;startsh&quot;&gt;五. 启动脚本 start.sh&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --daemon --config=/root/rsyncd/conf/rsyncd.conf  

    # 以后台方式启动  
    # 指定配置文件路径  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;六. 客户端操作&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync --port 873 --list-only  root@xx.xx.xx.xx::linkA  

    # 列出服务器上linkA下面的资源  
    # 注意，需要指定端口  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP root@xx.xx.xx.xx::linkA mypath/  

    # 把服务器上linkA下面的资源同步到本机的 mypath目录  
    # 注意，此处不需要指定端口  
    # 注意，此处的参数 -a 是 archive mode  
    # 注意，此处的参数 -v 是 传输时的进度等信息  
    # 注意，此处的参数 -z 是 压缩传输  
    # 注意，此处的参数 -r 是 递归（递归同步linkA下面的子目录）  
    # 注意，此处的参数 -P 是 传输进度  
    # 注意，这里的 root 指的是 linkA代表的目录所需要的认证用户  

rsync -avzrP --delete root@xx.xx.xx.xx::linkA mypath/  

    # 注意，比较上面一条命令，多了参数 --delete  
    # 它表示客户端的数据要与服务器上的完全一致  
    # 即如果同步之前，你的客户端的mypath目录下存在服务器上没有的文件，则同步的时候会自动删除它们  
    # 所以，使用这条命令的时候，请小心不要让你的客户端的同步目录下有其他重要数据  

Tip : 建议把客户端的同步命令放入crontab里，定期自动同步or备份  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 16:40:00 +0800</pubDate>
        <link>http://localhost:4000/2016/10/23/Rsync/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/23/Rsync/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>Elasticsearch 中文分词 &amp; 安全配置</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;一. 资源准备&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    centos7.0  

        注意是7.0的系统  

    elasticsearch-2.2.0.tar.gz  

        资源地址 : https://www.elastic.co/downloads/past-releases/elasticsearch-2-2-0  
        注意是 2.2.0 的版本  

    elasticsearch-analysis-ik-1.8.0.zip  

        资源地址 : https://github.com/medcl/elasticsearch-analysis-ik/releases  
        注意是 1.8.0 的版本  
    
    
    
    tar -zxvf elasticsearch-2.2.0.tar.gz  
    
        解压 elasticsearch  
    
    mv elasticsearch-2.2.0 elasticsearch  
    
        改名 elasticsearch 的安装目录(强迫症...)  
    
    mv elasticsearch-2.2.0.tar.gz elasticsearch/  
    
        把压缩包移至elasticsearch的安装目录(强迫症...)  
    
    
    
    tar -zxvf elasticsearch-analysis-ik-1.8.0.zip  
    
        解压 elasticsearch-ik  
    
    mv elasticsearch-analysis-ik-1.8.0 elastic-ik  
    
        改名 elasticsearch-ik 的安装目录(强迫症...)  
    
    mv elasticsearch-analysis-ik-1.8.0.zip elastic-ik/  
    
        把压缩包移至elastic-ik的安装目录(强迫症...)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ik&quot;&gt;二. 安装 ik分词器&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    yum install maven  
    
        安装 maven  
    
    cd path/elastic-ik  
    
        进入你的elastic-ik的安装目录  
    
    mvn clean  
    
    mvn compile  
    
    mvn package  
    
    mkdir /home/seven/elasticsearch/plugins/ik  
    
        创建ik分词插件的目录  
    
    cp target/releases/elasticsearch-analysis-ik-1.8.0.zip /home/seven/elasticsearch/plugins/ik/  
    
        把target/releases下的压缩文件拷贝到elasticsearch的ik插件目录下  
    
    cd /home/seven/elasticsearch/plugins/ik  
    
        进入elasticsearch的ik插件目录  
    
    unzip elasticsearch-analysis-ik-1.8.0.zip  
    
        解压这个ik压缩文件  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;elasticsearchyml&quot;&gt;三. 配置文件 elasticsearch.yml&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    # 此配置文件位于elasticsearch安装目录下的config目录中  
    # 我只把我显示指定的配置项列了出来 :  
    
    cluster.name: waringstates  
    
        集群的名称  
        若是同一个网段下几个机子要构成集群，该配置项必须相同  
    
    node.name: node-1  
    
        该结点的名称  
        若是同一个网段下几个机子要构成集群，该配置项必须不同  
    
    path.data: /mydata/elasticsearch/data  
    
        数据存储路径  
    
    path.logs: /mydata/elasticsearch/logs  
    
        日志存储路径  
    
    network.host: ******  
    
        绑定的ip地址  
        该值可以填 : 127.0.0.1 or 内网地址 or 公网地址  
    
    http.port: 9200  
    
        绑定的端口  
    
    path.repo: [&quot;/mydata/elasticsearch/backup&quot;]  
    
        数据备份的路径  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;elasticsearch&quot;&gt;四. 检验 elasticsearch&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    a. 创建一个测试用的索引  
    
        curl -XPUT 127.0.0.1:9200/index  
    
    b. 创建一个mapping  
    
        curl -XPOST 127.0.0.1:9200/index/fulltext/_mapping -d'  
        {  
            &quot;fulltext&quot; : {  
                &quot;_all&quot; : {  
                    &quot;analyzer&quot;        : &quot;ik_max_word&quot;,  
                    &quot;search_analyzer&quot; : &quot;ik_max_word&quot;,  
                    &quot;term_vector&quot;     : &quot;no&quot;,  
                    &quot;store&quot;           : &quot;false&quot;  
                },  
                &quot;properties&quot; : {  
                    &quot;content&quot; : {  
                        &quot;type&quot;            : &quot;text&quot;,  
                        &quot;analyzer&quot;        : &quot;ik_max_word&quot;,  
                        &quot;search_analyzer&quot; : &quot;ik_max_word&quot;,  
                        &quot;include_in_all&quot;  : &quot;true&quot;,  
                        &quot;boost&quot;           : 8  
                    }  
                }  
            }  
        }'  
    
    c. 创建一些文档  
    
        curl -XPOST 127.0.0.1:9200/index/fulltext/1 -d'{&quot;content&quot;:&quot;美国留给伊拉克的是个烂摊子吗&quot;}'  
        curl -XPOST 127.0.0.1:9200/index/fulltext/2 -d'{&quot;content&quot;:&quot;公安部：各地校车将享最高路权&quot;}'  
        curl -XPOST 127.0.0.1:9200/index/fulltext/3 -d'{&quot;content&quot;:&quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot;}'  
        curl -XPOST 127.0.0.1:9200/index/fulltext/4 -d'{&quot;content&quot;:&quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot;}'  
    
    d. 查询测试  
    
        curl -XPOST 127.0.0.1:9200/index/fulltext/_search -d '{&quot;query&quot; : { &quot;match&quot; : { &quot;content&quot; : &quot;中国&quot; }}}'  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ip&quot;&gt;五. 限制 IP&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    # 因为elasticsearch目前还没有用户权限的概念，因此必须做好安全防护  
    # 当你需要在公网上访问elasticsearch的时候，建议要限制可以访问的IP  
    # 通常，我们使用 iptables 来限制ip  
    
    systemctl stop firewalld  
    systemctl mask firewalld  
    
        centos7 默认使用的是firewall，因此需要先关闭它  
    
    yum install iptables-services  
    
        安装iptables service  
    
    systemctl enable iptables  
    
        开机启动iptables-service  
    
    systemctl start iptables  
    
        启动iptables  
    
    
    iptables -I INPUT -p tcp --dport 22 -j ACCEPT  
    
        开启ssh的22端口  
        !! 注意，别忘了把你之前的一些对外的端口信息配置一下，否则会导致无法连接  
        !! 注意，尤其注意先把ssh配好，否则呵呵哒...  
    
    iptables -I INPUT -s want_ip -p tcp --dport 9200 -j ACCEPT  
    
        开启9200端口(elasticsearch)，且只对want_ip这个ip开放  
    
    service iptables save  
    
        保存iptables的配置  
    
    service iptables restart  
    
        重启iptables  
    
    
    curl -XGET 公网ip:9200/?pretty  
    
        测试访问elasticsearch  
        当你在 want_ip 这个机子上执行这条命令，是有返回值的  
        当你在 其他机子上执行这条命令，是连不上的  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 03 Oct 2016 23:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/10/03/Elasticsearch-IK/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/03/Elasticsearch-IK/</guid>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>nginx代理多个flask</title>
        <description>&lt;p&gt;本文讲述如何用nginx代理多个flask，从而进行负载均衡&lt;/p&gt;

&lt;p&gt;所需准备 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. nginx  

        它安装依赖的东西还不少，可以参考 http://www.cnblogs.com/skynet/p/4146083.html  

2. flask  

        sudo pip install Flask  

3. uwsgi  

        sudo pip install uwsgi  
    
        使用uwsgi的原因是，如果光溜溜的flask是很容易崩溃的，  
        外面套一层uwsgi，实践检验能让flask强壮很多  
    
        若无法安装uwsgi这个库，则大多数原因是因为少了两个东西 :  
    
        ubuntu系列 :  
            sudo apt-get install python-dev  
            sudo apt-get install setuptools  
    
        centos系列 :  
            sudo yum install python-devel  
            sudo yum install setuptools  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;下面举个例子，讲讲具体的配置&lt;/p&gt;

&lt;h3 id=&quot;flask&quot;&gt;一.　flask程序的信息&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. 我的用flask库写的web服务端程序的根目录 :  

        /home/seven/program/openmind_server/  

2. 在这个目录下，我的程序的入口文件是 main.py  

        即入口文件的绝对地址是 /home/seven/program/openmind_server/main.py  
        
        且为了使用方便，最好让这个脚本接受两个参数，分别作为这个进程绑定的地址和端口  
        例如 :  
        python main.py 127.0.0.1 8081  
        python main.py 127.0.0.1 8082  

3. 在这个脚本中，我的app的名称是 Server_App  

        即 main.py 中，有类似这样的语句 :  
        
        Server_App = flask.Flask(__name__)  
        Server_App.secret_key = '\r\x9d1\xd1\xccW\x9e\xa6\x9a\x97[\xb1=\x93\x87\x15s&amp;lt;\xe8\xe3\x13DL?'  
        
        # 注意，若你的flask程序在不同的机子上（一般生产环境下都是这样，是真正的多机负载均衡）  
        # 则，这个 secret_key 要保持一致，否则session可能无法正常工作  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;uwsgi--uwsgi8081ini&quot;&gt;二.　uwsgi配置文件  uwsgi8081.ini&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[uwsgi]  

socket = 127.0.0.1:8081  
    绑定监听的地址和端口  
        
    实际生产环境下 :  
        1. 建议nginx单独一台服务器，然后其他的flask都在同一网段的其他机子上  
        2. uwsgi要在 nginx结点，及每台flask结点上 都要安装  
        3. flask只要在每台flask结点上安装  
        4. 这个uwsgi配置文件和对应的flask程序是在同一台机子上的  
    

master = true  

pidfile = /mydata/openmind_server/pids/uwsgi8081.pid  
    这个uwsgi进程的pid文件的路径（建议使用绝对路径）  

chdir = /home/seven/program/openmind_server/  
    你的用flask库编写的服务端程序的根目录的路径  
    （建议使用绝对路径，且最后有'/'）  
    （若flask程序位于不同机子上，则要保证各机子上的路径是一致的）  

wsgi-file = main.py  
    在上述目录下，你的入口脚本的名字  

callable = Server_App  
    在上述入口脚本中，你的flask的app对象的名字  

processes = 2  
    该值建议与CPU核数相同  

threads = 4  
    占用的线程数  

stats = 127.0.0.1:9091  
    查询状态信息的端口  

logdate=true  

daemonize=/mydata/openmind_server/logs/flask8081.log  
    以后台方式运行，且指定日志文件的路径（建议使用绝对路径）  


（ uwsgi8082.ini， uwsgi8083.ini， uwsgi8084.ini 与之类似，改端口和路径即可）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;nginx-usrlocalnginxconfnginxconf&quot;&gt;三.　nginx配置文件 /usr/local/nginx/conf/nginx.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;worker_processes  2;  
    # 建议与CPU核数相同  

error_log  /mydata/nginx/log/error.log;  
    # 错误日志的路径（建议使用绝对路径）  
    # 且除了它，在 /usr/local/nginx/logs/error.log 也有一部分的错误日志  

pid        /mydata/nginx/pid/nginx.pid;  
    # 进程号文件的路径（建议使用绝对路径）  

events {  
    use epoll;  
        # epoll效率比轮询要高  
    multi_accept on;  
    worker_connections  1024;  
        # 最大连接数  
}  


http {  
    include       mime.types;  
    default_type  application/octet-stream;  

    server_names_hash_bucket_size 128;  
    client_header_buffer_size 32k;  
    client_body_buffer_size 512k;  
    client_max_body_size 32m;  
    large_client_header_buffers 4 32k;  

    access_log  /mydata/nginx/log/access.log;  
        # 访问日志路径（建议使用绝对路径）  

    sendfile        on;  
    tcp_nodelay on;  
    server_tokens off;  
    access_log off;  
    charset UTF-8;  
    keepalive_timeout  60;  

    open_file_cache max=1024 inactive=20s;  
    open_file_cache_valid 60s;  
    open_file_cache_min_uses 2;  

    upstream my_servers {  
        server 127.0.0.1:8081;  
        server 127.0.0.1:8082;  
        server 127.0.0.1:8083;  
        server 127.0.0.1:8084;  
    }  
    # 转发配置 :  
    # 一共可以转发到本机的8081,8082,8083,8084四个结点上  
    # 实际生产环境中建议flask结点在其他机子上  

    server {  
        listen       80;  
            # 对外暴露80端口  
        server_name  localhost default backlog=256;  
        access_log  /mydata/nginx/log/host.access.log;  

        location / {  
            uwsgi_pass my_servers;  
            include uwsgi_params;  
            uwsgi_param UWSGI_CHDIR /home/seven/program/openmind_server/;  
            uwsgi_param UWSGI_SCRIPT main;  
        }  
        # 转发配置 :  
        # 通过使用上面定义的 upstream my_servers 来进行负载均衡  
        # 且指定flask程序的根目录  
        # 且指定flask程序根目录下的入口脚本的名称（不包含后缀名）  

        # redirect server error pages to the static page /50x.html  
        error_page   500 502 503 504  /50x.html;  
        location = /50x.html {  
            root   html;  
        }  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;四.　启动方式&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi --ini path/uwsgi8081.ini  
    启动8081结点（以非root用户的身份来启动）  

uwsgi --ini path/uwsgi8082.ini  
    启动8082结点（以非root用户的身份来启动）  

uwsgi --ini path/uwsgi8083.ini  
    启动8083结点（以非root用户的身份来启动）  

uwsgi --ini path/uwsgi8084.ini  
    启动8084结点（以非root用户的身份来启动）  

cd /usr/local/nginx/sbin  
    进入nginx的脚本目录  

./nginx  
    启动nginx（注意要以root用户身份来启动）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;五.　重启方式&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi --reload path/uwsgi8081.pid  
    重启8081结点（指定对应的pid文件，以非root身份）  

uwsgi --reload path/uwsgi8082.pid  
    重启8082结点（指定对应的pid文件，以非root身份）  

uwsgi --reload path/uwsgi8083.pid  
    重启8083结点（指定对应的pid文件，以非root身份）  

uwsgi --reload path/uwsgi8084.pid  
    重启8084结点（指定对应的pid文件，以非root身份）  

cd /usr/local/nginx/sbin  
    进入nginx的脚本目录  

./nginx -s stop  
    关闭nginx（注意要以root用户身份来关闭）  

./nginx  
    再次启动nginx（注意要以root用户身份来启动）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 09 Sep 2016 03:30:00 +0800</pubDate>
        <link>http://localhost:4000/2016/09/09/Nginx-Proxy/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/09/09/Nginx-Proxy/</guid>
        
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>mongodb 性能提升的6个步骤</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;第一步. 做监测工作&lt;/h3&gt;

&lt;p&gt;用 explain 来分析你的数据库操作语句&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        例如 db.your_collection.find({ x : 123, y : 456 }).explain(&quot;allPlansExecution&quot;)  
        查看你的索引的工作情况 :  
        比如实际用了哪个索引来查  
        比如扫描了多少文档  
        
        explain 也常用来测试比较多个索引方案的优劣  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用慢日志（静态方法，通过在配置文件中添加配置项）&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        profile=1  

                profile=0  表示不记录慢日志  
                profile=1  表示只记录慢日志  
                profile=2  表示所有日志都记录  

        slowms=100  

                慢日志的时间阀值是100ms  

        可以通过 db.getProfilingStatus() 来查看慢日志的信息  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用慢日志（动态方法，通过mongo-shell命令）&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        db.setProfilingLevel( profile, slowms )  

                第一个参数表示慢日志的级别，取值是 0 1 2  
                第二个参数表示慢日志的时间阀值，单位是毫秒  

                推荐通过这种动态的方式来设置慢日志  
                因为，慢日志通常用在内测时候，真正上线后为了性能，是不会开启慢日志的，或者说是不会长期开着的  
                一般是每隔一段时间，动态地开启一段时间来获取线上测试情况  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;查看服务状态&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        db.serverStatus()  

                必须在admin库下，才能使用这条命令  
                它会把最近15分钟内的监测情况全部打印出来  
                举个例子，我只打印出部分信息，db.serverStatus()['extra_info']，结果是 :  
                
                {  
                    &quot;note&quot;             : &quot;field vary by platform&quot;,  
                    &quot;heap_usage_bytes&quot; : 62236488,  
                    &quot;page_faults&quot;      : 24  
                }  
                
                其中 heap_usage_bytes 表示最近15分钟内，内存中的热数据占用的字节数  
                其中 page_faults      表示最近15分钟内，缺页中断的次数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用mongostat工具&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        该脚本位于mongodb的安装目录的bin目录下  
        举个例子 :  
        
        &amp;gt; mongostat \  
        &amp;gt; --host your_host:your_port \  
        &amp;gt; --username your_username_of_admin \  
        &amp;gt; --password your_password_of_admin \  
        &amp;gt; --authenticationDatabase admin  
        
        注意，authenticationDatabase这个参数必须是admin  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用mongo-shell自带的benchRun&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        举个例子 :  
        res = benchRun({  
            host        : '地址:端口',  
            username    : 'admin库的用户名',  
            password    : 'admin库的密码',  
            db          : '你要测试的库名',  
            ops         : [  
                {  
                    ns  : '你要测试的库名.集合名',  
                    op  : 'insert',  
                    doc : { 'x' : { '#RAND_INT' : [ 0, 999 ] } }  
                }  
            ],  
            parallel    : 20,  
            seconds     : 5  
        })  
        注意，benchRun需要在admin库下才能执行  
        参数 parallel 是指我要用多少个线程（连接）去并发地插入，注意它并不是说每秒20个并发，因为每个线程每秒可以完成许多次插入  
        参数 seconds  是指这个benchRun要执行多长时间  
        
        返回结果 :  
        {  
            &quot;note&quot;                       : &quot;values per second&quot;,  
            &quot;errCount&quot;                   : NumberLong(0),  
            &quot;trapped&quot;                    : &quot;error: not implemented&quot;,  
            &quot;insertLatencyAverageMicros&quot; : 11.217961300363536,  
            &quot;totalOps&quot;                   : NumberLong(344396),  
            &quot;totalOps/s&quot;                 : 68697.5910483047,  
            &quot;findOne&quot;                    : 0,  
            &quot;insert&quot;                     : 68697.5910483047,  
            &quot;delete&quot;                     : 0,  
            &quot;update&quot;                     : 0,  
            &quot;query&quot;                      : 0,  
            &quot;command&quot;                    : 0  
        }  
        注意，上述结果中的数值都是每秒平均值  
        例如insert=68697 是指每秒执行了这么多次插入  
        例如errCount     是指每秒的平均错误数  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用 iostat命令 查看系统IO情况&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        举个例子 :  
        iostat -x 1  
            // 每秒输出一次  
        
        示例输出 :  
        Linux 4.2.0-30-generic (localhost) 	2016年11月20日 	_x86_64_	(4 CPU)  
        avg-cpu:  %user   %nice %system %iowait  %steal   %idle  
                    6.37    0.01    1.74    0.92    0.00   90.96  
        Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util  
        sda               0.10     1.17    1.98    1.31    42.79   119.86    98.73     0.08   24.54   16.75   36.27   4.66   1.54  
            // 关注几个数据 :  
            // %iowait  是指CPU等待IO的比例  
            // %idle    是指CPU空闲的比例  
            // %util    是指设备（上述结果中可以看到是sda这块硬盘）在这一秒内的IO带宽的使用百分比  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;第二步. 优化文档的结构&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        当面临性能问题的时候，首先考虑的是优化文档结构和优化索引，其次才是系统调优和硬件优化  
        
        在设计文档的结构的时候，一定要非常清除你需要解决的最重要的问题是什么  
        mongodb并不是万能的许愿机，很多时候为了让你的最主要的业务流畅，你只能做出权衡  
        下面提出两个原则 :  
        
        1. 文档结构并不取决于数据的内容，而是取决于数据的访问方式  
                即，不要面向数据去设计数据库，而是面向应用去设计数据库  
        2. 无计可施时，割肉全身，善用冗余来提高查询效率  
        
        
        下面举两个案例  
        两个案例均来自imooc上面的MongoDB2014北京大会，链接为 http://www.imooc.com/learn/255  
    

        案例一  

        存储电商的产品，每个文档形如 :  
        {  
            _id     : 一个很长的字符串（全局唯一）,  
            
            china   : { 该产品的中文描述的具体的一些属性 },  
            
            english : { 该产品的英文描述的具体的一些属性 },  
            
            japan   : { 该产品的日文描述的具体的一些属性 },  
            
            ...还有其他十几个语系  
        }  
        原始的索引是 { _id : 1 }  
        原始的查询语句是 db.products.find( { _id : xxx }, { china : 1 } )  
        
        比如这里是一个中国人来查询xxx这件商品的具体信息  
        乍看之下这个设计确实没问题啊，为什么会很慢 ?  
        
        经过查日志发现，缺页中断太多，诶 ? 这关缺页中断什么事 ?  
        原因如下 :  
        1. 首先，mongodb在查询的时候，不管你有没有指定是否只返回某些字段，它都会把整个文档查出来放到内存中  
        2. 只不过在mongodb客户端（mongo-shell或者应用程序）看来，它只拿其中的china字段（当然_id是必拿的）  
        3. 所以，就算你只需要china字段，实际上内存中是存在着这个商品的全部信息  
        4. 假设总共20个语系，即内存的使用率只有 5%  
        5. 换句话说，内存原可以放20个商品，结果放了5个就满了，那当查询其余15个商品时，缺页中断率不高才怪  
        
        解决方案 :  
        拆分文档，拆分后的结构形如 :  
        {  
            _id    : 原来的_id 连接上 语系,  
            detail : { 该产品的在该语系下的详细描述 }  
        }  
        
        索引不变，现在的查询语句变为 db.products.find({ _id : xxxchina })  
        
        这样一来，mongodb查出来的就是我要用的，内存使用率提高了20倍，缺页中断大大减少  



        案例二  
        
        社交圈中的动态，涉及两种文档，一是用户文档，二是动态文档。简单表示如下 :  
        用户文档 :  
        {  
            _id     : 用户id,  
            friends : [ 朋友1的id, 朋友2的id, ... ]  
        }  
        用户文档的索引 { _id : 1 }  
        动态文档 :  
        {  
            creator : 发布者的id,  
            time    : 发布的时间戳,  
            content : 动态的内容  
        }  
        动态文档的索引 { creator : 1, time : -1 }  
        要查出我的所有朋友最近的几条动态，需要做联合查询，而且是带in的联合查询，慢是正常的  
        
        解决方案 :  
        在每发布一条动态的时候，顺带加上当前我的所有朋友，修改后的动态文档的结构 :  
        {  
            creator : 发布者的id,  
            time    : 发布的时间戳,  
            friends : [ 此时的朋友1的id, 此时的朋友2的id, ... ],  
            content : 动态的内容  
        }  
        另外为这个文档增加索引 { friends : 1, time : -1 }  
        现在的查询语句就不是联合查询了，会快很多  
        
        但是这个解决方案很奇葩是么，搞这么大的冗余，多浪费磁盘啊，而且一致性的维护怎么做？  
        但是，需要牢记的是，你的目标是啥？你需要解决的最大的问题是啥？  
        如果你的应用，容忍一定程度的不一致性，比如社交圈这种，肯定是要优先照顾读的性能，通过冗余来提高读性能是很常见的  
        
        
        
        你可能会有疑问 ：  
        案例一是因为要查的信息占整个文档的比例太小，所以内存利用率不高导致缺页中断频繁  
        照这个道理，案例二中增加了很大的冗余信息，不是也会导致频繁的缺页中断吗，为什么案例二就可以用冗余呢  
        此两者不是很矛盾吗？  
        
        我一开始也有这个疑惑，但是我要说的是，你会这么想，是不自觉地犯了根据数据内容来设计数据库的老病  
        具体分析一下 :  
        
        案例一存储的是电商商品的信息，所有人都可能会去查询一些热门商品的信息  
        也就是说，商品信息存在热数据，而且是被所有人都可能访问的热数据  
        所以，在这种应用场景下，为了让热数据使用率更高，当然要提高内存利用率，即减少缺页中断的次数  
        既然要提高内存的利用率，就要使得用户查的信息占整个文档的比例尽可能大  
        这样一来，才能让固定的内存去装的下更多数量的文档  
        所以，需要把一个商品的文档按照语系来切分成不同的文档  
        这样一来，那些罕见语系的商品信息基本不会占用内存，内存中都是热门商品的常用语系的信息  
        
        案例二存储的是不同用户发表的动态信息  
        第一，不同人的动态是不同的。第二，而且一般查的时候是翻页来查的  
        这两个原因就决定了这种数据是不存在热数据的概念的  
        所以，绝大多数情况，都是不可避免的缺页中断，都是去磁盘上查  
        既然无法使用热数据，既然不可避免地查磁盘，那就只能让查磁盘更快这条路了  
        所以，使用冗余是合适的  
        
        对比分析了这两个案例，以及你可能出现的疑惑，相信你有了更深刻的认识  
        再次强调 :  
        不要面向数据去设计数据库，而是要面向应用去设计数据库  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;第三步. 优化索引&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        和一般的sql索引很类似，不做太多阐述，这边我只提一个之前没有注意到的降序索引  
        
        例如消息文档 :  
        {  
            myid    : 我的id,  
            
            who     : 谁给我发的消息,  
            
            time    : 消息的时间戳,  
            
            content : 消息的内容  
        }  
        消息文档的索引 { myid : 1, time : -1 }  
        
        这样的索引，可以很快地找出与我相关的最近几条消息，实现按时间降序分页查询  
        如果用{ myid : 1, time : 1 }索引的话 :  
        还需要排序，我不知道mongodb内部会不会做什么优化，但是用降序索引肯定是确保效率的  
        
        另外，当你有多种索引方案备选时，建议通过explain来看看谁更好  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;第四步. 优化内存&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        首先，提两个概念  
        
        概念一. 内存映射  
        
                mongodb采用内存映射的方式来进行内存和磁盘上的数据调度  
                其实内存映射是操作系统自带的，并不是mongodb自己实现的  
                当你访问的数据在内存中的时候，mongodb能够很快地把数据拿给你  
                当你访问的数据不在内存时，会触发缺页中断，告诉操作系统把xx号页面调入内存，然后再读内存  
                
                // 但是，高版本（&amp;gt;=3.0）的mongodb有了自己的存储引擎WiredTiger  
        
        概念二. 工作集  
        
                工作集 = 索引 + 内存中的热数据  
                
                如何查索引的大小？  
                在mongo shell中，切换到你的某个库，通过 db.stats() 来查看  
                其中的 indexSize 便是该库的所有索引占的字节数  
                
                如何查内存中的热数据的大小？  
                在mongo shell中，切换到admin库，通过 db.serverStatus() 来查看  
                该命令会返回最近15分钟内的运行情况  
                如果只需要查热数据的大小，可以通过 db.serverStatus()['extra_info']，我的mongo版本是3.2.4  
                其中的 heap_usage_bytes 便是内存中的热数据占的字节数  
        
        为了让mongodb尽量少的发生缺页中断，应该让内存大于工作集的大小  
        这便是选用内存大小的根据  
        
        如果单机确实无法满足的话，就只能通过分片了  
        因为很多时候工作集确实很大，甚至索引的大小就超过了实际数据的大小  
        但是在分片的每台主机上，选用内存的依据还是工作集  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;io&quot;&gt;第五步. 优化IO&lt;/h3&gt;

&lt;p&gt;对于不同的数据，采用不同的存储介质&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        数据文件用SSD来存储  

                mongodb绝大多数情况下，都是随机读写  
                相同情况下，SSD随机读写的效率是HDD的几十倍  

        日志文件用HDD来存储  

                对于顺序读写来说，SSD和HDD的效率相差不大  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;设置合理的预读值&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        什么是预读值？  
        在请求磁盘上的数据的时候，操作系统并不是只返回一个页面，而是把接下来的好几个页面都调入内存中  
        
        而mongodb绝大多数是随机读写，如果预读值太大（默认是256），会导致缺页中断比较多  
        此时就需要调小预读值，一般设置为32比较合适  
        
        例如 :  
        通过 sudo blockdev --report 来查看系统各存储设备的预读值  
        通过 sudo blockdev --setra 32 /dev/sda5 来设置/dev/sda5这个分区的预读值是32K  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;关闭数据库文件的atime&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        禁止系统对文件的访问时间更新会有效提高文件读取的性能  
        
        比如你的mongodb的数据在 /mydata 下面，文件系统是 ext4  
        可以在 /etc/fstab 这个文件中添加一行 /dev/xvdb /mydata ext4 noatime 0 0  
        修改完后，重新挂载 sudo mount -o remount /mydata  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-4&quot;&gt;第六步. 分片集群&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        我专门写了一篇关于mongodb的分片片键的博客  
        [地址是](https://340starobserver.github.io/2016/06/07/Mongo-ShardKey/)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-5&quot;&gt;第七步. 其他建议&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        1. 开启 releaseConnectionsAfterResponse 参数  
            db.runCommand({ setParameter : 1, releaseConnectionsAfterResponse : true })  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 20 Aug 2016 06:30:00 +0800</pubDate>
        <link>http://localhost:4000/2016/08/20/Mongo-Optimal/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/08/20/Mongo-Optimal/</guid>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>mongo分片集群的部署以及集群认证</title>
        <description>&lt;p&gt;本文适合已经对mongo集群的理论知识已经有所了解的读者&lt;/p&gt;

&lt;p&gt;本文着重讲述集群部署上的完整步骤和细节，以及如何在集群上使用用户认证功能&lt;/p&gt;

&lt;p&gt;我给的示例的集群结构 ：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;1个路由mongos结点（本地，27017端口）&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  

    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;1个元配置config结点（本地，27018端口）&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  

    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;2个分片shard结点（本地，28001以及28002端口）&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;环境版本 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;mongo版本&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;3.2.4&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
    
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;系统版本&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;ubuntu15.04&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;当然，生产环境下，建议多个mongos结点和多个config结点，&lt;br /&gt;
其中mongo推荐的config结点的数量是至少三个&lt;br /&gt;
而且生产环境下，每个分片shard结点可以是一个复制集的主结点&lt;/p&gt;

&lt;p&gt;下面列出所有的步骤：&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;先来不带认证的&lt;/h3&gt;

&lt;h3 id=&quot;shard-shard28001conf&quot;&gt;一. 第一个shard分片数据结点的配置文件 shard28001.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    port=28001  
    
            shard1的端口  
    
    bind_ip=127.0.0.1  
    
            shard1的绑定地址  
    
    dbpath=/home/seven/program/mongodb/data/shard28001/  
    
            shard1的数据目录(绝对路径)  
    
    logpath=/home/seven/program/mongodb/log/shard28001.log  
    
            shard1的日志目录(绝对路径)  
    
    pidfilepath=/home/seven/program/mongodb/data/shard28001/shard28001.pid  
    
            shard1的pid路径(绝对路径)  
    
    logappend=true  
    
            shard1的日志以追加方式  
    
    fork=true  
    
            shard1以后台方式运行  
    
    shardsvr=true  
    
            表明该mongo进程是一个分片结点  

    profile=1  
    
            只在操作时间超过slowms时，才记录慢日志  
            profile=0表示永不记录，profile=1表示只记录慢日志，profile=2表示所有日志都记录  
    
    slowms=100  
    
            慢日志的时间阀值是100ms  
            
            另外，这两项配置推荐在主结点和从结点上都进行配置  
            并且可以通过db.getProfilingStatus()这条命令来查看慢日志的配置信息  
            
            其实，不推荐通过配置文件的方式强制开启慢日志  
            相反，推荐使用db.setProfilingLevel(int)的方式动态调整profile的等级  
            因为，慢日志通常用在内测时候，真正上线后为了性能，是不会开启慢日志的，或者说是不会长期开着的  
            一般是每隔一段时间，动态地开启一段时间来获取线上测试情况  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;shard-shard28002conf&quot;&gt;二. 第二个shard分片数据结点的配置文件 shard28002.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    port=28002  
    
            shard2的端口  
    
    bind_ip=127.0.0.1  
    
            shard2的绑定地址  
    
    dbpath=/home/seven/program/mongodb/data/shard28002/  
    
            shard2的数据目录(绝对路径)  
    
    logpath=/home/seven/program/mongodb/log/shard28002.log  
    
            shard2的日志目录(绝对路径)  
    
    pidfilepath=/home/seven/program/mongodb/data/shard28002/shard28002.pid  
    
            shard2的pid路径(绝对路径)  
    
    logappend=true  
    
            shard2的日志以追加方式  
    
    fork=true  
    
            shard2以后台方式运行  
    
    shardsvr=true  
    
            表明该mongo进程是一个分片结点  
    
    profile=1  
    
    slowms=100  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;config-config27018conf&quot;&gt;三. config元数据结点的配置文件 config27018.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    port=27018  
    
            config结点的端口  
    
    bind_ip=127.0.0.1  
    
            config结点的绑定地址  
    
    dbpath=/home/seven/program/mongodb/data/config27018/  
    
            config结点的数据目录(绝对路径)  
    
    logpath=/home/seven/program/mongodb/log/config27018.log  
    
            config结点的日志路径(绝对路径)  
    
    pidfilepath=/home/seven/program/mongodb/data/config27018/config27018.pid  
    
            config结点的pid路径(绝对路径)  
    
    logappend=true  
    
            config结点的日志以追加方式  
    
    fork=true  
    
            config结点以后台方式运行  
    
    configsvr=true  
    
            表明该mongo进程是一个元数据结点  

    profile=1  
    
    slowms=100  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mongos-mongos27017conf&quot;&gt;四. mongos路由结点的配置文件 mongos27017.conf&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    port=27017  
    
            mongos结点的端口  
    
    bind_ip=127.0.0.1  
    
            mongos结点的绑定地址  
    
    logpath=/home/seven/program/mongodb/log/mongos27017.log  
    
            mongos结点的日志路径(绝对路径)  
    
    pidfilepath=/home/seven/program/mongodb/data/mongos27017/mongos27017.pid  
    
            mongos结点的pid路径(绝对路径)  
    
    logappend=true  
    
            mongos结点的日志以追加方式  
    
    fork=true  
    
            mongos结点以后台方式运行  
    
    configdb=127.0.0.1:27018  
    
            表明该mongo进程是一个路由结点，且它只有一个元数据结点并且地址为本地且端口为27018  
    
    注意mongos路由结点是不需要也不能定义dbpath的  
    注意路由结点上不需要配置profile和slowms，同样在路由结点上也无法查看这两项设置  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;五. 启动脚本&lt;/h3&gt;

&lt;p&gt;init.sh　：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    禁用hugepage，否则启动mongod进程的时候会有warning  
    另外这个脚本要以root方式运行，所以权限最好设置为700，所属组设置为root:root  

    echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled  
    
    echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/defrag  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;shard28001.sh　：　分片结点1的启动脚本，这个脚本最好不要以root身份运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    cd /home/seven/program/mongodb/bin  
    
            进入mongodb的bin目录  
    
    ./mongod -f ../conf/shard28001.conf  
    
            启动shard1结点(-f指定配置文件)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;shard28002.sh　：　分片结点2的启动脚本，这个脚本最好不要以root身份运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    cd /home/seven/program/mongodb/bin  
    
            进入mongodb的bin目录  
    
    ./mongod -f ../conf/shard28002.conf  
    
            启动shard2结点(-f指定配置文件)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;config27018.sh　：　元数据结点的启动脚本，这个脚本最好不要以root身份运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    cd /home/seven/program/mongodb/bin  
    
            进入mongodb的bin目录  
    
    ./mongod -f ../conf/config27018.conf  
    
            启动config结点(-f指定配置文件)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;mongos27017.sh　：　路由结点的启动脚本，这个脚本最好不要以root身份运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    cd /home/seven/program/mongodb/bin  
    
            进入mongodb的bin目录  
    
    ./mongos -f ../conf/mongos27017.conf  
    
            以mongos形式启动路由结点(-f指定配置文件)  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;六. 启动各实例&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    su root  
    
            切换为root身份，以便运行init.sh脚本来禁用hugepage  
    
    ./init.sh  
    
            禁用hugepage，（当然这里你需要进到你自己机子上存放该脚本的目录）  
    
    exit  
    
            退出root身份，以便启动mongod实例  

    ./shard28001.sh  
    
            启动第一个分片结点  
    
    ./shard28002.sh  
    
            启动第二个分片结点  
    
    ./config27018.sh  
    
            启动元数据结点  
    
    ./mongos27017.sh  
    
            启动路由结点  
            若你的config结点不满3个，它会提示你在生产环境下最好至少三个config结点  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;七. 添加分片成员&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mongo 127.0.0.1:27017/admin  
    
            进入mongos（路由结点）的shell  
    
    db.runCommand({ &quot;addShard&quot; : &quot;127.0.0.1:28001&quot; })  
    
            添加分片结点28001到集群中  
            如果不事先进入admin库，会报错，所以需要连接时指定admin库，或者use admin  
    
    db.runCommand({ &quot;addShard&quot; : &quot;127.0.0.1:28002&quot; })  
    
            添加分片结点28002到集群中  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-4&quot;&gt;八. 创建一个测试库和集合&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    use 新库名  
    
            创建一个新的库（当然是在路由结点，即mongos的shell中进行）  
    
    db.新表名.insert({...})  
    
            插入若干条数据  
    
    db.新表名.ensureIndex({...})  
    
            为这个表建一个索引吧  
            例如我是db.usertable.ensureIndex({ userid : 1 },{ unique : true })  
    
    db.runCommand({ enablesharding : 新库名 })  
    
            使刚才创建的库能够被分片  
            （发现报错，提示必须在admin环境下，所以use admin，再执行这条命令）  
    
    db.runCommand({ shardcollection : &quot;库名.表名&quot;, key : {...} })  
    
            为某个库中的某个表添加分片片键,例如我是 :  
            db.runCommand(  
                {  
                    shardcollection : &quot;weshare.usertable&quot;,  
                    key             : { &quot;userid&quot; : 1 },  
                    unique          : true  
                }  
            )  
            注意，强烈推荐片键是索引的一部分前缀，有利于达到查询的局部化  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-5&quot;&gt;九. 查看集群状态&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    use config  
    
            进入config库，即元数据库  
            （当然这里还是在路由结点的mongos的shell里执行命令）  
    
    db.shards.find()  
    
            查看当前集群中有哪些shard结点  
    
    use 新库名  
    
            进入你刚才创建的那个库  
    
    db.表名.stats()  
    
            查看该库中的该表的集群状态  
            若发现里面最开始的sharded字段是true，则表示你的集群创建成功了  
    
    db.printShardingStatus()  
    
            查看分片状态  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-6&quot;&gt;再来加入认证的配置&lt;/h3&gt;

&lt;h3 id=&quot;section-7&quot;&gt;十. 生成密钥文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    openssl rand -base64 64 &amp;gt; keyfile.dat  

            生成64字节的密钥文件  

    chmod 600 keyfile.dat  

            建议把密钥文件的权限设置为600（针对启动mongo实例的那个用户）  
            接着需要把这个密钥文件拷贝到集群中每一个结点上（路由结点，元配置结点，分片结点上都要有这个密钥文件）  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-8&quot;&gt;十一. 创建集群用户&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mongo 127.0.0.1:27017/admin  

            进入mongos路由结点（我这里是本地的27017端口，请根据自身的地址和端口来进行）  

    db.createUser(  
        {  
            user  : yourusername,  
            pwd   : yourpassword,  
            roles :  
            [  
                { role : &quot;root&quot;, db : &quot;admin&quot; },  
                { role : &quot;clusterAdmin&quot;, db : &quot;admin&quot; }  
            ]  
        }  
    )  

            创建针对admin库的管理员用户  

    use 新库  

            进入你之前创建的新库  

    db.createUser(  
        {  
            user  : yourusername,  
            pwd   : yourpassword,  
            roles :  
            [  
                { role : &quot;dbOwner&quot;, db : yourdb },  
                { role : &quot;clusterAdmin&quot;, db : &quot;admin&quot; }  
            ]  
        }  
    )  

            创建针对某个这个新库的用户  

    注意，上述的两个用户，需要在每个结点（每个分片结点，每个路由结点）上都要创建  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-9&quot;&gt;十二. 开启集群认证&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    keyFile=path/keyfile.dat  

            在每个结点（路由结点，元配置结点，分片结点）的配置文件中加入keyFile的配置项  

    auth=true  

            在每个元配置结点和分片结点（即除了mongos结点）的配置文件中加入auth=true的配置项  

    db.shutdownServer()  

            关闭原先的集群  
            注意，需要按照 路由结点 -&amp;gt; 配置结点 -&amp;gt; 分片结点 的顺序，依次关闭各结点的进程  
            在关闭某个进程时，需要先进入admin库，然后执行这条命令  

    重新启动集群，命令同第六步  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-10&quot;&gt;十三. 验证集群的认证&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    mongo 127.0.0.1:27017/admin  
    
            进入路由结点（地址和端口请按照你的实际情况）  
    
    db.auth(yourusername,yourpassword)  
    
            admin库的认证  
    
    use 新库  
    
            进入之前你创建的新库  
    
    db.新表.insert({...})  
    
            往这个新库的新表里插入一条数据  
            发现报错没有权限，因为你需要进行auth，先执行db.auth(yourusr,yourpwd)  
            然后再执行这条命令  
    
    db.新表名.ensureIndex({...})  
    
            为这个新表添加索引  
    
    db.runCommand({ shardcollection : &quot;库名.表名&quot;, key : {...} })  
    
            为这个新表添加片键。注意，强烈推荐片键是索引的一部分前缀，这样能够达到查询的局部化  
            注意，要先进入admin库，否则这条命令不会成功  
    
    db.表名.stats()  
    
            查看该库中的该表的集群状态  
            若发现里面最开始的sharded字段是true，则表示添加认证功能后的集群没有出现异常  
    
    db.printShardingStatus()  
    
            查看分片状态  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 19 Aug 2016 04:20:00 +0800</pubDate>
        <link>http://localhost:4000/2016/08/19/Mongo-Cluster/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/08/19/Mongo-Cluster/</guid>
        
        
        <category>Database</category>
        
      </item>
    
  </channel>
</rss>
